<!DOCTYPE html>
<html>
<head>
<title>Fri Aug 27, 2021 : #flightworthy (chtc)</title>
</head>
<body>
<h3>Fri Aug 27, 2021 : #flightworthy (chtc)</h3>
<span style="color: #99a949"><span style="font-size: small">(10:06:01)</span> <b>matyas:</b></span> Hey folks, can someone help with a freshdesk ticket? (<a href="https://support.opensciencegrid.org/public/tickets/55b1e8469575e86fa52b23def0107bbf738eb8b2bb682238ba94ab06eae7460e">public link</a>). condor_ce_q hangs frequently on the site. 9.0.4, with GSI.<br/>
<span style="color: #4cc091"><span style="font-size: small">(10:10:58)</span> <b>blin:</b></span> i don't think auth is really a concern here (he's running it from the CE host so it should be using FS auth) at this point<br/>
<span style="color: #4cc091"><span style="font-size: small">(10:11:22)</span> <b>blin:</b></span> @bbockelman was suspecting potential IO issues last i saw<br/>
<span style="color: #99a949"><span style="font-size: small">(10:15:00)</span> <b>matyas:</b></span> it looks like it's at least _trying_ GSI auth given one of the stack traces<br/>
<span style="color: #99a949"><span style="font-size: small">(10:15:46)</span> <b>matyas:</b></span> <pre>#0  0x00007f13ac70caca in probable_prime () from /usr/lib64/libcrypto.so.10<br/>#1  0x00007f13ac70d52c in BN_generate_prime_ex () from /usr/lib64/libcrypto.so.10<br/>#2  0x00007f13ac73acf7 in RSA_generate_key_ex () from /usr/lib64/libcrypto.so.10<br/>#3  0x00007f13a6bf3d02 in globus_gsi_proxy_create_req () from /usr/lib64/libglobus_gsi_proxy_core.so.0<br/>#4  0x00007f13ad60beed in x509_receive_delegation(char const*, int (*)(void*, void**, unsigned long*), void*, int (*)(void*, void*, unsigned long), void*, void**) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#5  0x00007f13ad6bd23e in ReliSock::get_x509_delegation(char const*, bool, void**) () from /usr/lib64/libcondor_utils_9_0_4.so</pre><br/>note "get_x509_delegation" from "libcondor_utils_9_0_4.so"<br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:17:11)</span> <b>jfrey:</b></span> get_x509_delegation would indicate a job submission, not a condor_(ce_)q.<br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:17:36)</span> <b>jfrey:</b></span> And is independent of authentication.<br/>
<span style="color: #4cc091"><span style="font-size: small">(10:18:26)</span> <b>blin:</b></span> perhaps an overloaded schedd would explain both the job submission delegation and hanging queries?<br/>
<span style="color: #99a949"><span style="font-size: small">(10:18:58)</span> <b>matyas:</b></span> he says it's the schedd process... also its EUID is that of a submitting user<br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:19:42)</span> <b>jfrey:</b></span> Proxy delegation happens as part of file transfer. That would be in a forked child of the schedd with EUID set to the submitting user.<br/>
<span style="color: #99a949"><span style="font-size: small">(10:20:33)</span> <b>matyas:</b></span> does the child set the EUID itself, or does the schedd set the EUID before forking?<br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:20:57)</span> <b>jfrey:</b></span> I would have to check the code, but I believe it happens in the child.<br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:21:14)</span> <b>jfrey:</b></span> Is this stack trace from a core file or attaching with gdb? (i.e. did the process crash?<br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:22:16)</span> <b>jfrey:</b></span> RecentDeamonCoreDutyCycle in the schedd’s ad would help tell if the schedd is overloaded.<br/>
<span style="color: #99a949"><span style="font-size: small">(10:24:04)</span> <b>matyas:</b></span> "pstack" he said<br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:25:44)</span> <b>jfrey:</b></span> Ok. Looks like he polled the forked child of the schedd. And I can confirm that setting EUID to the user happens in the child process.<br/>
<span style="color: #4cc091"><span style="font-size: small">(10:26:37)</span> <b>blin:</b></span> feelsbadman.gif<br/><pre>$ podman run --rm -it opensciencegrid/hosted-ce:release condor_ce_status -pool <a href="http://ce5-vanderbilt.sites.opensciencegrid.org:9619">ce5-vanderbilt.sites.opensciencegrid.org:9619</a> -schedd -af recentdaemoncoredutycycle<br/>0.9999926227717096</pre><br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:26:48)</span> <b>jfrey:</b></span> Definitely overloaded.<br/>
<span style="color: #684b6c"><span style="font-size: small">(10:31:02)</span> <b>bbockelman:</b></span> @blin -  can you do the 'direct' query magic to get the per-callback stats?<br/><br/>I did have andrew dump the process tree a few times to check that he was looking at the parent, not the child.<br/>
<blockquote>
<span style="color: #4cc091"><span style="font-size: small">(10:34:17)</span> <b>blin:</b></span> do they just live in the schedd ad?<br/>
<span style="color: #684b6c"><span style="font-size: small">(11:37:38)</span> <b>bbockelman:</b></span> they are - but not sent to the collector.  There's some <tt>-direct</tt> voodoo I can never remember.<br/>
</blockquote>
<span style="color: #684b6c"><span style="font-size: small">(10:32:16)</span> <b>bbockelman:</b></span> Beyond the delegation (which could be an unlucky pstack), he saw a lot of these:<br/><pre>#0  0x00007f13ab4f51d7 in unlink () from /usr/lib64/libc.so.6<br/>#1  0x00007f13ad511088 in Directory::do_remove_file(char const*) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#2  0x00007f13ad512ba2 in Directory::do_remove(char const*, bool) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#3  0x00007f13ad512c78 in Directory::Remove_Entire_Directory() () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#4  0x00007f13ad63981b in remove_spool_directory(char const*) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#5  0x00007f13ad63ba18 in SpooledJobFiles::removeJobSpoolDirectory(classad::ClassAd*) () from /usr/lib64/libcondor_utils_9_0_4.so</pre><br/>
<span style="color: #9e3997"><span style="font-size: small">(10:34:16)</span> <b>tlmiller:</b></span> That looks like a disk or filesystem problem causing the schedd grief, doesn't it?<br/>
<span style="color: #4cc091"><span style="font-size: small">(10:34:47)</span> <b>blin:</b></span> yeah, i think they looked at <tt>iotop</tt> and things seemed ok?<br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:39:38)</span> <b>jfrey:</b></span> Do a lot of their jobs have spool directories with large numbers of files?<br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:41:21)</span> <b>jfrey:</b></span> If the jobs generate a huge number of output files, it may take some work to catch them.<br/>
<span style="color: #9b3b45"><span style="font-size: small">(10:42:09)</span> <b>jfrey:</b></span> strace’ing the schedd for a few minutes would reveal if it’s doing a ton of unlink()s<br/>
<span style="color: #4cc091"><span style="font-size: small">(10:42:11)</span> <b>blin:</b></span> should we take this to the #software channel in the OSG slack? Andrew's quite responsive there and it'd avoid a game of telephone<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:51:44)</span> <b>coatsworth:</b></span> Just to be clear: can I still push documentation changes directly to master without going through a topic branch? @tannenba please confirm when you have a minute.<br/>
<span style="color: #235e5b"><span style="font-size: small">(13:59:28)</span> <b>johnkn:</b></span> Does anyone know why the CTHC pool is mostly running 9.1.0 with a few 9.1.1's thrown in?  that's a pretty old build...<br/>
<span style="color: #674b1b"><span style="font-size: small">(14:08:18)</span> <b>coatsworth:</b></span> I was wondering the same thing, I was surprised to see submit2 still running 9.1.2 when we've already released 9.1.3?<br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:02:42)</span> <b>tim:</b></span> It looks like they missed the step to push 9.1.1 out to the rest of the pool. The 9.1.2 and 9.1.3 security updates were for submit nodes and central collector only.<br/>
<blockquote>
<span style="color: #5a4592"><span style="font-size: small">(16:04:48)</span> <b>tannenba:</b></span> @tim Re your comment above:<br/>1. v9.1.3 was not a security update.  <br/>
<span style="color: #5a4592"><span style="font-size: small">(16:05:00)</span> <b>tannenba:</b></span> 2. submit5.chtc is still running v9.1.1<br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:05:59)</span> <b>tim:</b></span> You are right 9.1.1 and 9.1.2 were security releases.<br/>
<span style="color: #5a4592"><span style="font-size: small">(16:07:43)</span> <b>tannenba:</b></span> 3. One of the security patches impacts could impact more than submit and central managers, unless SEC_DEFAULT_AUTHENTICATION_METHODS is redefined to not use SciTokens.  At least according to the info at <a href="https://research.cs.wisc.edu/htcondor/security/vulnerabilities/HTCONDOR-2021-0004.html">https://research.cs.wisc.edu/htcondor/security/vulnerabilities/HTCONDOR-2021-0004.html</a><br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:09:37)</span> <b>tim:</b></span> CHTC was running a "special" 9.1.1 that had the work toward 9.1.3 with the security patches.<br/>
<span style="color: #5a4592"><span style="font-size: small">(16:13:29)</span> <b>tannenba:</b></span> @tim Please add to the release punchlist to do a condor_status at CHTC to validate the current version being released has indeed been running at CHTC.... Looks to me like v9.1.3 went out the door without ever being run on any CHTC execute nodes....<br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:14:32)</span> <b>tim:</b></span> @tannenba Yes, we did test 9.1.3 changes. They had a special build. That included 9.1.3 changes plus the security fixes<br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:14:51)</span> <b>tim:</b></span> It was called 9.1.1 because of information embargo.<br/>
</blockquote>
<span style="color: #5a4592"><span style="font-size: small">(16:02:46)</span> <b>tannenba:</b></span> @tim @wiscmoate @tjslauson Hi folks, so HTCondor v9.1.3 was released 8/19/21, meaning it should have been running in CHTC since early August.... but looking today at servers in the <tt><a href="http://chtc.wisc.edu">chtc.wisc.edu</a></tt> domain in our pool, it appears that only the central manager and one access point is running v9.1.3..... and zero (!) execution points.  Also CHTC is  vulnerable to security issues as we have servers that did not receive the security update (e.g. submit5.chtc)...<br/><pre>$ condor_status -collector -cons 'regexp("<a href="http://chtc.wisc.edu">chtc.wisc.edu</a>",name)' -af CondorVersion | sort | uniq -c       <br/>      3 $CondorVersion: 9.1.3 Aug 03 2021 BuildID: 552620 PackageID: 9.1.3-0.552620 RC $<br/>$ condor_status -negotiator -cons 'regexp("<a href="http://chtc.wisc.edu">chtc.wisc.edu</a>",name)' -af CondorVersion | sort | uniq -c         <br/>      3 $CondorVersion: 9.1.3 Aug 03 2021 BuildID: 552620 PackageID: 9.1.3-0.552620 RC $<br/>$ condor_status -schedd -cons 'regexp("<a href="http://chtc.wisc.edu">chtc.wisc.edu</a>",name)' -af CondorVersion | sort | uniq -c          <br/>      1 $CondorVersion: 8.9.8 Jun 29 2020 BuildID: 508520 PackageID: 8.9.8-0.508520 $<br/>     11 $CondorVersion: 9.1.0 May 13 2021 BuildID: 541048 PackageID: 9.1.0-0.541048 RC $<br/>      7 $CondorVersion: 9.1.1 Jun 29 2021 BuildID: 548245 PackageID: 9.1.1-0.548245 RC $<br/>      5 $CondorVersion: 9.1.2 Jul 13 2021 BuildID: 550476 PackageID: 9.1.2-0.550476 RC $<br/>      1 $CondorVersion: 9.1.3 Aug 03 2021 BuildID: 552620 PackageID: 9.1.3-0.552620 RC $<br/>$ condor_status -startd -cons 'PartitionableSlot=?=True &amp;&amp; regexp("<a href="http://chtc.wisc.edu">chtc.wisc.edu</a>",name)' -af CondorVersion | sort | uniq -c  <br/>      1 $CondorVersion: 8.9.10 Nov 16 2020 BuildID: 523243 PackageID: 8.9.10-0.523243 RC $<br/>      1 $CondorVersion: 8.9.6 Mar 18 2020 BuildID: 498485 PackageID: 8.9.6-0.498485 PRE-RELEASE-UWCS $<br/>      3 $CondorVersion: 8.9.6 Mar 22 2020 BuildID: 498526 PackageID: 8.9.6-1 $<br/>      2 $CondorVersion: 8.9.9 Sep 24 2020 BuildID: 518510 PackageID: 8.9.9-0.518510 $<br/>     12 $CondorVersion: 9.1.0 May 03 2021 BuildID: 539023 PackageID: 9.1.0-0.539023 RC $<br/>    386 $CondorVersion: 9.1.0 May 13 2021 BuildID: 541048 PackageID: 9.1.0-0.541048 RC $<br/>     60 $CondorVersion: 9.1.1 Jun 29 2021 BuildID: 548245 PackageID: 9.1.1-0.548245 RC $</pre><br/>
<span style="color: #3c989f"><span style="font-size: small">(16:11:32)</span> <b>wiscmoate:</b></span> @tannenba admittedly, we should have just upgraded the whole pool, I was following instructions at the time from -&gt; <a href="https://wiki.chtc.wisc.edu/wiki/HTCondor_9.1_CHTC_Pool_Upgrade_Logs#9.1.2-0.550476">https://wiki.chtc.wisc.edu/wiki/HTCondor_9.1_CHTC_Pool_Upgrade_Logs#9.1.2-0.550476</a><br/>&gt;    Code changes are in the Collector and Schedd alone. As such, only submit nodes and the central manager need be updated.<br/>I've had a <a href="https://wiki.chtc.wisc.edu/wiki/HTCondor_9.1_CHTC_Pool_Upgrade_Logs#9.1.3-0.552620">9.1.3</a> for a bit, but have been waiting for an HTCondor pre-release to drop so as to not duplicate effort<br/>
<span style="color: #3c989f"><span style="font-size: small">(16:12:43)</span> <b>wiscmoate:</b></span> I know it should be higher priority, but things have been busy<br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:13:25)</span> <b>tim:</b></span> @tannenba are we going to give him an RC on Monday? We were going to decide today, I think.<br/>
<span style="color: #684b6c"><span style="font-size: small">(16:14:59)</span> <b>bbockelman:</b></span> <a href="https://research.cs.wisc.edu/htcondor/news/HTCondor_9.1.3_released/">https://research.cs.wisc.edu/htcondor/news/HTCondor_9.1.3_released/</a> &lt;~ 9.1.3 is already released.<br/>
<span style="color: #5a4592"><span style="font-size: small">(16:15:26)</span> <b>tannenba:</b></span> @tim I think it is likely we will give him an RC on either Mon or Tues, we can decide at our Monday huddle....<br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:16:05)</span> <b>tim:</b></span> @bbockelman Yes, 9.1.3 was tested in CHTC. It was just called 9.1.1 because of security release embargo/<br/>
<span style="color: #235e5b"><span style="font-size: small">(16:16:40)</span> <b>johnkn:</b></span> thats good, but most of the CHTC execute nodes are still 9.1.0<br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:18:07)</span> <b>tim:</b></span> Yes, infrastructure missed step to roll it out the remaining execute nodes. Todd T wants the release manager to double check their work now. I'll add it to the check list.<br/>
<span style="color: #3c989f"><span style="font-size: small">(16:19:13)</span> <b>wiscmoate:</b></span> Yes, that's my fault.<br/>
<span style="color: #3c989f"><span style="font-size: small">(16:19:31)</span> <b>wiscmoate:</b></span> Apologies.<br/>
<span style="color: #3c989f"><span style="font-size: small">(16:20:42)</span> <b>wiscmoate:</b></span> It would definitely help to have a check from CHTC devs (didn't say the F-word!), makes sense.<br/>
<span style="color: #5a4592"><span style="font-size: small">(16:21:01)</span> <b>tannenba:</b></span> @tim I was unaware that we disfigure the version number in our security releases... that seems pretty wacked.... something to straighten out when the security release punchlist appears on the wiki today ...  hint, hint! :slightly_smiling_face:<br/>
<span style="color: #684b6c"><span style="font-size: small">(16:24:24)</span> <b>bbockelman:</b></span> So the 9.1.3-as-tested-on-CHTC-that-calls-itself-9.1.1 -- did it contain the patches for 9.1.1 and 9.1.2?<br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:26:33)</span> <b>tim:</b></span> Nothing changes outwardly when a security release is in progress. Normally, we have done a security release between code freezes. We code froze for development, did our security release, and then code froze for stable. So, the development version numbers look odd.<br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:28:49)</span> <b>tim:</b></span> So, 9.1.3 testing as 9.1.1 had the security fixes for 9.1.1 only. It was the 9.1.3 RC that contained the 9.1.2 fixes. That went on the central manager immediately due to GSI crashing.<br/>
<span style="color: #bb86b7"><span style="font-size: small">(16:29:31)</span> <b>tim:</b></span> It was noted to be appropriate for all nodes. It really should have gone on the submit nodes as well. I should have pushed Moate for that.<br/>
<span style="color: #684b6c"><span style="font-size: small">(16:38:55)</span> <b>bbockelman:</b></span> What tag does 9.1.3 testing as 9.1.1 correspond to?<br/>
<span style="color: #2b6836"><span style="font-size: small">(16:50:04)</span> <b>jcpatton:</b></span> Weird job behavior over in OSG land: <a href="https://opensciencegrid.atlassian.net/browse/HTCONDOR-689">https://opensciencegrid.atlassian.net/browse/HTCONDOR-689</a><br/>
<span style="color: #2b6836"><span style="font-size: small">(16:50:17)</span> <b>jcpatton:</b></span> Not sure who wants to take a stab<br/>
<span style="color: #2b6836"><span style="font-size: small">(16:50:32)</span> <b>jcpatton:</b></span> <tt>NumJobStarts = 0</tt> even though the job completed… vanilla universe<br/>
<span style="color: #5a4592"><span style="font-size: small">(16:55:46)</span> <b>tannenba:</b></span> @jcpatton Ugh.  At first blush, looks like perhaps there was a network disconnect between shadow&lt;-&gt;starter soon after input sandbox file transfer completed, before the starter could tell the shadow it is forking the job.  Then when the shadow&lt;-&gt;starter reconnected later, NumJobStarts was still never incremented....<br/>
<span style="color: #684b6c"><span style="font-size: small">(18:00:33)</span> <b>bbockelman:</b></span> Yeah, we’ve seen this before… missed updates are lost.<br/>
</body>
</html>
