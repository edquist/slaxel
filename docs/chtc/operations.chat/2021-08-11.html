<!DOCTYPE html>
<html>
<head>
<title>Wed Aug 11, 2021 : #operations (chtc)</title>
</head>
<body>
<h3>Wed Aug 11, 2021 : #operations (chtc)</h3>
<span style="color: #9f69e7"><span style="font-size: small">(13:56:17)</span> <b>lmichael:</b></span> Looks like my internet just went out (was out yesterday evening). Proceed without me for the rest of ops meeting.<br/><br/>Did the OConnorbsubmit node show up yet?<br/>Morgan server hasn’t been ordered yet. Had to get a new quote due to delays on part of Morgan group (more $, but their loss).<br/>
<span style="color: #3c989f"><span style="font-size: small">(14:23:04)</span> <b>wiscmoate:</b></span> I've heard nothing about the oconnorsubmit server<br/>
<span style="color: #9f69e7"><span style="font-size: small">(15:02:36)</span> <b>lmichael:</b></span> @wiscmoate @jbart Megan’s high-memory jobs that ran longer than 72 hours requested the following resources (recovered from our high-mem reports):<br/>20cpus, 512GB RAM, 1.5TB disk<br/>
<blockquote>
<span style="color: #9f69e7"><span style="font-size: small">(2021-08-12 11:24:35)</span> <b>lmichael:</b></span> I’ve got mem2001 currently draining, so is ready for a test job submission, then you can cancel the drain with something like the following (on <a href="http://cm.chtc.wisc.edu">cm.chtc.wisc.edu</a>):<br/><pre>sudo condor_drain -pool <a href="http://cm3000.chtc.wisc.edu">cm3000.chtc.wisc.edu</a> -cancel mem2001</pre><br/>
<span style="color: #9f69e7"><span style="font-size: small">(2021-08-12 12:29:17)</span> <b>lmichael:</b></span> @wiscmoate @jbart ^<br/>
<span style="color: #3c989f"><span style="font-size: small">(2021-08-12 12:39:12)</span> <b>wiscmoate:</b></span> Acknowledged @lmichael;  we can't really handle it right now, too many irons in the fire;  Having Joe submit a simpler job at the moment.<br/>
<span style="color: #3c989f"><span style="font-size: small">(2021-08-12 13:31:18)</span> <b>wiscmoate:</b></span> @jbart can you figure out how to submit a job like the one above?<br/>
<span style="color: #73769d"><span style="font-size: small">(2021-08-12 13:32:13)</span> <b>jbart:</b></span> I will give it a try! Will run it by you before I submit.<br/>
<span style="color: #3c989f"><span style="font-size: small">(2021-08-12 13:32:16)</span> <b>wiscmoate:</b></span> Make it sleep for 72 hours<br/>
<span style="color: #3c989f"><span style="font-size: small">(2021-08-12 13:32:26)</span> <b>wiscmoate:</b></span> Actually -<br/>
<span style="color: #3c989f"><span style="font-size: small">(2021-08-12 13:32:31)</span> <b>wiscmoate:</b></span> Make it sleep for 2 weeks<br/>
<span style="color: #73769d"><span style="font-size: small">(2021-08-12 13:34:41)</span> <b>jbart:</b></span> Am i understanding right that you want a job that requests those resources, then just sleeps for 2 weeks?<br/>
<span style="color: #3c989f"><span style="font-size: small">(2021-08-12 13:39:25)</span> <b>wiscmoate:</b></span> Yes<br/>
<span style="color: #3c989f"><span style="font-size: small">(2021-08-12 13:39:46)</span> <b>wiscmoate:</b></span> We're not going to let it run for two weeks, but I want it to run until we say otherwise<br/>
<span style="color: #3c989f"><span style="font-size: small">(2021-08-12 13:40:25)</span> <b>wiscmoate:</b></span> If you have useful computation to have it do, do that :wink:<br/>
<span style="color: #3c989f"><span style="font-size: small">(2021-08-12 13:41:09)</span> <b>wiscmoate:</b></span> But the point here is to investigate why jobs aren't getting kicked off after 72 hours<br/>
<span style="color: #73769d"><span style="font-size: small">(2021-08-12 13:48:52)</span> <b>jbart:</b></span> Yep, understood. Just wanted to confirm!<br/>
<span style="color: #73769d"><span style="font-size: small">(2021-08-17 07:42:03)</span> <b>jbart:</b></span> OWNER        BATCH_NAME    SUBMITTED   DONE   RUN    IDLE  TOTAL JOB_IDS<br/>jfbartkowiak ID: 2326     8/12 16:03      _      1      _      1 2326.0<br/><br/>1 jobs; 0 completed, 0 removed, 0 idle, 1 running, 0 held, 0 suspended<br/><br/>Did we just watch this job WAY overshoot 72 hours?<br/>
<span style="color: #9f69e7"><span style="font-size: small">(2021-08-17 08:54:17)</span> <b>lmichael:</b></span> Yup! Now, drain the machine to see what happens. (Use my same ‘condor_drain’ command as before, but replace ‘-cancel’ with ‘-resume’)<br/>
<span style="color: #9f69e7"><span style="font-size: small">(2021-08-17 09:34:50)</span> <b>lmichael:</b></span> @gthain see above. Joe’s test job has run BEYOND 72 hours on mem2001 (machine not draining). We’re hoping to recreate what happened with Megan Frayer’s job, which didn’t go on hood after 72 hours, but we weren’t quite expecting it to run longer than that.<br/>
<span style="color: #73769d"><span style="font-size: small">(2021-08-17 11:01:13)</span> <b>jbart:</b></span> I ran your command with -resume, now we wait!<br/>
<span style="color: #9f69e7"><span style="font-size: small">(2021-08-18 09:22:09)</span> <b>lmichael:</b></span> I don’t think your execution of the command worked (server was not draining, and your job was still running). I just ran the command and it looks like your job was immediately evicted. Question is: was it put on hold?<br/><br/>@gthain ^<br/>
<span style="color: #9f69e7"><span style="font-size: small">(2021-08-18 11:31:42)</span> <b>lmichael:</b></span> @jbart, can you manually hold your jobs (with condor_hold) so that it will stop running (again) on the high-memory servers. I have other user jobs to match there (you are higher priority), and we’ve now confirmed that your job was (1) only evicted once the machine was drained (instead of at the desired 72 hours), and (2) was not held when evicted (since it’s now running again after I un-drained). @gthain<br/>
<span style="color: #73769d"><span style="font-size: small">(2021-08-18 11:32:10)</span> <b>jbart:</b></span> Will do!<br/>
<span style="color: #73769d"><span style="font-size: small">(2021-08-18 11:38:22)</span> <b>jbart:</b></span> @lmichael<br/>You may want to confirm individually, but I believe my job was successfully put on hold.<br/><pre>1 jobs; 0 completed, 0 removed, 0 idle, 0 running, 1 held, 0 suspended</pre><br/>
</blockquote>
<span style="color: #684b6c"><span style="font-size: small">(15:16:46)</span> <b>bbockelman:</b></span> @johnkn / @wiscmoate / @tannenba - Quick question from a user.<br/>1. What, precisely, is in gpulab2003?  I see <tt>TotalGPUs = 14</tt> whereas <tt>GPU_XXXXXXXXDeviceUuid</tt> has 7 unique GPUs listed.  My memory is that "8" is the right number, no more, no less.<br/>2. Do we have any monitoring of GPU memory usage?  I could have sworn we had an attribute to report memory usage but I see it neither in the running job nor the slot ad (just doing a <tt>grep -i gpu</tt> on the relevant ads).<br/>
<span style="color: #3c989f"><span style="font-size: small">(15:21:54)</span> <b>wiscmoate:</b></span> &gt;  What, precisely, is in gpulab2003?  I see <tt>TotalGPUs = 14</tt> whereas <tt>GPU_XXXXXXXXDeviceUuid</tt> has 7 unique GPUs listed.  My memory is that "8" is the right number, no more, no less.<br/>@bbockelman 8 physical GPUs, likely one has dropped out.  The doubling of <tt>TotalGPUS</tt> (7*2) is likely due to bologna batch configuration<br/>
<span style="color: #3c989f"><span style="font-size: small">(15:28:52)</span> <b>wiscmoate:</b></span> &gt;  Do we have any monitoring of GPU memory usage?  I could have sworn we had an attribute to report memory usage but I see it neither in the running job nor the slot ad (just doing a <tt>grep -i gpu</tt> on the relevant ads).<br/>@bbockelman Telemetry exists in ganglia.  Our ganglia server is limping along (I don't think it can handle its current load) so be prepared for long wait times, but here is the 1 week display for <a href="http://gpulab2003.chtc.wisc.edu">gpulab2003.chtc.wisc.edu</a>, look under <tt>gpu metrics</tt><br/>
<span style="color: #3c989f"><span style="font-size: small">(15:32:54)</span> <b>wiscmoate:</b></span> Right, the link....<br/>
<span style="color: #3c989f"><span style="font-size: small">(15:35:01)</span> <b>wiscmoate:</b></span> <a href="https://ganglia.chtc.wisc.edu/?r=week&amp;cs=&amp;ce=&amp;m=cpu_report&amp;c=CHTC&amp;h=gpulab2003.chtc.wisc.edu&amp;tab=m&amp;vn=&amp;tz=&amp;hide-hf=false&amp;mc=2&amp;z=medium&amp;metric_group=NOGROUPS">https://ganglia.chtc.wisc.edu/?r=week&amp;cs=&amp;ce=&amp;m=cpu_report&amp;c=CHTC&amp;h=gpulab2003.chtc.wisc.edu&amp;tab=m&amp;vn=&amp;tz=&amp;hide-hf=false&amp;mc=2&amp;z=medium&amp;metric_group=NOGROUPS</a><br/>
</body>
</html>
