<!DOCTYPE html>
<html>
<head>
<title>Mon May 4, 2020 : #ligo-rucio (osg)</title>
</head>
<body>
<h3>Mon May 4, 2020 : #ligo-rucio (osg)</h3>
<span style="color: #a2a5dc"><span style="font-size: small">(14:54:05)</span> <b>james.clark:</b></span> Hi <b>@channel</b>, i need to set up some larger transfers to Tokyo...  I've just spent the afternoon setting up and testing the rucio throttling daemon so *hopefully* there should be no more than 100 requests submitted to FTS at a time.   There are 6 datasets: 5 with ~5k files and one with ~15k files.<br/><br/>My plan: set up a transfer for the 1st dataset and keep an eye on it to make sure the throttling is working ok (i have just tested this with a different end point and it seems to work ok).<br/><br/>Worst case scenario: i configured something badly and there will be a request for ~5k transfers.  In that case, I'll let that finish and go back to the drawing board before submitting any more.<br/>
<span style="color: #ea2977"><span style="font-size: small">(14:55:17)</span> <b>jlstephen:</b></span> ok thanks for the heads up<br/>
<span style="color: #a63024"><span style="font-size: small">(15:05:04)</span> <b>paschos:</b></span> filesizes? @james.clark<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(15:06:21)</span> <b>james.clark:</b></span> current batch is ~800 M.<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(15:06:32)</span> <b>james.clark:</b></span> the throttle *seems* to be working ok, thankfully<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(15:42:17)</span> <b>james.clark:</b></span> hmm.  so, it does look like it's putting stuff in the queue, rather than submitting everything all at once, but it's still doing so at a higher rate than I asked for.  I'll hold off submitting everything else until I have a better handle on exactly what it's doing and if there's an additional knob to turn - i'd like to have full control over this.<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(16:34:24)</span> <b>james.clark:</b></span> oh, wait - looks the the pod running the throttle daemon had crashed (i had an erroneous start option).  I believe throughput should stop growing now.  i'll let this batch finish to be on the safe side, though.<br/>
</body>
</html>
