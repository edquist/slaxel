<!DOCTYPE html>
<html>
<head>
<title>Mon Oct 26, 2020 : #software (osg)</title>
</head>
<body>
<h3>Mon Oct 26, 2020 : #software (osg)</h3>
<span style="color: #e96699"><span style="font-size: small">(12:45:22)</span> <b>lincoln:</b></span> hi software, I think Pascal has mentioned this before but we are often seeing "stale file handle" on one of our CVMFS clients which requires us to clean up the mount and fix things. we are using cvmfs-2.7.4-1.osg35.el7.x86_64 on EL7<br/>
<span style="color: #e96699"><span style="font-size: small">(12:45:31)</span> <b>lincoln:</b></span> how should we go about debugging it?<br/>
<span style="color: #e96699"><span style="font-size: small">(12:45:58)</span> <b>lincoln:</b></span> It happens frequently, seemingly once a day<br/>
<span style="color: #e96699"><span style="font-size: small">(12:46:47)</span> <b>lincoln:</b></span> We see some log messages as such:<br/><pre>Oct 26 12:38:30 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) geographic order of servers retrieved from <a href="http://cvmfs-s1goc.opensciencegrid.org">cvmfs-s1goc.opensciencegrid.org</a><br/>Oct 26 12:38:30 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) CernVM-FS: linking /cvmfs/config-osg.opensciencegrid.org to repository <a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a><br/>Oct 26 12:38:30 scott cvmfs2: (libcvmfs_fuse3_stub.so) failed to download repository manifest (2 - malformed URL)<br/>Oct 26 12:38:30 scott cvmfs2: (libcvmfs_fuse3_stub.so) failed to fetch file catalog at libcvmfs_fuse3_stub.so:/ (hash: 0000000000000000000000000000000000000000, error 2 [malformed URL])<br/>Oct 26 12:38:30 scott cvmfs2: (libcvmfs_fuse3_stub.so) Failed to initialize root file catalog (16 - file catalog failure)<br/>Oct 26 12:38:31 scott cvmfs2: (libcvmfs_fuse_stub.so) failed to download repository manifest (2 - malformed URL)<br/>Oct 26 12:38:31 scott cvmfs2: (libcvmfs_fuse_stub.so) failed to fetch file catalog at libcvmfs_fuse_stub.so:/ (hash: 0000000000000000000000000000000000000000, error 2 [malformed URL])</pre><br/>
<span style="color: #e96699"><span style="font-size: small">(12:46:58)</span> <b>lincoln:</b></span> malformed URL :thinking_face: :thinking_face: :thinking_face: :thinking_face:<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:47:09)</span> <b>bbockelm:</b></span> @dwd is typically excellent at this.<br/>
<span style="color: #e96699"><span style="font-size: small">(12:47:44)</span> <b>lincoln:</b></span> I think that the FUSE client is crashing in some manner leading to the stale file handle<br/>
<span style="color: #e96699"><span style="font-size: small">(12:47:46)</span> <b>lincoln:</b></span> does it core dump or anything?<br/>
<span style="color: #e96699"><span style="font-size: small">(12:48:02)</span> <b>lincoln:</b></span> @jlstephen might have more information on the nature of the issue<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:48:04)</span> <b>bbockelm:</b></span> Is it stale file handle or transport endpoint disconnected?<br/>
<span style="color: #ea2977"><span style="font-size: small">(12:48:48)</span> <b>jlstephen:</b></span> transport endpoint disconnected<br/>
<span style="color: #e96699"><span style="font-size: small">(12:48:58)</span> <b>lincoln:</b></span> oh, my b :slightly_smiling_face:<br/>
<span style="color: #ea2977"><span style="font-size: small">(12:49:38)</span> <b>jlstephen:</b></span> those messages are actually from after i started reloading cvmfs<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:49:51)</span> <b>bbockelm:</b></span> Get anything useful pre-crash?<br/>
<span style="color: #ea2977"><span style="font-size: small">(12:50:08)</span> <b>jlstephen:</b></span> <pre>Oct 26 12:11:07 scott cvmfs2: (<a href="http://oasis.opensciencegrid.org">oasis.opensciencegrid.org</a>) geographic order of servers retrieved from <a href="http://cvmfs-s1fnal.opensciencegrid.org">cvmfs-s1fnal.opensciencegrid.org</a><br/>Oct 26 12:11:07 scott cvmfs2: (<a href="http://oasis.opensciencegrid.org">oasis.opensciencegrid.org</a>) CernVM-FS: linking /cvmfs/oasis.opensciencegrid.org to repository <a href="http://oasis.opensciencegrid.org">oasis.opensciencegrid.org</a><br/>Oct 26 12:38:05 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) looks like cvmfs has been crashed previously<br/>Oct 26 12:38:05 scott cvmfs2: re-building cache database</pre><br/>is all i have in /var/log/messages<br/>
<span style="color: #ea2977"><span style="font-size: small">(12:50:17)</span> <b>jlstephen:</b></span> i didn't see anything for that time frame in dmesg<br/>
<span style="color: #ea2977"><span style="font-size: small">(12:50:28)</span> <b>jlstephen:</b></span> i started reloading at 12:38:05<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:50:29)</span> <b>bbockelm:</b></span> any chance you're running <tt>abrtd</tt> on the machine?<br/>
<span style="color: #ea2977"><span style="font-size: small">(12:50:50)</span> <b>jlstephen:</b></span> yes<br/>
<span style="color: #ea2977"><span style="font-size: small">(12:51:06)</span> <b>jlstephen:</b></span> looks like it's running<br/>
<span style="color: #99a949"><span style="font-size: small">(12:53:31)</span> <b>dwd:</b></span> malformed URL usually comes from CVMS_SERVER_URL not being set correctly<br/>
<span style="color: #e96699"><span style="font-size: small">(12:53:51)</span> <b>lincoln:</b></span> looks like that comes from after it starts anyhow<br/>
<span style="color: #99a949"><span style="font-size: small">(12:56:21)</span> <b>dwd:</b></span> It is odd to see libcvmfs_fuse3_stub.so in place of a repository name in /var/log/messages<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:57:10)</span> <b>bbockelm:</b></span> @jlstephen - in that case, did it grab the crash from <tt>/var/wherever/abrtd</tt>?  Otherwise, the CVMFS watchdog process may generate it also.  Again, Dave's the expert.<br/>
<span style="color: #99a949"><span style="font-size: small">(12:59:06)</span> <b>dwd:</b></span> The more useful information is probably further back in the log, from when it started having a problem.  May have been from before the last log rotation.  Since it said <a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a> crashed, look for previous messages with that string<br/>
<span style="color: #e96699"><span style="font-size: small">(13:02:52)</span> <b>lincoln:</b></span> hrm, got something from a few days ago- let me paste<br/>
<span style="color: #e96699"><span style="font-size: small">(13:03:31)</span> <b>lincoln:</b></span> this might be a red herring from _after_ a restart given the immediately preceeding log messages<br/>
<span style="color: #e96699"><span style="font-size: small">(13:03:32)</span> <b>lincoln:</b></span> <pre>Oct 23 15:22:58 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) reloading Fuse module<br/>Oct 23 15:23:02 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) geographic order of servers retrieved from <a href="http://cvmfs-s1goc.opensciencegrid.org">cvmfs-s1goc.opensciencegrid.org</a><br/>Oct 23 15:23:49 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) looks like cvmfs has been crashed previously<br/>Oct 23 15:23:49 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) geographic order of servers retrieved from <a href="http://cvmfs-s1fnal.opensciencegrid.org">cvmfs-s1fnal.opensciencegrid.org</a><br/>Oct 23 15:23:49 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) CernVM-FS: linking /cvmfs/config-osg.opensciencegrid.org to repository <a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a><br/>Oct 23 15:24:09 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) --#012Signal: 6, errno: 2, version: 2.7.4, PID: 3709094#012Executable path: /usr/bin/cvmfs2#012#012Thread 16 (Thread 0x7f3f07fd0700 (LWP 3709099)):#012#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6#012#1  0x00007f3f0a35985f in poll (__timeout=-1, __nfds=2, __fds=0x7f3f07fcfee8)#012    at /usr/include/bits/poll2.h:46#012#2  Watchdog::MainWatchdogListener (data=0x137a900)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/monitor.cc:481#012#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 15 (Thread 0x7f3f077cf700 (LWP 3709100)):#012#0  0x00007f3f0d58275d in read () from /lib64/libpthread.so.0#012#1  0x00007f3f0a37e479 in read (__nbytes=1, __buf=0x7f3f077cee8f, __fd=11)#012    at /usr/include/bits/unistd.h:44#012#2  ReadPipe (fd=11, buf=buf@entry=0x7f3f077cee8f, nbyte=nbyte@entry=1)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/util/posix.cc:421#012#3  0x00007f3f0a399638 in FuseInvalidator::MainInvalidator (data=0x137a7a0)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/fuse_evict.cc:111#012#4  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#5  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 14 (Thread 0x7f3f06fce700 (LWP 3709101)):#012#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6#012#1  0x00007f3f0a39a41f in poll (__timeout=&lt;optimized out&gt;, __nfds=1, #012    __fds=0x7f3f06fcded0) at /usr/include/bits/poll2.h:46#012#2  FuseRemounter::MainRemountTrigger (data=0x137a720)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/fuse_remount.cc:174#012#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 13 (Thread 0x7f3f067cd700 (LWP 3709102)):#012#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6#012#1  0x00007f3f0a3446bf in poll (__timeout=60000, __nfds=1, #012    __fds=0x7f3f067cced0) at /usr/include/bits/poll2.h:46#012#2  glue::NentryTracker::MainCleaner (data=0x137a230)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/glue_buffer.cc:187#012#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 12 (Thread 0x7f3f05fcc700 (LWP 3709103)):#012#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6#012#1  0x00007f3f0a33a9ca in poll (__timeout=&lt;optimized out&gt;, #012    __nfds=&lt;optimized out&gt;, __fds=&lt;optimized out&gt;)#012    at /usr/include/bits/poll2.h:46#012#2  download::DownloadManager::MainDownload (data=0x12d6f00)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/download.cc:501#012#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 11 (Thread 0x7f3f057cb700 (LWP 3709104)):#012#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6#012#1  0x00007f3f0a33a9ca in poll (__timeout=&lt;optimized out&gt;, #012    __nfds=&lt;optimized out&gt;, __fds=&lt;optimized out&gt;)#012    at /usr/include/bits/poll2.h:46#012#2  download::DownloadManager::MainDownload (data=0x12d8200)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/download.cc:501#012#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 10 (Thread 0x7f3f04fca700 (LWP 3709105)):#012#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6#012#1  0x00007f3f0a39eec8 in poll (__timeout=-1, __nfds=2, __fds=0x7f3efc0008c0)#012    at /usr/include/bits/poll2.h:46#012#2  quota::MainWatchdogListener (data=0x12af5b0)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_listener.cc:89#012#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 9 (Thread 0x7f3ef7fff700 (LWP 3709106)):#012#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6#012#1  0x00007f3f0a39f3e3 in poll (__timeout=-1, __nfds=2, __fds=0x7f3ef00008c0)#012    at /usr/include/bits/poll2.h:46#012#2  quota::MainUnpinListener (data=0x137aa20)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_listener.cc:47#012#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 8 (Thread 0x7f3ef77fe700 (LWP 3709107)):#012#0  0x00007f3f0d5829dd in accept () from /lib64/libpthread.so.0#012#1  0x00007f3f0a3a11cf in TalkManager::MainResponder (data=0x1378af0)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/talk.cc:167#012#2  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#3  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 7 (Thread 0x7f3ef6ffd700 (LWP 3709108)):#012#0  0x00007f3f0d5829dd in accept () from /lib64/libpthread.so.0#012#1  0x00007f3f0c74d69a in loader::loader_talk::MainTalk (data=&lt;optimized out&gt;)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/loader_talk.cc:59#012#2  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#3  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 6 (Thread 0x7f3ef67fc700 (LWP 3709109)):#012#0  0x00007f3f0ca7b9a3 in select () from /lib64/libc.so.6#012#1  0x00007f3f0a37f7e9 in SafeSleepMs (ms=ms@entry=100)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/util/posix.cc:1519#012#2  0x00007f3f0a35a407 in Watchdog::SendTrace (sig=6, #012    siginfo=&lt;optimized out&gt;, context=&lt;optimized out&gt;)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/monitor.cc:312#012#3  &lt;signal handler called&gt;#012#4  0x00007f3f0c9bc387 in raise () from /lib64/libc.so.6#012#5  0x00007f3f0c9bda78 in abort () from /lib64/libc.so.6#012#6  0x00007f3f0c9b51a6 in __assert_fail_base () from /lib64/libc.so.6#012#7  0x00007f3f0c9b5252 in __assert_fail () from /lib64/libc.so.6#012#8  0x00007f3f0a36e344 in PosixQuotaManager::MakeReturnPipe (#012    this=this@entry=0x12b4430, pipe=pipe@entry=0x7f3ef67fbaf0)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_posix.cc:1420#012#9  0x00007f3f0a36e7b7 in PosixQuotaManager::GetSharedStatus (this=0x12b4430, #012    gauge=gauge@entry=0x7f3ef67fbb78, pinned=pinned@entry=0x7f3ef67fbb80)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_posix.cc:661#012#10 0x00007f3f0a36e85e in PosixQuotaManager::GetSize (this=&lt;optimized out&gt;)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_posix.cc:676#012#11 0x00007f3f0a38defe in cvmfs::cvmfs_statfs (req=0x7f3ee8000e40, ino=256)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/cvmfs.cc:1246#012#12 0x00007f3f0c749c52 in loader::stub_statfs (req=0x7f3ee8000e40, ino=1)#012    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/loader.cc:286#012#13 0x00007f3f0be4573b in do_statfs () from /lib64/libfuse.so.2#012#14 0x00007f3f0be44b6b in fuse_ll_process_buf () from /lib64/libfuse.so.2#012#15 0x00007f3f0be41401 in fuse_do_work () from /lib64/libfuse.so.2#012#16 0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#17 0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 5 (Thread 0x7f3ef5ffb700 (LWP 3709110)):#012#0  0x00007f3f0d58275d in read () from /lib64/libpthread.so.0#012#1  0x00007f3f0be40d62 in fuse_kern_chan_receive () from /lib64/libfuse.so.2#012#2  0x00007f3f0be41d59 in fuse_ll_receive_buf () from /lib64/libfuse.so.2#012#3  0x00007f3f0be4137e in fuse_do_work () from /lib64/libfuse.so.2#012#4  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#5  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 4 (Thread 0x7f3ef57fa700 (LWP 3709111)):#012#0  0x00007f3f0d58275d in read () from /lib64/libpthread.so.0#012#1  0x00007f3f0be40d62 in fuse_kern_chan_receive () from /lib64/libfuse.so.2#012#2  0x00007f3f0be41d59 in fuse_ll_receive_buf () from /lib64/libfuse.so.2#012#3  0x00007f3f0be4137e in fuse_do_work () from /lib64/libfuse.so.2#012#4  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0#012#5  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6#012#012Thread 3 (Thread 0x7f3ef4ff9700 (LWP 3709112)):#012#0  0x00007f3f0d58275d in r<br/>Oct 23 15:24:11 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) crash cleanup handler unmounted stalled /cvmfs/config-osg.opensciencegrid.org</pre><br/>
<span style="color: #99a949"><span style="font-size: small">(13:05:59)</span> <b>dwd:</b></span> That can be made more readable with <tt>sed 's/#012/\n/g'</tt><br/>
<span style="color: #e96699"><span style="font-size: small">(13:06:36)</span> <b>lincoln:</b></span> happy to do so.<br/><br/>
<span style="color: #e96699"><span style="font-size: small">(13:06:36)</span> <b>lincoln:</b></span> <pre>Oct 23 15:24:09 scott cvmfs2: (<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a>) --<br/>Signal: 6, errno: 2, version: 2.7.4, PID: 3709094<br/>Executable path: /usr/bin/cvmfs2<br/><br/>Thread 16 (Thread 0x7f3f07fd0700 (LWP 3709099)):<br/>#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6<br/>#1  0x00007f3f0a35985f in poll (__timeout=-1, __nfds=2, __fds=0x7f3f07fcfee8)<br/>    at /usr/include/bits/poll2.h:46<br/>#2  Watchdog::MainWatchdogListener (data=0x137a900)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/monitor.cc:481<br/>#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 15 (Thread 0x7f3f077cf700 (LWP 3709100)):<br/>#0  0x00007f3f0d58275d in read () from /lib64/libpthread.so.0<br/>#1  0x00007f3f0a37e479 in read (__nbytes=1, __buf=0x7f3f077cee8f, __fd=11)<br/>    at /usr/include/bits/unistd.h:44<br/>#2  ReadPipe (fd=11, buf=buf@entry=0x7f3f077cee8f, nbyte=nbyte@entry=1)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/util/posix.cc:421<br/>#3  0x00007f3f0a399638 in FuseInvalidator::MainInvalidator (data=0x137a7a0)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/fuse_evict.cc:111<br/>#4  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#5  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 14 (Thread 0x7f3f06fce700 (LWP 3709101)):<br/>#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6<br/>#1  0x00007f3f0a39a41f in poll (__timeout=&lt;optimized out&gt;, __nfds=1,<br/>    __fds=0x7f3f06fcded0) at /usr/include/bits/poll2.h:46<br/>#2  FuseRemounter::MainRemountTrigger (data=0x137a720)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/fuse_remount.cc:174<br/>#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 13 (Thread 0x7f3f067cd700 (LWP 3709102)):<br/>#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6<br/>#1  0x00007f3f0a3446bf in poll (__timeout=60000, __nfds=1,<br/>    __fds=0x7f3f067cced0) at /usr/include/bits/poll2.h:46<br/>#2  glue::NentryTracker::MainCleaner (data=0x137a230)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/glue_buffer.cc:187<br/>#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 12 (Thread 0x7f3f05fcc700 (LWP 3709103)):<br/>#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6<br/>#1  0x00007f3f0a33a9ca in poll (__timeout=&lt;optimized out&gt;,<br/>    __nfds=&lt;optimized out&gt;, __fds=&lt;optimized out&gt;)<br/>    at /usr/include/bits/poll2.h:46<br/>#2  download::DownloadManager::MainDownload (data=0x12d6f00)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/download.cc:501<br/>#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 11 (Thread 0x7f3f057cb700 (LWP 3709104)):<br/>#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6<br/>#1  0x00007f3f0a33a9ca in poll (__timeout=&lt;optimized out&gt;,<br/>    __nfds=&lt;optimized out&gt;, __fds=&lt;optimized out&gt;)<br/>    at /usr/include/bits/poll2.h:46<br/>#2  download::DownloadManager::MainDownload (data=0x12d8200)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/download.cc:501<br/>#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 10 (Thread 0x7f3f04fca700 (LWP 3709105)):<br/>#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6<br/>#1  0x00007f3f0a39eec8 in poll (__timeout=-1, __nfds=2, __fds=0x7f3efc0008c0)<br/>    at /usr/include/bits/poll2.h:46<br/>#2  quota::MainWatchdogListener (data=0x12af5b0)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_listener.cc:89<br/>#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 9 (Thread 0x7f3ef7fff700 (LWP 3709106)):<br/>#0  0x00007f3f0ca79c3d in poll () from /lib64/libc.so.6<br/>#1  0x00007f3f0a39f3e3 in poll (__timeout=-1, __nfds=2, __fds=0x7f3ef00008c0)<br/>    at /usr/include/bits/poll2.h:46<br/>#2  quota::MainUnpinListener (data=0x137aa20)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_listener.cc:47<br/>#3  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#4  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 8 (Thread 0x7f3ef77fe700 (LWP 3709107)):<br/>#0  0x00007f3f0d5829dd in accept () from /lib64/libpthread.so.0<br/>#1  0x00007f3f0a3a11cf in TalkManager::MainResponder (data=0x1378af0)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/talk.cc:167<br/>#2  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#3  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 7 (Thread 0x7f3ef6ffd700 (LWP 3709108)):<br/>#0  0x00007f3f0d5829dd in accept () from /lib64/libpthread.so.0<br/>#1  0x00007f3f0c74d69a in loader::loader_talk::MainTalk (data=&lt;optimized out&gt;)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/loader_talk.cc:59<br/>#2  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#3  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 6 (Thread 0x7f3ef67fc700 (LWP 3709109)):<br/>#0  0x00007f3f0ca7b9a3 in select () from /lib64/libc.so.6<br/>#1  0x00007f3f0a37f7e9 in SafeSleepMs (ms=ms@entry=100)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/util/posix.cc:1519<br/>#2  0x00007f3f0a35a407 in Watchdog::SendTrace (sig=6,<br/>    siginfo=&lt;optimized out&gt;, context=&lt;optimized out&gt;)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/monitor.cc:312<br/>#3  &lt;signal handler called&gt;<br/>#4  0x00007f3f0c9bc387 in raise () from /lib64/libc.so.6<br/>#5  0x00007f3f0c9bda78 in abort () from /lib64/libc.so.6<br/>#6  0x00007f3f0c9b51a6 in __assert_fail_base () from /lib64/libc.so.6<br/>#7  0x00007f3f0c9b5252 in __assert_fail () from /lib64/libc.so.6<br/>#8  0x00007f3f0a36e344 in PosixQuotaManager::MakeReturnPipe (<br/>    this=this@entry=0x12b4430, pipe=pipe@entry=0x7f3ef67fbaf0)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_posix.cc:1420<br/>#9  0x00007f3f0a36e7b7 in PosixQuotaManager::GetSharedStatus (this=0x12b4430,<br/>    gauge=gauge@entry=0x7f3ef67fbb78, pinned=pinned@entry=0x7f3ef67fbb80)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_posix.cc:661<br/>#10 0x00007f3f0a36e85e in PosixQuotaManager::GetSize (this=&lt;optimized out&gt;)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_posix.cc:676<br/>#11 0x00007f3f0a38defe in cvmfs::cvmfs_statfs (req=0x7f3ee8000e40, ino=256)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/cvmfs.cc:1246<br/>#12 0x00007f3f0c749c52 in loader::stub_statfs (req=0x7f3ee8000e40, ino=1)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/loader.cc:286<br/>#13 0x00007f3f0be4573b in do_statfs () from /lib64/libfuse.so.2<br/>#14 0x00007f3f0be44b6b in fuse_ll_process_buf () from /lib64/libfuse.so.2<br/>#15 0x00007f3f0be41401 in fuse_do_work () from /lib64/libfuse.so.2<br/>#16 0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#17 0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 5 (Thread 0x7f3ef5ffb700 (LWP 3709110)):<br/>#0  0x00007f3f0d58275d in read () from /lib64/libpthread.so.0<br/>#1  0x00007f3f0be40d62 in fuse_kern_chan_receive () from /lib64/libfuse.so.2<br/>#2  0x00007f3f0be41d59 in fuse_ll_receive_buf () from /lib64/libfuse.so.2<br/>#3  0x00007f3f0be4137e in fuse_do_work () from /lib64/libfuse.so.2<br/>#4  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#5  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 4 (Thread 0x7f3ef57fa700 (LWP 3709111)):<br/>#0  0x00007f3f0d58275d in read () from /lib64/libpthread.so.0<br/>#1  0x00007f3f0be40d62 in fuse_kern_chan_receive () from /lib64/libfuse.so.2<br/>#2  0x00007f3f0be41d59 in fuse_ll_receive_buf () from /lib64/libfuse.so.2<br/>#3  0x00007f3f0be4137e in fuse_do_work () from /lib64/libfuse.so.2<br/>#4  0x00007f3f0d57bea5 in start_thread () from /lib64/libpthread.so.0<br/>#5  0x00007f3f0ca8496d in clone () from /lib64/libc.so.6<br/><br/>Thread 3 (Thread 0x7f3ef4ff9700 (LWP 3709112)):<br/>#0  0x00007f3f0d58275d in r</pre><br/>
<span style="color: #e96699"><span style="font-size: small">(13:06:43)</span> <b>lincoln:</b></span> appears that msg is truncated<br/>
<span style="color: #99a949"><span style="font-size: small">(13:07:08)</span> <b>dwd:</b></span> It crashed at<br/><pre>#8  0x00007f3f0a36e344 in PosixQuotaManager::MakeReturnPipe (<br/>    this=this@entry=0x12b4430, pipe=pipe@entry=0x7f3ef67fbaf0)<br/>    at /builddir/build/BUILD/cvmfs-2.7.4/cvmfs/quota_posix.cc:1420</pre><br/><br/>
<span style="color: #99a949"><span style="font-size: small">(13:07:54)</span> <b>dwd:</b></span> So it looks like there was a problem with managing the space.  Is there plenty of room in the cache filesystem compared to CVMFS_QUOTA_LIMIT?<br/>
<span style="color: #e96699"><span style="font-size: small">(13:08:07)</span> <b>lincoln:</b></span> looking-<br/>
<span style="color: #ea2977"><span style="font-size: small">(13:08:50)</span> <b>jlstephen:</b></span> yes<br/>
<span style="color: #ea2977"><span style="font-size: small">(13:08:50)</span> <b>jlstephen:</b></span> [root@scott ~]# df -h /scratch/cvmfs/cache<br/>Filesystem      Size  Used Avail Use% Mounted on<br/>/dev/sda2       1.5T  793G  595G  58% /<br/>
<span style="color: #e96699"><span style="font-size: small">(13:08:51)</span> <b>lincoln:</b></span> quota limit is 51200, filesystem has plenty of space (600GB)<br/>
<span style="color: #e96699"><span style="font-size: small">(13:09:25)</span> <b>lincoln:</b></span> <pre>[root@scott cvmfs]# pwd<br/>/scratch/cvmfs<br/>[root@scott cvmfs]# du -h -s<br/>834M    .</pre><br/>
<span style="color: #e96699"><span style="font-size: small">(13:09:30)</span> <b>lincoln:</b></span> probably we wiped the cache<br/>
<span style="color: #99a949"><span style="font-size: small">(13:09:54)</span> <b>dwd:</b></span> Did you wipe it while it was live?<br/>
<span style="color: #ea2977"><span style="font-size: small">(13:10:06)</span> <b>jlstephen:</b></span> i wiped it after the process had completely crashed<br/>
<span style="color: #99a949"><span style="font-size: small">(13:10:28)</span> <b>dwd:</b></span> How’s the root filesystem?<br/>
<span style="color: #e96699"><span style="font-size: small">(13:10:31)</span> <b>lincoln:</b></span> the specific error i posted was from Friday, I don't know what we did then<br/>
<span style="color: #e96699"><span style="font-size: small">(13:11:14)</span> <b>lincoln:</b></span> root filesystem seems ok- no xfs errors in dmesg, disks dont have any reallocated sectors or anything like that to my knowledge<br/>
<span style="color: #e96699"><span style="font-size: small">(13:11:20)</span> <b>lincoln:</b></span> its a raid 1 mirror as i recall<br/>
<span style="color: #a63024"><span style="font-size: small">(13:12:11)</span> <b>paschos:</b></span> the specific error i posted was from Friday, I don’t know what we did then ===&gt; kill, wipe cache and probe<br/>
<span style="color: #e96699"><span style="font-size: small">(13:12:26)</span> <b>lincoln:</b></span> ok<br/>
<span style="color: #e96699"><span style="font-size: small">(13:12:48)</span> <b>lincoln:</b></span> so anyhow - maybe we can look in abrt- is there anything we should do to increase debugging verbosity, capture core dumps, etc?<br/>
<span style="color: #99a949"><span style="font-size: small">(13:12:51)</span> <b>dwd:</b></span> and plenty of space?   The error is actually in MakeReturnPipe.  I wonder if it is a file descriptor problem, although usually we get an error that says it is running out of file descriptors<br/>
<span style="color: #e96699"><span style="font-size: small">(13:13:03)</span> <b>lincoln:</b></span> yes, plenty of space<br/>
<span style="color: #e96699"><span style="font-size: small">(13:13:07)</span> <b>lincoln:</b></span> I can check the ulimits<br/>
<span style="color: #99a949"><span style="font-size: small">(13:13:34)</span> <b>dwd:</b></span> cvmfs has its own file descriptor limit, higher than ulimit<br/>
<span style="color: #99a949"><span style="font-size: small">(13:13:57)</span> <b>dwd:</b></span> How many cores on these nodes?  We have had problems with running out of file descriptors on high core count nodes<br/>
<span style="color: #e96699"><span style="font-size: small">(13:13:57)</span> <b>lincoln:</b></span> alright<br/>
<span style="color: #e96699"><span style="font-size: small">(13:14:02)</span> <b>lincoln:</b></span> 24<br/>
<span style="color: #e96699"><span style="font-size: small">(13:14:26)</span> <b>lincoln:</b></span> it has an identical (hopefully) sister node that doesn't seem to have crashes<br/>
<span style="color: #e96699"><span style="font-size: small">(13:14:37)</span> <b>lincoln:</b></span> so we're a bit flummoxed<br/>
<span style="color: #e96699"><span style="font-size: small">(13:15:17)</span> <b>lincoln:</b></span> the user usage patterns are a bit different, and there are some differences we're aware of but not around CVMFS<br/>
<span style="color: #e96699"><span style="font-size: small">(13:18:03)</span> <b>lincoln:</b></span> this has been a huge thorn in our side for a little while, so we would definitely appreciate any debugging. i.e., the next time it crashes. what should we collect and forward?<br/>
<span style="color: #99a949"><span style="font-size: small">(13:27:03)</span> <b>dwd:</b></span> The code shows the failure was in creating <tt>workspace_dir_ + "/pipe"</tt> and I assume workspace_dir_ is <tt>$CVMS_CACHE_DIR/shared</tt> .  You could do a cvmfs_config bugreport on one of the machines and post a ticket to <a href="https://sft.its.cern.ch/jira/projects/CVM">https://sft.its.cern.ch/jira/projects/CVM</a> although if you do be sure to include the stack trace from the previous messages log, since I’m pretty sure the bugreport only looks in the current log.   If it is a file descriptor problem, you can increase the value with CVMFS_NFILES=131072 in /etc/cvmfs/default.local, although we have mostly only seen such problems on nodes with higher numbers of cores<br/>
<span style="color: #9e3997"><span style="font-size: small">(13:27:09)</span> <b>bbockelm:</b></span> FWIW, here's the surrounding lines of code:<br/><pre>  // Connect reader's end<br/>  pipe[0] = open((workspace_dir_ + "/pipe" + StringifyInt(pipe[1])).c_str(),<br/>                 O_RDONLY | O_NONBLOCK);<br/>  assert(pipe[0] &gt;= 0);</pre><br/><br/>
<span style="color: #9e3997"><span style="font-size: small">(13:27:55)</span> <b>bbockelm:</b></span> _note_ that <tt>workspace_dir + "/pipe"</tt> was created immediately before.<br/>
<span style="color: #e96699"><span style="font-size: small">(13:31:52)</span> <b>lincoln:</b></span> what bothers me is that we only see two crashes with that error in /var/log/messages in a month but we've seen it crash more frequently than that.<br/>
<span style="color: #e96699"><span style="font-size: small">(13:34:07)</span> <b>lincoln:</b></span> what do you think the chances are that its a cleanup-steps-out-of-order issue? i.e., see a transport endpoint connected, do a wipecache _before_ a killall? because I could see myself absentmindedly doing that<br/>
<span style="color: #e96699"><span style="font-size: small">(13:37:12)</span> <b>lincoln:</b></span> @dwd are there any negative side effects of increasing the CVMFS_NFILES everywhere? ( we don't want to special case the puppet rules if possible :slightly_smiling_face: )<br/>
<span style="color: #99a949"><span style="font-size: small">(13:39:34)</span> <b>dwd:</b></span> It’s already messed up when you see transport endpoint message so that wouldn’t be the root cause.  Also I believe that a wipecache is also safe to do while running, although I could be wrong. What would be dangerous and could definitely cause the message was a manual <tt>rm -rf $CVMFS_CACHE_DIR/*</tt> while mounted.  Yes it should be safe to increase CVMFS_NFILES everywhere, I have never seen it cause a problem.<br/>
<span style="color: #99a949"><span style="font-size: small">(13:40:16)</span> <b>dwd:</b></span> You don’t have wipecaches run from cron somewhere do you?<br/>
<span style="color: #e96699"><span style="font-size: small">(13:40:31)</span> <b>lincoln:</b></span> ah ok<br/>
<span style="color: #e96699"><span style="font-size: small">(13:40:36)</span> <b>lincoln:</b></span> we shouldn't<br/>
<span style="color: #9e3997"><span style="font-size: small">(13:59:17)</span> <b>bbockelm:</b></span> @lincoln - looking at the documented return codes of <tt>open()</tt>, here are possibilities that I think are viable:<br/>• Process has hit the FD limit.<br/>• System has hit the FD limit.<br/>• Permission denied.<br/>• File does not exist.<br/>• Insufficient kernel memory.<br/>
<span style="color: #9e3997"><span style="font-size: small">(14:00:14)</span> <b>bbockelm:</b></span> It's unfortunate that it doesn't log anything here and just aborts the process without any breadcrumbs -- but my suspicion is either one of the FD limits or "file does not exist" (clobbering cache cleanup) with a slight preference of "process has hit the FD limit".<br/>
<span style="color: #99a949"><span style="font-size: small">(14:04:19)</span> <b>dwd:</b></span> Is selinux enabled?  We did just run into an issue with inadequate selinux access to symlinks in cvmfs, and I wonder if it might be a similar issue with access to named pipes<br/>
<span style="color: #e96699"><span style="font-size: small">(14:09:41)</span> <b>lincoln:</b></span> It is not<br/>
<span style="color: #99a949"><span style="font-size: small">(14:09:48)</span> <b>dwd:</b></span> ok<br/>
<span style="color: #e96699"><span style="font-size: small">(14:10:17)</span> <b>lincoln:</b></span> OK, I think Judith has applied CVMFS_NFILES<br/>
<span style="color: #9e3997"><span style="font-size: small">(14:10:40)</span> <b>bbockelm:</b></span> (I don't think selinux would be an issue if this is happening "randomly" -- would expect selinux to fail this out all the time)<br/>
<span style="color: #e96699"><span style="font-size: small">(14:10:47)</span> <b>lincoln:</b></span> what are the next steps for capturing debug output should it crash again?<br/>
<span style="color: #99a949"><span style="font-size: small">(14:12:55)</span> <b>dwd:</b></span> Begin with a cvmfs_config bugreport and a CVM ticket as a I said, and include the stack trace.  If Jakob doesn’t have a better answer, he (or I) could make a debug test build that shows the error code from that open call.<br/>
<span style="color: #e96699"><span style="font-size: small">(14:13:01)</span> <b>lincoln:</b></span> got it.<br/>
<span style="color: #e96699"><span style="font-size: small">(14:15:27)</span> <b>lincoln:</b></span> thanks folks<br/>
<span style="color: #e96699"><span style="font-size: small">(14:15:46)</span> <b>lincoln:</b></span> hopefully nfiles fixes it but if it doesn't we'll be back! :wink:<br/>
<span style="color: #99a949"><span style="font-size: small">(14:19:45)</span> <b>dwd:</b></span> It would be good to have a ticket either way<br/>
<span style="color: #e96699"><span style="font-size: small">(14:21:40)</span> <b>lincoln:</b></span> ok sure thing<br/>
</body>
</html>
