<!DOCTYPE html>
<html>
<head>
<title>Mon Apr 23, 2018 : #software (osg)</title>
</head>
<body>
<h3>Mon Apr 23, 2018 : #software (osg)</h3>
<span style="color: #a63024"><span style="font-size: small">(11:28:52)</span> <b>efajardo:</b></span> I did not get<br/>
<span style="color: #a63024"><span style="font-size: small">(11:29:15)</span> <b>efajardo:</b></span> what is the correct way to install<br/>
<span style="color: #a63024"><span style="font-size: small">(11:29:26)</span> <b>efajardo:</b></span> the <tt> /etc/yum.repos.d/goc*.repo</tt> files<br/>
<span style="color: #a63024"><span style="font-size: small">(11:29:33)</span> <b>efajardo:</b></span> and hopefully the up to date ones<br/>
<span style="color: #c386df"><span style="font-size: small">(11:30:43)</span> <b>matyas:</b></span> same as the osg repos<br/>
<span style="color: #c386df"><span style="font-size: small">(11:30:49)</span> <b>matyas:</b></span> install osg-release<br/>
<span style="color: #43761b"><span style="font-size: small">(11:30:50)</span> <b>blin:</b></span> e.g. the <tt>osg-release</tt> rpm<br/>
<span style="color: #c386df"><span style="font-size: small">(11:31:03)</span> <b>matyas:</b></span> except the goc repos are disabled by default so edit the files and set enabled=1<br/>
<span style="color: #a63024"><span style="font-size: small">(11:33:04)</span> <b>efajardo:</b></span> I see<br/>
<span style="color: #a63024"><span style="font-size: small">(11:33:06)</span> <b>efajardo:</b></span> <pre>Installed Packages<br/>osg-release.noarch                                                           3.3-6.osg33.el6                                                           @osg<br/></pre>`<br/>
<span style="color: #a63024"><span style="font-size: small">(11:33:50)</span> <b>efajardo:</b></span> but <tt>/etc/yum.repos.d/goc.repo</tt><br/>
<span style="color: #a63024"><span style="font-size: small">(11:33:59)</span> <b>efajardo:</b></span> <pre>[goc]<br/>name=OSG Software for Enterprise Linux 6 - GOC Production - $basearch<br/>baseurl=<a href="http://repo.grid.iu.edu/osg/goc/el6/production/$basearch">http://repo.grid.iu.edu/osg/goc/el6/production/$basearch</a><br/>#mirrorlist=<a href="http://repo.grid.iu.edu/mirror/osg/goc/el6/production/$basearch">http://repo.grid.iu.edu/mirror/osg/goc/el6/production/$basearch</a><br/>failovermethod=priority<br/>priority=98<br/>enabled=0<br/>gpgcheck=1<br/>gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-OSG<br/>consider_as_osg=yes</pre><br/>
<span style="color: #c386df"><span style="font-size: small">(11:35:48)</span> <b>matyas:</b></span> looks like we didn't update it for 3.3<br/>
<span style="color: #a72f79"><span style="font-size: small">(11:53:28)</span> <b>andrew.melo:</b></span> Hi OSG folks -- I have two software questions/observations (both on C7 + OSG3.4, up-to-date as of Apr 18th)<br/>1. The most recent blahp appears to segfault occasionally:<br/><pre><br/>[Apr18 04:57] blahpd[3209780]: segfault at 7ffddb2cbff8 ip 00007f93b6831bd6 sp 00007ffddb2cc000 error 6 in libclassad.so.8.6.9[7f93b6804000+94000]<br/>[Apr18 06:49] blahpd[658755]: segfault at 7fffa6b6fff8 ip 00007f17833cbbd2 sp 00007fffa6b70000 error 6 in libclassad.so.8.6.9[7f178339e000+94000]<br/>[Apr20 16:42] blahpd[1516770]: segfault at 6 ip 00007fadd1983411 sp 00007fadcdecf708 error 4<br/>[  +0.000041] blahpd[1516769]: segfault at 6 ip 00007fadd1983411 sp 00007fadce6d0708 error 4 in libc-2.17.so[7fadd1846000+1b8000]<br/>[root@ce3 ~]# rpm -q blahp<br/>blahp-1.18.36.bosco-1.osg34.el7.x86_64<br/></pre><br/>2. I've noticed that often CVMFS struggles through updating via yum and will get hopelessly stuck. I pulled this machine over on the 18th, and /cvmfs/cms.cern.ch is still unresponsive:<br/><pre><br/>[root@ce3 ~]# ps aux | grep cvmfs<br/>cvmfs     556490  0.0  0.0 641452  3464 ?        Sl   Apr18   5:39 /usr/bin/cvmfs2 -o rw,fsname=cvmfs2,allow_other,grab_mountpoint,uid=992,gid=989 <a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a> /cvmfs/config-osg.opensciencegrid.org<br/>cvmfs     556553  0.0  0.0 115252  1480 ?        S    Apr18   0:00 /bin/sh<br/>cvmfs     556554  0.0  0.0 115252   664 ?        S    Apr18   0:00 /bin/sh<br/>cvmfs     556555  0.0  0.0 115252   608 ?        S    Apr18   0:00 /bin/sh<br/>cvmfs     556556  0.0  0.0 107976   768 ?        S    Apr18   0:00 df<br/>cvmfs     556557  0.0  0.0 112664   968 ?        S    Apr18   0:00 grep  /$<br/>cvmfs     556558  0.0  0.0 113492   968 ?        S    Apr18   0:00 awk { print $2 }<br/>root      556928  0.0  0.0 123476  1044 ?        S    Apr18   0:00 /usr/bin/mount -n -t cvmfs <a href="http://cms.cern.ch">cms.cern.ch</a> /cvmfs/cms.cern.ch<br/>root      556929  0.0  0.0  14876  1296 ?        S    Apr18   0:00 /sbin/mount.cvmfs <a href="http://cms.cern.ch">cms.cern.ch</a> /cvmfs/cms.cern.ch -n -o rw<br/></pre><br/>
<span style="color: #43761b"><span style="font-size: small">(11:54:40)</span> <b>blin:</b></span> @dwd ^^<br/>
<span style="color: #73769d"><span style="font-size: small">(11:58:54)</span> <b>tim.theisen:</b></span> The blahp was built against HTCondor 8.6.10, it looks like it is getting libraries from HTCondor 8.6.9.<br/>
<span style="color: #99a949"><span style="font-size: small">(11:59:47)</span> <b>dwd:</b></span> @andrew.melo was the CVMFS yum update an upgrade somehow on the 18th?  There was no new version released that day.<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:01:54)</span> <b>andrew.melo:</b></span> @dwd Yeah, I pulled the whole thing forward on the 18th. We use spacewalk (which I have set to update on Sundays), but I saw that there was some CE updates for a bug we were hitting, so I manually moved things<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:03:26)</span> <b>andrew.melo:</b></span> @tim.theisen Hmm. Maybe something weird and racy happened. I pulled everything in one fell swoop, perhaps blahpd started after blah got updated, but before the condor libraries updated<br/><pre><br/>[root@ce3 ~]# rpm -qa --qf '%{INSTALLTIME} (%{INSTALLTIME:date}): %{NAME}-%{VERSION}-%{RELEASE}.%{ARCH}\n' | sort -n | grep -e condor -e blah<br/>1524085127 (Wed 18 Apr 2018 03:58:47 PM CDT): condor-classads-8.6.10-1.osg34.el7.x86_64<br/>1524085128 (Wed 18 Apr 2018 03:58:48 PM CDT): blahp-1.18.36.bosco-1.osg34.el7.x86_64<br/>1524085130 (Wed 18 Apr 2018 03:58:50 PM CDT): condor-procd-8.6.10-1.osg34.el7.x86_64<br/>1524085130 (Wed 18 Apr 2018 03:58:50 PM CDT): condor-python-8.6.10-1.osg34.el7.x86_64<br/>1524085131 (Wed 18 Apr 2018 03:58:51 PM CDT): condor-8.6.10-1.osg34.el7.x86_64<br/>1524085133 (Wed 18 Apr 2018 03:58:53 PM CDT): htcondor-ce-3.1.1-1.osg34.el7.noarch<br/>1524085133 (Wed 18 Apr 2018 03:58:53 PM CDT): htcondor-ce-client-3.1.1-1.osg34.el7.noarch<br/>1524085133 (Wed 18 Apr 2018 03:58:53 PM CDT): htcondor-ce-slurm-3.1.1-1.osg34.el7.noarch<br/></pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(12:04:12)</span> <b>andrew.melo:</b></span> @dwd I've noticed that on other nodes too. Some fraction of the time, I end up having to do a <tt>killall -u cvmfs -9</tt> to let yum continue, then a <tt>yum-complete-transaction</tt> to do the cleanup<br/>
<span style="color: #99a949"><span style="font-size: small">(12:04:51)</span> <b>dwd:</b></span> FNAL has seen a similar problem on an upgrade in the past.  I am trying to find the ticket but having trouble contacting the CMFS JIRA at the moment<br/>
<span style="color: #99a949"><span style="font-size: small">(12:09:36)</span> <b>dwd:</b></span> Ok the ticket is <a href="https://sft.its.cern.ch/jira/browse/CVM-1466">https://sft.its.cern.ch/jira/browse/CVM-1466</a> but currently the server appears to be only available inside the CERN network<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:09:52)</span> <b>andrew.melo:</b></span> I think (?) that if CVMFS is automounted, you don't want to reload it in the RPM post script. I'm having trouble diagnosing it (because FUSE acts weird when the usermode half borks out), but I think CVMFS/FUSE tries to wait till all the current filehandles expire before it'll close. If that's the case, it's rough because a job can be potentially running for days, the yum transaction gets held open, etc...<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:12:43)</span> <b>andrew.melo:</b></span> @dwd I love CERN-only infrastructure....<br/>
<span style="color: #99a949"><span style="font-size: small">(12:15:06)</span> <b>dwd:</b></span> CVMFS goes through a lot of effort to make itself upgradable while live.  It has a frontend process that holds all the file descriptors open, and an API that talks to a second backend process that does almost all of the work so it can be upgraded with the file descriptors still open.  So that’s not the problem.<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:15:28)</span> <b>andrew.melo:</b></span> Ah, I pulled the scriptlets out of the RPM which jogged my memory. I remember seeing this process tree get jammed up<br/><pre><br/>/usr/bin/cvmfs_config reload<br/></pre><br/>
<span style="color: #9e3997"><span style="font-size: small">(12:15:47)</span> <b>bbockelm:</b></span> fwiw - CVMFS doesn't wait until all current filehandles expire.  It does wait until the kernel dcache expires (60s).  So anything over 60s implies bug / something to investigate.<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:16:44)</span> <b>andrew.melo:</b></span> That's def the behavior I've seen. Let me try to reproduce it<br/>
<span style="color: #99a949"><span style="font-size: small">(12:17:01)</span> <b>dwd:</b></span> Please leave the broken machine in its current state if you can so it can be investigated<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:17:37)</span> <b>andrew.melo:</b></span> I will. This is the box I'm testing my C7 upgrades for, so it can be wedged (added bonus, it's on the public internet)<br/>
<span style="color: #99a949"><span style="font-size: small">(12:19:26)</span> <b>dwd:</b></span> Can you attach to a stuck cvmfs2 process and get a gdb stack backtrace?  A multi-threaded one (thread apply all backtrace).  Probably there are two cvmfs2 processes, we’d want to trace both.<br/>
<span style="color: #99a949"><span style="font-size: small">(12:20:58)</span> <b>dwd:</b></span> Also Jakob was asking for the output of the yum update command, if that can be retrieved.  We couldn’t get it at Fermilab<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:21:23)</span> <b>andrew.melo:</b></span> OK. Let me try and get it to trigger (and make sure it's for more than 60 secs). I screwed up and killed the processes before I posted here. I was getting some nice dmesg about processes getting stuck on VFS:<br/><pre><br/>[3535684.302407] INFO: task df:2427447 blocked for more than 120 seconds.<br/>[3535684.308597] "echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs" disables this message.<br/>[3535684.309997] df              D ffff880002bcbf40     0 2427447 2425349 0x00000084<br/>[3535684.311825] Call Trace:<br/>[3535684.312726]  [&lt;ffffffff816b40e9&gt;] schedule+0x29/0x70<br/>[3535684.313848]  [&lt;ffffffffc0427545&gt;] __fuse_request_send+0xf5/0x2e0 [fuse]<br/>[3535684.315224]  [&lt;ffffffff810b4fc0&gt;] ? wake_up_atomic_t+0x30/0x30<br/>[3535684.316446]  [&lt;ffffffffc0427742&gt;] fuse_request_send+0x12/0x20 [fuse]<br/>[3535684.317524]  [&lt;ffffffffc042caaa&gt;] fuse_do_getattr+0x10a/0x2d0 [fuse]<br/>[3535684.318573]  [&lt;ffffffffc042dbc5&gt;] fuse_update_attributes+0x75/0x80 [fuse]<br/>[3535684.319674]  [&lt;ffffffffc042dc13&gt;] fuse_getattr+0x43/0x50 [fuse]<br/>[3535684.320681]  [&lt;ffffffff8120acd9&gt;] vfs_getattr+0x49/0x80<br/>[3535684.321723]  [&lt;ffffffff8120ae05&gt;] vfs_fstatat+0x75/0xc0<br/>[3535684.322611]  [&lt;ffffffff8120b35e&gt;] SYSC_newstat+0x2e/0x60<br/>[3535684.323453]  [&lt;ffffffff81123386&gt;] ? __audit_syscall_exit+0x1e6/0x280<br/>[3535684.324420]  [&lt;ffffffff8120b63e&gt;] SyS_newstat+0xe/0x10<br/>[3535684.325236]  [&lt;ffffffff816c0715&gt;] system_call_fastpath+0x1c/0x21<br/>[root@ce3 tmp]# <br/></pre><br/>
<span style="color: #9e3997"><span style="font-size: small">(12:23:00)</span> <b>bbockelm:</b></span> Yeah - that's saying there's a kernel thread trying to respond to a fstat call from userspace which, in turn, is waiting on the fuse process to respond.<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:23:28)</span> <b>bbockelm:</b></span> So indeed it shows a symptom but you'll need to look at the <tt>cvmfs2</tt> process to guess why it isn't responding.<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:24:06)</span> <b>andrew.melo:</b></span> Right, I know that doesn't show the actual problem. But at the very least it's more than 60 secs, so I"m doing something right (wrong)<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:24:19)</span> <b>bbockelm:</b></span> yup, that confirms it.<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:27:19)</span> <b>andrew.melo:</b></span> @dwd While I'm trying to get this machine stuck, could you give me some pointers to the frontend/backend code? A naiive search for "fronted" and "backend" doesn't give me the goods<br/>
<span style="color: #99a949"><span style="font-size: small">(12:27:32)</span> <b>dwd:</b></span> We didn’t have vfs stack backtraces at Fermilab, so the problem might be different.  It would also help to try to get a “cvmfs_config bugreport” file.  It may hang, maybe even more than once, but then kill each hanging process so we can collect as much as possible.<br/>
<span style="color: #99a949"><span style="font-size: small">(12:27:55)</span> <b>dwd:</b></span> Do you mean the cvmfs source code that does it?  I actually don’t know offhand but I suppose I could find it.<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:37:40)</span> <b>andrew.melo:</b></span> heh, actually, just a downgrade got it stuck...<br/><pre><br/>[root@ce3 tmp]# yum downgrade cvmfs-2.4.2<br/>Loaded plugins: fastestmirror, rhnplugin<br/>This system is receiving updates from RHN Classic or Red Hat Satellite.<br/>Loading mirror speeds from cached hostfile<br/>Resolving Dependencies<br/>--&gt; Running transaction check<br/>---&gt; Package cvmfs.x86_64 0:2.4.2-1.osg34.el7 will be a downgrade<br/>---&gt; Package cvmfs.x86_64 0:2.4.4-1.osg34.el7 will be erased<br/>--&gt; Finished Dependency Resolution<br/>&lt;snip&gt;<br/>Running transaction<br/>  Installing : cvmfs-2.4.2-1.osg34.el7.x86_64                                                                                                                                                                         1/2 <br/></pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(12:44:39)</span> <b>andrew.melo:</b></span> <pre><br/>[root@ce3 ~]# ps aux | grep cvmfs<br/>cvmfs    2432748  0.0  0.0 706972  3756 ?        Sl   11:55   0:00 /usr/bin/cvmfs2 -o rw,fsname=cvmfs2,allow_other,grab_mountpoint,uid=992,gid=989 <a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a> /cvmfs/config-osg.opensciencegrid.org<br/>cvmfs    2432828  0.0  0.0 706956  3948 ?        Sl   11:55   0:00 /usr/bin/cvmfs2 -o rw,fsname=cvmfs2,allow_other,grab_mountpoint,uid=992,gid=989 <a href="http://cms.cern.ch">cms.cern.ch</a> /cvmfs/cms.cern.ch<br/>root     2440143  0.6  0.5 497804 82252 pts/1    S+   12:28   0:06 /usr/bin/python /usr/bin/yum downgrade cvmfs-2.4.2<br/>root     2440379  0.0  0.0  12276  2136 pts/1    S+   12:30   0:00 /bin/bash /usr/bin/cvmfs_config reload<br/>root     2440445  0.0  0.0  12168  1332 pts/1    S+   12:30   0:00 /bin/bash /usr/bin/cvmfs_config reload<br/>root     2440456  0.0  0.0  12168  1332 pts/1    S+   12:30   0:00 /bin/bash /usr/bin/cvmfs_config reload<br/>root     2440463  0.0  0.0  53304  2512 pts/1    S+   12:30   0:00 cvmfs2 __RELOAD__ /var/run/cvmfs/cvmfs.config-osg.opensciencegrid.org stop_and_go<br/>root     2440469  0.0  0.0  53304  2512 pts/1    S+   12:30   0:00 cvmfs2 __RELOAD__ /var/run/cvmfs/cvmfs.cms.cern.ch stop_and_go<br/>cvmfs    2440496  0.0  0.0 706956  1940 ?        Ss   12:30   0:00 /usr/bin/cvmfs2 -o rw,fsname=cvmfs2,allow_other,grab_mountpoint,uid=992,gid=989 <a href="http://cms.cern.ch">cms.cern.ch</a> /cvmfs/cms.cern.ch<br/>cvmfs    2440497  0.0  0.0 115252  1480 ?        S    12:30   0:00 /bin/sh<br/>cvmfs    2440498  0.0  0.0 115252   664 ?        S    12:30   0:00 /bin/sh<br/>cvmfs    2440499  0.0  0.0 115252   608 ?        S    12:30   0:00 /bin/sh<br/>cvmfs    2440500  0.0  0.0 107976   764 ?        S    12:30   0:00 df<br/>cvmfs    2440501  0.0  0.0 112664   968 ?        S    12:30   0:00 grep  /$<br/>cvmfs    2440502  0.0  0.0 113492   968 ?        S    12:30   0:00 awk { print $2 }<br/>root     2442062  0.0  0.0 112668   968 pts/3    S+   12:44   0:00 grep --color=auto cvmfs<br/>[root@ce3 ~]# <br/></pre><br/>
<span style="color: #99a949"><span style="font-size: small">(12:46:07)</span> <b>dwd:</b></span> Yes so if you look in the cvmfs code for __RELOAD__ you get to the right area of code.  In the Fermilab case, I touched /var/run/cvmfs/cvmfs.cms.cern.ch.paused and that made it proceed<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:53:22)</span> <b>andrew.melo:</b></span> So, is this something known?<br/>
<span style="color: #99a949"><span style="font-size: small">(12:53:47)</span> <b>dwd:</b></span> It was a known problem but the solution is not yet known<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:54:43)</span> <b>andrew.melo:</b></span> Hmm. It looks like GDB barfs trying to load, it's probably walking the FD table and getting a nice deadlock:<br/><pre><br/>[root@ce3 ~]# gdb -p 2440496<br/><br/>GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-100.el7_4.1<br/>Copyright (C) 2013 Free Software Foundation, Inc.<br/>License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;<br/>This is free software: you are free to change and redistribute it.<br/>There is NO WARRANTY, to the extent permitted by law.  Type "show copying"<br/>and "show warranty" for details.<br/>This GDB was configured as "x86_64-redhat-linux-gnu".<br/>For bug reporting instructions, please see:<br/>&lt;http://www.gnu.org/software/gdb/bugs/&gt;.<br/>Attaching to process 2440496<br/>thread apply all bt<br/><br/>^C<br/></pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(12:55:32)</span> <b>andrew.melo:</b></span> Do you want me to try harder to get a bt? I'm not sure of what's useful here if people are aware of this specific issue<br/>
<span style="color: #99a949"><span style="font-size: small">(12:57:16)</span> <b>dwd:</b></span> Try the other process instead, that’s probably the more important one.  We weren’t able to get enough debugging information from the Fermilab case.<br/>
<span style="color: #99a949"><span style="font-size: small">(12:58:24)</span> <b>dwd:</b></span> That was because by the time that Jakob looked closely at the info I had collected, he wanted more info but there were no more stuck machines.<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:59:22)</span> <b>andrew.melo:</b></span> The backtrace from <tt>2440469</tt>?<br/>
<span style="color: #99a949"><span style="font-size: small">(13:00:52)</span> <b>dwd:</b></span> Oh, no, not the __RELOAD__ cvmfs2, but the running ones 2432748 or 2432828<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:02:19)</span> <b>andrew.melo:</b></span> Boooo. I guess that binary is gone from the filesystem:<br/><pre><br/>/usr/bin/cvmfs2;5ade17b9 (deleted): No such file or directory.<br/>(gdb) thread apply all bt<br/><br/>Thread 1 (process 2432828):<br/>Python Exception &lt;class 'gdb.MemoryError'&gt; Cannot access memory at address 0x5040ea80: <br/>(gdb) <br/></pre><br/>
<span style="color: #99a949"><span style="font-size: small">(13:04:04)</span> <b>dwd:</b></span> That would be the old one I would think<br/>
<span style="color: #99a949"><span style="font-size: small">(13:04:14)</span> <b>dwd:</b></span> Do both have that problem?<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:04:16)</span> <b>andrew.melo:</b></span> Yeah<br/>
<span style="color: #99a949"><span style="font-size: small">(13:04:30)</span> <b>dwd:</b></span> I guess that means the old one hasn’t exited yet<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:04:51)</span> <b>andrew.melo:</b></span> I can do a gcore, but it complains about "Memory read failed for corefile section, blah blah", so I'm not sure if the core will actually be useful<br/>
<span style="color: #99a949"><span style="font-size: small">(13:10:40)</span> <b>dwd:</b></span> A gcore could be useful after you switch back to the other /usr/bin/cvmfs2 with the correct symbols, so yes please do that.   I was unfamiliar with gcore.  Then please make that cvmfs_config bugreport tarball (again, killing any processes it runs that get stuck, until it finishes) if you haven’t, and try touching /var/run/cvmfs/cvmfs.cms.cern.ch.paused to see if that makes this one proceed.  I think maybe after it proceeds we’ll see more useful info from the yum update; as it is now there’s nothing of interest.<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:16:31)</span> <b>andrew.melo:</b></span> I don't think it's going to resolve the symbols even if I replace the binary with the old one, the inode won't match (the 2nd half of <tt>/usr/bin/cvmfs2;5ade17b9</tt>)<br/>
<span style="color: #99a949"><span style="font-size: small">(13:17:11)</span> <b>dwd:</b></span> If you run gdb /usr/bin/cvmfs2 corefilename it should work<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:17:48)</span> <b>andrew.melo:</b></span> ah, right<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:18:38)</span> <b>andrew.melo:</b></span> let me try flipping this around with what you said above, then try to get it stuck outside of yum, so nothing is screwing with binaries in the background<br/>
<span style="color: #99a949"><span style="font-size: small">(13:20:10)</span> <b>dwd:</b></span> I’m not sure what you mean by that but if you also collect the info I asked, feel free to try other things too<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:23:51)</span> <b>andrew.melo:</b></span> I meant to run the pre/post-install scriptlets manually. I'm getting the core and the bugreport. I'll touch the paused to see if it continues<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:26:58)</span> <b>andrew.melo:</b></span> Boo, bugreport's hanging. Do you want me to try to touch the "paused" files?<br/>
<span style="color: #99a949"><span style="font-size: small">(13:55:39)</span> <b>dwd:</b></span> Please kill the processes in bugreport that are hanging so it completes first.<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:59:35)</span> <b>andrew.melo:</b></span> I don't know who to blow away that'l keep things OK to try the 2nd step<br/>
<span style="color: #99a949"><span style="font-size: small">(14:02:05)</span> <b>dwd:</b></span> Look at the process tree to find out which one under cvmfs_config bugreport is the lowest one, that’s the one that’s hanging.  If you can’t kill it, kill its parent<br/>
<span style="color: #99a949"><span style="font-size: small">(14:03:32)</span> <b>dwd:</b></span> pstree -p is helpful<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:04:31)</span> <b>andrew.melo:</b></span> Wait,what's in the bugreport? Is it just the config info? Could I just run that after I blow away the mount? The pstree doesn't have anything interesting beneath it, just awk, df, grep<br/>
<span style="color: #99a949"><span style="font-size: small">(14:05:30)</span> <b>dwd:</b></span> probably the df is hung.  The bugreport does also try to look at the current state of things so I think it’s useful to try to do it while it is in the stuck state, in hopes of collecting some useful info<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:05:54)</span> <b>andrew.melo:</b></span> It's unkillable, unfortunately<br/>
<span style="color: #99a949"><span style="font-size: small">(14:06:03)</span> <b>dwd:</b></span> then kill its parent<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:06:12)</span> <b>andrew.melo:</b></span> the parent is the bugreport itself<br/>
<span style="color: #99a949"><span style="font-size: small">(14:06:20)</span> <b>dwd:</b></span> You’re sure it isn’t a fork of it?<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:07:26)</span> <b>andrew.melo:</b></span> There was three copies. I killed the parent then grandparent and got something or another<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:07:54)</span> <b>andrew.melo:</b></span> Waiting for something else to unstick<br/>
<span style="color: #99a949"><span style="font-size: small">(14:08:13)</span> <b>dwd:</b></span> yes you might need to repeat a few times<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:13:37)</span> <b>andrew.melo:</b></span> Unfortunately, it then tries to do a df, and the only parent is the toplevel cvmfs_config itself<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:13:44)</span> <b>andrew.melo:</b></span> <tt>─sshd───bash───cvmfs_config───df</tt><br/>
<span style="color: #99a949"><span style="font-size: small">(14:14:41)</span> <b>dwd:</b></span> Before it creates the tarball?  I don’t recall ever seeing that.  Oh well, then I guess the only thing to do is to try to create the .paused file<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:16:20)</span> <b>andrew.melo:</b></span> Yeah, this s where it got:<br/><pre><br/>Gathering eval find /var/cache/cvmfs -maxdepth 1 -exec ls -lah \{\} \;<br/>Gathering cvmfs_config probe<br/>/usr/bin/cvmfs_config: line 1316: 2461170 Terminated              $cmd &gt;&gt; $out 2&gt; $err<br/>Gathering mount<br/>Gathering df -h<br/></pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(14:18:23)</span> <b>andrew.melo:</b></span> Hm. Sure that's the right name?<br/><pre><br/>[root@ce3 ~]# ls -l /var/run/cvmfs/<br/>total 0<br/>srw------- 1 cvmfs cvmfs  0 Apr 23 11:55 <a href="http://cvmfs.cms.cern.ch">cvmfs.cms.cern.ch</a><br/>-rw-r--r-- 1 cvmfs cvmfs  0 Apr 23 14:16 cvmfs.cms.cern.ch.paused<br/>srw------- 1 cvmfs cvmfs  0 Apr 23 11:54 <a href="http://cvmfs.config-osg.opensciencegrid.org">cvmfs.config-osg.opensciencegrid.org</a><br/>-rw-r--r-- 1 cvmfs cvmfs  0 Apr 23 14:16 cvmfs.config-osg.opensciencegrid.org.paused<br/>drwxr-xr-x 2 root  root  60 Apr 23 12:30 cvmfs.pause<br/></pre><br/>
<span style="color: #99a949"><span style="font-size: small">(14:18:40)</span> <b>dwd:</b></span> I think so.  Nothing happened?<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:19:08)</span> <b>andrew.melo:</b></span> Doesn't appear so<br/>
<span style="color: #99a949"><span style="font-size: small">(14:20:43)</span> <b>dwd:</b></span> Then it appears to be a different kind of stuck than I saw at Fermilab.  Can you give me a login on the machine?  Otherwise I can keep talking you through trying to find out what it is stuck on<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:20:56)</span> <b>andrew.melo:</b></span> yeah<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:20:59)</span> <b>andrew.melo:</b></span> on sec<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:21:01)</span> <b>andrew.melo:</b></span> *one sec<br/>
<span style="color: #99a949"><span style="font-size: small">(14:21:21)</span> <b>dwd:</b></span> I would need at least access to cvmfs user, maybe root<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:21:33)</span> <b>andrew.melo:</b></span> I'll just give you wheel<br/>
<span style="color: #43761b"><span style="font-size: small">(16:04:37)</span> <b>blin:</b></span> @sthapa @efajardo @dweitzel coming to office hours?<br/>
<span style="color: #5b89d5"><span style="font-size: small">(16:04:50)</span> <b>sthapa:</b></span> yes, give me a second<br/>
<span style="color: #c386df"><span style="font-size: small">(16:51:24)</span> <b>matyas:</b></span> is there anybody in the world that is running their own rsv gratia collector?<br/>
<span style="color: #5b89d5"><span style="font-size: small">(16:51:56)</span> <b>sthapa:</b></span> unl?<br/>
<span style="color: #235e5b"><span style="font-size: small">(17:02:06)</span> <b>dweitzel:</b></span> nope, not RSV gratia collector.<br/>
</body>
</html>
