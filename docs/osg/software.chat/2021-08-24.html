<!DOCTYPE html>
<html>
<head>
<title>Tue Aug 24, 2021 : #software (osg)</title>
</head>
<body>
<h3>Tue Aug 24, 2021 : #software (osg)</h3>
<span style="color: #a72f79"><span style="font-size: small">(08:42:24)</span> <b>andrew.melo:</b></span> What is supposed to clean up /var/lib/gratia/condorce_data ? It appears I have one that is growing without bounds<br/>
<span style="color: #43761b"><span style="font-size: small">(08:45:30)</span> <b>blin:</b></span> it's got history files in there, right?<br/>
<span style="color: #43761b"><span style="font-size: small">(08:45:43)</span> <b>blin:</b></span> what version of htcondor-ce/osg-ce?<br/>
<span style="color: #43761b"><span style="font-size: small">(08:51:53)</span> <b>blin:</b></span> there should be a schedd cron that runs<br/>
<span style="color: #43761b"><span style="font-size: small">(08:53:06)</span> <b>blin:</b></span> <tt>/usr/share/condor-ce/config.d/03-gratia-cleanup.conf</tt><br/>
<span style="color: #a72f79"><span style="font-size: small">(08:53:30)</span> <b>andrew.melo:</b></span> This is with the recent -upcoming<br/>
<span style="color: #a72f79"><span style="font-size: small">(08:53:47)</span> <b>andrew.melo:</b></span> Hmmm. not cron in the "vixie cron" sense, I assume?<br/>
<span style="color: #43761b"><span style="font-size: small">(08:54:15)</span> <b>blin:</b></span> if there are issues with the schedd cron, you'll see errors in <tt>/var/log/condor-ce/SchedLog*</tt><br/>
<span style="color: #a72f79"><span style="font-size: small">(08:54:35)</span> <b>andrew.melo:</b></span> I see a lot of things in the SchedLog :slightly_smiling_face:<br/>
<span style="color: #43761b"><span style="font-size: small">(08:54:37)</span> <b>blin:</b></span> yeah it's cron...but condor-ized<br/>
<span style="color: #43761b"><span style="font-size: small">(08:54:52)</span> <b>blin:</b></span> try <tt>grep GratiaCleanup /var/log/condor-ce/SchedLog*</tt><br/>
<span style="color: #43761b"><span style="font-size: small">(08:55:06)</span> <b>blin:</b></span> maybe with some <tt>-A</tt>  or <tt>-B</tt> options for context<br/>
<span style="color: #a72f79"><span style="font-size: small">(08:55:12)</span> <b>andrew.melo:</b></span> ?<br/><pre>08/23/21 15:41:52 CronJob: Deleting job 'GRATIA_CLEANUP' (/usr/share/condor-ce/gratia_cleanup.py), timer 12<br/>08/23/21 15:42:04    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf<br/>08/23/21 15:42:04 Logging per-job history files to: /var/lib/gratia/condorce_data<br/>08/23/21 15:42:04 CronJob: Initializing job 'GRATIA_CLEANUP' (/usr/share/condor-ce/gratia_cleanup.py)<br/>08/23/21 20:04:06 CronJob: Deleting job 'GRATIA_CLEANUP' (/usr/share/condor-ce/gratia_cleanup.py), timer 12<br/>08/23/21 20:04:14    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf<br/>08/23/21 20:04:14 Logging per-job history files to: /var/lib/gratia/condorce_data<br/>08/23/21 20:04:14 CronJob: Initializing job 'GRATIA_CLEANUP' (/usr/share/condor-ce/gratia_cleanup.py)</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(08:56:14)</span> <b>blin:</b></span> ...looks sane<br/>
<span style="color: #43761b"><span style="font-size: small">(08:56:24)</span> <b>blin:</b></span> what's the oldest file in there?<br/>
<span style="color: #a72f79"><span style="font-size: small">(08:58:33)</span> <b>andrew.melo:</b></span> Aug 17, but that's when we had to blow it away to free up space in /<br/>
<span style="color: #a72f79"><span style="font-size: small">(08:59:36)</span> <b>andrew.melo:</b></span> Is there one of these for every job that runs?<br/><pre>[meloam@ce5-vanderbilt condorce_data]$ find . -type f | wc -l<br/>105633</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(09:00:41)</span> <b>blin:</b></span> ah right, so we keep 31 days of ads (unfortunately we don't provide a config option to modify this)<br/>
<span style="color: #43761b"><span style="font-size: small">(09:00:46)</span> <b>blin:</b></span> however, gratia should be consuming these files<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:01:04)</span> <b>andrew.melo:</b></span> Is this just the fallback if gratia doens't fire and upload it somewhere?<br/>
<span style="color: #43761b"><span style="font-size: small">(09:01:45)</span> <b>blin:</b></span> yup, exactly<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:02:32)</span> <b>andrew.melo:</b></span> Who fires gratia?<br/>
<span style="color: #43761b"><span style="font-size: small">(09:02:34)</span> <b>blin:</b></span> so uhh <tt>/var/log/gratia/</tt> would be a good place to start and making sure the <tt>gratia-probes-cron</tt> is enabled and started<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:02:56)</span> <b>andrew.melo:</b></span> Not a good start..<br/><pre>[root@ce5-vanderbilt log]# systemctl status gratia-probes-cron<br/>● gratia-probes-cron.service - SYSV: Enable specified gratia probes to run via cron. based on fetch-crl-cron script (Steve Traylen &lt;steve.traylen@cern.ch&gt;)<br/>   Loaded: loaded (/etc/rc.d/init.d/gratia-probes-cron; bad; vendor preset: disabled)<br/>   Active: inactive (dead)<br/>     Docs: man:systemd-sysv-generator(8)</pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(09:03:16)</span> <b>andrew.melo:</b></span> <pre>Aug 24 09:03:03 <a href="http://ce5-vanderbilt.sites.opensciencegrid.org">ce5-vanderbilt.sites.opensciencegrid.org</a> gratia-probes-cron[2538603]: There are no enabled probes to start.</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(09:03:25)</span> <b>blin:</b></span> it's also worth checking if <tt>/etc/gratia/*/ProbeConfig</tt> is enabled for your batch system<br/>
<span style="color: #43761b"><span style="font-size: small">(09:04:18)</span> <b>blin:</b></span> <tt>osg-configure</tt> does this for you :slightly_smiling_face:<br/>
<span style="color: #43761b"><span style="font-size: small">(09:04:37)</span> <b>blin:</b></span> i imagine that if the probe isn't enabled it's also not configured. do you have an old copy laying around for the host?<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:05:36)</span> <b>andrew.melo:</b></span> I don't do osg-configure because it's a big bummer to try and get it into config management<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:05:55)</span> <b>andrew.melo:</b></span> but there is an /etc/gratia/slurm/ProbeConfig<br/>
<span style="color: #c386df"><span style="font-size: small">(09:06:59)</span> <b>matyas:</b></span> is it enabled?<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:10:09)</span> <b>andrew.melo:</b></span> Looks like no<br/>
<span style="color: #43761b"><span style="font-size: small">(09:12:23)</span> <b>blin:</b></span> you'll also need to change<br/><pre>ProbeName="generic"<br/>SiteName="Generic Site"</pre><br/>to something like<br/><pre>ProbeName="slurm:&lt;CE FQDN&gt;"<br/>SiteName="&lt;TOPOLOGY RESOURCE NAME&gt;"</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(09:12:42)</span> <b>blin:</b></span> you  have local users whose usage you don't want uploaded to GRACC, right?<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:12:51)</span> <b>andrew.melo:</b></span> Probably so<br/>
<span style="color: #43761b"><span style="font-size: small">(09:13:08)</span> <b>blin:</b></span> i think you want to set these to 1<br/><pre>    SuppressNoDNRecords="0"<br/>    SuppressGridLocalRecords="0"</pre><br/>but i always forget. <b>@edquist</b> should know<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:13:31)</span> <b>andrew.melo:</b></span> IT'd be nice if osg-configure had a "dry run" option or similar that you could have it dump everything into a different tree to diff against<br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(09:14:40)</span> <b>blin:</b></span> i think we have a ticket for this :disappointed:<br/>
<span style="color: #c386df"><span style="font-size: small">(09:21:17)</span> <b>matyas:</b></span> I think we closed it as 'never gonna happen' :disappointed:<br/>
<span style="color: #c386df"><span style="font-size: small">(09:23:19)</span> <b>matyas:</b></span> &gt; Mat Selmeci<br/>&gt; 2016. May 12. 13:32<br/>&gt; I guess it's time to admit I will never have time for this.<br/>
<span style="color: #c386df"><span style="font-size: small">(09:23:58)</span> <b>matyas:</b></span> &gt; Tim Cartwright<br/>&gt; 2016. May 13. 11:14<br/>&gt; Should this become important enough to actually do, we can make a fresh ticket.<br/>
<span style="color: #c386df"><span style="font-size: small">(09:24:52)</span> <b>matyas:</b></span> but yes I think this is a good idea so we should make a fresh ticket<br/>
<span style="color: #c386df"><span style="font-size: small">(11:39:29)</span> <b>matyas:</b></span> <a href="https://opensciencegrid.atlassian.net/browse/SOFTWARE-4783">https://opensciencegrid.atlassian.net/browse/SOFTWARE-4783</a><br/>(3.6 only, sorry Andrew)<br/>
</blockquote>
<span style="color: #16569E"><span style="font-size: small">(09:13:48)</span> <b>edquist:</b></span> mmm!<br/>
<span style="color: #c386df"><span style="font-size: small">(09:13:57)</span> <b>matyas:</b></span> agreed<br/>
<span style="color: #16569E"><span style="font-size: small">(09:14:09)</span> <b>edquist:</b></span> yeah maybe copy off the directories in question first<br/>
<span style="color: #c386df"><span style="font-size: small">(09:14:10)</span> <b>matyas:</b></span> you might also need to set the various Slurm* options<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:14:22)</span> <b>andrew.melo:</b></span> Yeah, I gotta go look up our slurmdb password and whatnot<br/>
<span style="color: #c386df"><span style="font-size: small">(09:14:44)</span> <b>matyas:</b></span> @blin should Andrew enable the htcondor-ce probe?<br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(09:16:15)</span> <b>blin:</b></span> eh, i'd rather we only tell folks to use that in 3.6 or when the batch system probes won't work for a site<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:22:03)</span> <b>andrew.melo:</b></span> We gotta wait for the entire HEP community to drop x509 before we can go to 3.6 :disappointed:<br/>
</blockquote>
<span style="color: #a72f79"><span style="font-size: small">(09:23:10)</span> <b>andrew.melo:</b></span> grrrrr, one sec, I'm trying to debug this wifi power strip (I use it for my fish tank to control all the stuffs), and I think I need to cycle my modem and my tank to get the SSIDs to line up right<br/>
<span style="color: #16569E"><span style="font-size: small">(09:26:25)</span> <b>edquist:</b></span> &gt; <tt>SuppressGridLocalRecords</tt><br/><br/>The comments in 50-gratia-gwms.conf say:<br/><br/><a href="https://github.com/opensciencegrid/gratia-probe/blob/master/condor/50-gratia-gwms.conf#L8-L17">https://github.com/opensciencegrid/gratia-probe/blob/master/condor/50-gratia-gwms.conf#L8-L17</a><br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(09:28:52)</span> <b>blin:</b></span> doesn't this config only get installed in the access point scenario?<br/>
</blockquote>
<span style="color: #235e5b"><span style="font-size: small">(09:27:42)</span> <b>dweitzel:</b></span> I think you want<br/><pre>SuppressNoDNRecords="1"<br/>SuppressGridLocalRecords="1"</pre><br/>
<span style="color: #235e5b"><span style="font-size: small">(09:28:31)</span> <b>dweitzel:</b></span> Oh, I just re-read Brian's comment, he already said this.<br/>
<span style="color: #16569E"><span style="font-size: small">(09:28:41)</span> <b>edquist:</b></span> yeah<br/>
<span style="color: #16569E"><span style="font-size: small">(09:29:09)</span> <b>edquist:</b></span> (i always forget when they are needed and have to look them up)<br/>
<span style="color: #43761b"><span style="font-size: small">(09:29:51)</span> <b>blin:</b></span> is it possible to add comments into the ProbeConfig or is it impossible because of the XML structure?<br/>
<span style="color: #235e5b"><span style="font-size: small">(09:30:09)</span> <b>dweitzel:</b></span> (Side tracking slightly) Does the HTCondor-CE probe only work in 3.6?<br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(09:31:28)</span> <b>blin:</b></span> it works in 3.6 but we don't have documentation or anything for it<br/>
<span style="color: #235e5b"><span style="font-size: small">(09:31:42)</span> <b>dweitzel:</b></span> Does it work in 3.5?<br/>
<span style="color: #43761b"><span style="font-size: small">(09:31:58)</span> <b>blin:</b></span> er sorry, yeah it works in 3.5<br/>
<span style="color: #43761b"><span style="font-size: small">(09:32:06)</span> <b>blin:</b></span> we don't have any documentation or osg-configure stuff for it is the problem<br/>
<span style="color: #235e5b"><span style="font-size: small">(09:33:21)</span> <b>dweitzel:</b></span> So why are we not suggesting the HTCondor-CE probe to Andrew?<br/>
<span style="color: #c386df"><span style="font-size: small">(09:39:53)</span> <b>matyas:</b></span> we have osg-configure stuff for it<br/>
<span style="color: #235e5b"><span style="font-size: small">(09:42:13)</span> <b>dweitzel:</b></span> In 3.5?<br/>
<span style="color: #c386df"><span style="font-size: small">(09:42:18)</span> <b>matyas:</b></span> yeah<br/>
<span style="color: #235e5b"><span style="font-size: small">(09:42:39)</span> <b>dweitzel:</b></span> I hate the slurm probe connecting to the MySQL db with a passion.<br/>
<span style="color: #c386df"><span style="font-size: small">(11:47:29)</span> <b>matyas:</b></span> my bad we don't have osg-configure stuff for htcondor-ce for 3.5<br/>
<span style="color: #c386df"><span style="font-size: small">(11:47:34)</span> <b>matyas:</b></span> the probe, that is<br/>
</blockquote>
<span style="color: #16569E"><span style="font-size: small">(09:30:30)</span> <b>edquist:</b></span> you can add xml comments<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:30:44)</span> <b>andrew.melo:</b></span> the probe config is a single tag with multiiple attributes, so no comments allowed within it<br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(09:30:58)</span> <b>blin:</b></span> yeah, that's what i feared<br/>
<span style="color: #c386df"><span style="font-size: small">(09:31:24)</span> <b>matyas:</b></span> can you add <tt>comment1="..." comment2="..."</tt> attributes?<br/>
<span style="color: #a72f79"><span style="font-size: small">(09:31:38)</span> <b>andrew.melo:</b></span> yeah, that'd work<br/>
</blockquote>
<span style="color: #16569E"><span style="font-size: small">(09:31:06)</span> <b>edquist:</b></span> <tt>&lt;!-- comment here --&gt;</tt><br/>
<span style="color: #16569E"><span style="font-size: small">(09:31:22)</span> <b>edquist:</b></span> also,<br/>
<span style="color: #16569E"><span style="font-size: small">(09:31:36)</span> <b>edquist:</b></span> the old convention was,<br/>
<span style="color: #16569E"><span style="font-size: small">(09:31:42)</span> <b>edquist:</b></span> to make up comment attrs<br/>
<span style="color: #16569E"><span style="font-size: small">(09:32:38)</span> <b>edquist:</b></span> <pre>     Comments28="Number of records to be sent per envelope. Consider setting higher (up to 200)."</pre><br/>
<span style="color: #16569E"><span style="font-size: small">(09:33:55)</span> <b>edquist:</b></span> i don't think it breaks anything to add extra attrs to the top level xml tag, so extra ones can be used as comments<br/>
<span style="color: #674b1b"><span style="font-size: small">(09:44:26)</span> <b>showmic:</b></span> Just out of curiosity, are you trying to solve an issue with respect to a ticket in FD? If yes, may I have the link for that ticket?<br/>
<blockquote>
<span style="color: #235e5b"><span style="font-size: small">(09:48:59)</span> <b>dweitzel:</b></span> Nope, no ticket.  Everything is just in this slack.<br/>
</blockquote>
<span style="color: #235e5b"><span style="font-size: small">(12:19:19)</span> <b>dweitzel:</b></span> Probably heard this before, but just got a request in a ticket for a system admin style training.  This one was specifically for XRootD.<br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(12:25:34)</span> <b>blin:</b></span> Xcache, door, or SE?<br/>
<span style="color: #235e5b"><span style="font-size: small">(12:27:10)</span> <b>dweitzel:</b></span> Door.  It's a t3, so xrootd standalone ended up working for them.<br/>
<span style="color: #43761b"><span style="font-size: small">(12:55:11)</span> <b>blin:</b></span> gotcha. this is just generally, right? not specific to the token transition?<br/>
<span style="color: #235e5b"><span style="font-size: small">(13:52:25)</span> <b>dweitzel:</b></span> Right. Generally<br/>
</blockquote>
<span style="color: #a72f79"><span style="font-size: small">(14:34:39)</span> <b>andrew.melo:</b></span> uh, is it bad to have two condor_schedd's running on the CE?<br/><pre>[root@ce5-vanderbilt slurm]# ps aux | grep condor<br/>condor   2715352  0.0  0.0  86248  5720 ?        Ss   13:06   0:00 condor_master<br/>root     2715400  0.0  0.0  24388  5048 ?        S    13:06   0:01 condor_procd -A /var/lock/condor-ce/procd_pipe -L /var/log/condor-ce/ProcLog -R 1000000 -S 60 -C 989<br/>condor   2715401  0.1  0.0  61716  6160 ?        Ss   13:06   0:05 condor_shared_port<br/>condor   2715403  6.2  5.7 1203816 937224 ?      Ss   13:06   5:26 condor_collector<br/>cmspilot 2715405  3.8  1.4 362872 227996 ?       Rs   13:06   3:23 condor_schedd<br/>cmspilot 2715406  1.7  2.4 469240 390532 ?       Ss   13:06   1:29 condor_job_router<br/>cmspilot 2733213  1.1  0.3 170724 55080 ?        S    13:24   0:48 condor_gridmanager -f -C (Owner=?="cmspilot"&amp;&amp;JobUniverse==9) -o cmspilot -S /tmp/condor_g_scratch.0x55c4e999b6b0.2715405<br/>lscpilot 2733214  0.0  0.0 126572 10836 ?        S    13:24   0:03 condor_gridmanager -f -C (Owner=?="lscpilot"&amp;&amp;JobUniverse==9) -o lscpilot -S /tmp/condor_g_scratch.0x55c4e9648f40.2715405<br/>condor   2809721 62.6  1.3 359288 215592 ?       R    14:20   8:46 condor_schedd<br/>condor   2829671  1.4  0.0      0     0 ?        Z    14:33   0:00 [condor_schedd] &lt;defunct&gt;</pre><br/>
<span style="color: #c386df"><span style="font-size: small">(14:35:31)</span> <b>matyas:</b></span> they're owned by different users so I don't think they'll conflict<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:36:13)</span> <b>andrew.melo:</b></span> trying to see why this CE is blinking out. condor_ce_q is unhappy<br/>
<span style="color: #43761b"><span style="font-size: small">(14:36:18)</span> <b>blin:</b></span> CEs + condor batch normally run two different schedd's<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:36:25)</span> <b>andrew.melo:</b></span> <pre>[root@ce5-vanderbilt slurm]# condor_ce_q<br/><br/>-- Failed to fetch ads from: &lt;129.59.197.77:26663?alias=ce5-vanderbilt.sites.opensciencegrid.org&gt; : <a href="http://ce5-vanderbilt.sites.opensciencegrid.org">ce5-vanderbilt.sites.opensciencegrid.org</a><br/>SECMAN:2007:Failed to end classad message.</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(14:36:26)</span> <b>blin:</b></span> but yeah, it really depends on the configs<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:36:28)</span> <b>andrew.melo:</b></span> I'm a slurm batch!<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:37:09)</span> <b>andrew.melo:</b></span> 2715405 is the pid binding 26663<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:37:44)</span> <b>andrew.melo:</b></span> why is he sad, he's got plenty of time!<br/>
<span style="color: #43761b"><span style="font-size: small">(14:37:47)</span> <b>blin:</b></span> so what's with the two schedd's then?<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:38:12)</span> <b>andrew.melo:</b></span> I was hoping you could tell me!<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:38:51)</span> <b>andrew.melo:</b></span> and the cmspilot got his own jobrouter?<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:39:43)</span> <b>andrew.melo:</b></span> and now the other schedd is gone<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:40:06)</span> <b>andrew.melo:</b></span> and now it's back?<br/><pre>condor   2715352  0.0  0.0  86248  5720 ?        Ss   13:06   0:00 condor_master<br/>root     2715400  0.0  0.0  24388  5048 ?        S    13:06   0:01 condor_procd -A /var/lock/condor-ce/procd_pipe -L /var/log/condor-ce/ProcLog -R 1000000 -S 60 -C 989<br/>condor   2715401  0.1  0.0  61716  6160 ?        Ss   13:06   0:06 condor_shared_port<br/>condor   2715403  6.3  5.8 1212488 945616 ?      Ss   13:06   5:53 condor_collector<br/>cmspilot 2715405  4.0  1.4 363268 228364 ?       Rs   13:06   3:46 condor_schedd<br/>condor   2715406  1.6  2.4 470420 391796 ?       Ss   13:06   1:32 condor_job_router<br/>cmspilot 2733213  1.1  0.3 170892 55080 ?        S    13:24   0:52 condor_gridmanager -f -C (Owner=?="cmspilot"&amp;&amp;JobUniverse==9) -o cmspilot -S /tmp/condor_g_scratch.0x55c4e999b6b0.2715405<br/>lscpilot 2733214  0.0  0.0 126572 10836 ?        S    13:24   0:04 condor_gridmanager -f -C (Owner=?="lscpilot"&amp;&amp;JobUniverse==9) -o lscpilot -S /tmp/condor_g_scratch.0x55c4e9648f40.2715405<br/>lcgadmin 2834335  0.0  0.0 125088  9328 ?        S    14:37   0:00 condor_gridmanager -f -C (Owner=?="lcgadmin"&amp;&amp;JobUniverse==9) -o lcgadmin -S /tmp/condor_g_scratch.0x55c4ea8e3db0.2715405<br/>condor   2836688  6.1  1.3 363004 219424 ?       S    14:39   0:00 condor_schedd<br/>condor   2837193  4.0  0.0      0     0 ?        Z    14:39   0:00 [condor_schedd] &lt;defunct&gt;<br/>root     2837195  0.0  0.0 112812   944 pts/0    R+   14:39   0:00 grep --color=auto condor</pre><br/><br/>
<span style="color: #43761b"><span style="font-size: small">(14:40:27)</span> <b>blin:</b></span> what's pid <tt>228364</tt>?<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:40:55)</span> <b>andrew.melo:</b></span> not enough digits<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:41:23)</span> <b>andrew.melo:</b></span> I think that's the ram in a process<br/><pre>[root@ce5-vanderbilt slurm]# ps aux | grep 228364<br/>cmspilot 2715405  4.0  1.4 363268 228364 ?       Rs   13:06   3:48 condor_schedd</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(14:42:11)</span> <b>blin:</b></span> oh lol, so what's the PPID of that schedd?<br/>
<span style="color: #43761b"><span style="font-size: small">(14:42:30)</span> <b>blin:</b></span> if it's the same as the <tt>condor_schedd</tt> running as the <tt>condor</tt> user, it's probably somethign really weird in your CE config<br/>
<span style="color: #43761b"><span style="font-size: small">(14:42:43)</span> <b>blin:</b></span> if not, then it's another <tt>condor_master</tt> starting it up from somewhere mysterious<br/>
<span style="color: #9e3997"><span style="font-size: small">(14:53:18)</span> <b>bbockelm:</b></span> <tt>condor_schedd</tt> will fork/exec to do various work.  Note one of those had 0 CPU time and just launched.  I bet you caught it post-fork/pre-exec.<br/>
<span style="color: #9e3997"><span style="font-size: small">(14:53:30)</span> <b>bbockelm:</b></span> If you do <tt>ps faux</tt>, I bet you'd see one schedd be the child of the other.<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:56:48)</span> <b>andrew.melo:</b></span> I'm kinda surprised that the "parent' is running as cmspilot<br/>
<span style="color: #a72f79"><span style="font-size: small">(15:24:58)</span> <b>andrew.melo:</b></span> What config val tells the master what user to start the subprocesses as?<br/>
<span style="color: #43761b"><span style="font-size: small">(15:28:20)</span> <b>blin:</b></span> i think direct children are always either root or condor, depending on the daemon ¯\_(ツ)_/¯<br/>
<span style="color: #a72f79"><span style="font-size: small">(15:29:12)</span> <b>andrew.melo:</b></span> I see the following on ce6...<br/><pre>$ ps aux | grep condor<br/>lscpilot  230960  1.0  0.0 126204  9080 ?        S    15:28   0:00 condor_gridmanager -f -C (Owner=?="lscpilot"&amp;&amp;JobUniverse==9) -o lscpilot -S /tmp/condor_g_scratch.0x56061f343730.2345081<br/>condor    230994 13.0  0.8 274020 133760 ?       S    15:28   0:00 condor_schedd -f<br/>condor    231024  1.0  0.8 274020 131532 ?       S    15:28   0:00 condor_schedd -f<br/>cmspilot  231045  0.0  0.8 274020 133460 ?       S    15:28   0:00 condor_schedd -f<br/>meloam    231073  0.0  0.0 112812   940 pts/0    S+   15:28   0:00 grep --color=auto condor<br/>condor   2345005  0.0  0.0 136072  6824 ?        Ss   Aug17   0:08 condor_master<br/>root     2345064  0.0  0.0  26880  5536 ?        S    Aug17   2:08 condor_procd -A /var/lock/condor-ce/procd_pipe -L /var/log/condor-ce/ProcLog -R 1000000 -S 60 -C 990<br/>condor   2345065  0.3  0.0 113676  6992 ?        Ss   Aug17  33:22 condor_shared_port -f<br/>condor   2345070  0.1  0.1 265404 21896 ?        Ss   Aug17  18:13 condor_collector -f<br/>condor   2345081  5.9  0.8 274020 139944 ?       Ss   Aug17 623:41 condor_schedd -f<br/>condor   2345082  3.1  0.7 256420 127244 ?       Ss   Aug17 325:49 condor_job_router -f</pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(15:29:21)</span> <b>andrew.melo:</b></span> so it dtarted a schedd as the right user when the service started<br/>
<span style="color: #43761b"><span style="font-size: small">(15:29:45)</span> <b>blin:</b></span> yeah the schedd fork/execed more schedd's + the gridmanager<br/>
<span style="color: #a72f79"><span style="font-size: small">(15:29:55)</span> <b>andrew.melo:</b></span> but ce5 lost the parent owned by condor<br/>
<span style="color: #a72f79"><span style="font-size: small">(15:30:00)</span> <b>andrew.melo:</b></span> so maybe it forked and then died?<br/>
<span style="color: #a72f79"><span style="font-size: small">(15:30:26)</span> <b>andrew.melo:</b></span> leaving the baby around?<br/>
<span style="color: #43761b"><span style="font-size: small">(15:30:31)</span> <b>blin:</b></span> so there's no <tt>condor_master</tt>? what does the <tt>condor-ce</tt> service say? there may also be things in <tt>/var/log/condor-ce/MasterLog</tt><br/>
<span style="color: #a72f79"><span style="font-size: small">(15:30:35)</span> <b>andrew.melo:</b></span> I guess I should say that ce5 is the one from upcoming<br/>
<span style="color: #a72f79"><span style="font-size: small">(15:32:27)</span> <b>andrew.melo:</b></span> alright, I stopped the services, blew away the logs then restarted them. We see that it runs okay for a few handful of hours then barfs<br/>
<span style="color: #43761b"><span style="font-size: small">(15:33:01)</span> <b>blin:</b></span> what version of condor?<br/>
<span style="color: #43761b"><span style="font-size: small">(15:33:20)</span> <b>blin:</b></span> <tt>condor_ce_status -any</tt> would be helpful too to see if you can reach the collector<br/>
<span style="color: #43761b"><span style="font-size: small">(15:33:33)</span> <b>blin:</b></span> we should probably take this to a ticket (<a href="mailto:help@opensciencegrid.org">help@opensciencegrid.org</a>)<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:36:33)</span> <b>andrew.melo:</b></span> Unrelated .. I'm also seeing that old jobs aren't moving from completed to removed<br/><pre>Total for query: 9260 jobs; 5583 completed, 4 removed, 498 idle, 3172 running, 3 held, 0 suspended </pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(16:36:58)</span> <b>andrew.melo:</b></span> let me wait for it to fail then I'll try and get more debug info out of you<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:37:15)</span> <b>andrew.melo:</b></span> <pre>[root@ce5-vanderbilt ~]# condor_q -version<br/>$CondorVersion: 9.0.4 Jul 29 2021 PackageID: 9.0.4-1 $<br/>$CondorPlatform: X86_64-CentOS_7.9 $</pre><br/>
<span style="color: #c386df"><span style="font-size: small">(16:38:06)</span> <b>matyas:</b></span> do they have <tt>Leave_In_Queue</tt> set to anything?<br/>
<span style="color: #c386df"><span style="font-size: small">(16:38:53)</span> <b>matyas:</b></span> sorry, <tt>LeaveJobInQueue</tt><br/>
<span style="color: #c386df"><span style="font-size: small">(16:39:55)</span> <b>matyas:</b></span> or do they have <tt>OnExitRemove</tt> not <tt>true</tt>?<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:40:15)</span> <b>andrew.melo:</b></span> <pre>[root@ce5-vanderbilt ~]# condor_ce_q -long 4140535.0 | grep -e '^Leave' -e 'OnExit'<br/>LeaveJobInQueue = JobStatus == 4</pre><br/>
<span style="color: #c386df"><span style="font-size: small">(16:40:31)</span> <b>matyas:</b></span> yep<br/>
<span style="color: #c386df"><span style="font-size: small">(16:40:39)</span> <b>matyas:</b></span> 4 is "completed"<br/>
<span style="color: #c386df"><span style="font-size: small">(16:40:51)</span> <b>matyas:</b></span> so... this person's job will be left in the queue if they complete<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:40:59)</span> <b>andrew.melo:</b></span> That job is from the factory<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:41:13)</span> <b>andrew.melo:</b></span> I should say, this is a CE, so every job is from the factory<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:41:27)</span> <b>andrew.melo:</b></span> I would like to have it go away<br/>
<span style="color: #c386df"><span style="font-size: small">(16:43:40)</span> <b>matyas:</b></span> I guess the factory is supposed to remove them? My pilots have the same attrib<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:45:00)</span> <b>andrew.melo:</b></span> well, I'm trying to bisect down the difference between these two hosts<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:46:25)</span> <b>andrew.melo:</b></span> so interestingly enough, the new condor_schedd after restarting is owned by condor<br/>
<span style="color: #9e3997"><span style="font-size: small">(16:47:12)</span> <b>bbockelm:</b></span> &gt;  I'm kinda surprised that the "parent' is running as cmspilot<br/>@andrew.melo - recall that <tt>ps</tt> shows the effective UID and not the "real" UID.  HTCondor will set the euid to a particular user to read/write files as them and then switch back to eUID condor at rest.<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:47:54)</span> <b>andrew.melo:</b></span> Iguess I should look at /proc to see what the UID is when I see it next, but I watched "watch" for an hour and it was always cmspilot<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:48:05)</span> <b>andrew.melo:</b></span> and I couldn't do condor_ce_q when that was happening<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:49:47)</span> <b>andrew.melo:</b></span> Is this relevant?<br/><pre>08/24/21 16:49:27 Number of Active Workers 0<br/>08/24/21 16:49:29 Can't find address for startd <a href="http://ce5-vanderbilt.sites.opensciencegrid.org">ce5-vanderbilt.sites.opensciencegrid.org</a><br/>08/24/21 16:49:29 Can't find address for negotiator <br/>08/24/21 16:49:29 Failed to send RESCHEDULE to unknown daemon: <br/>08/24/21 16:49:32 (cid:12179) Command=QMGMT_WRITE_CMD, peer=&lt;129.59.197.77:24695&gt;</pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(16:49:57)</span> <b>andrew.melo:</b></span> (from the schedd log)<br/>
<span style="color: #43761b"><span style="font-size: small">(16:54:19)</span> <b>blin:</b></span> the negotiator message is expected. i don't think i've seen a startd message before. there definitely shouldn't be any startds (<tt>condor_ce_config_val DAEMON_LIST | grep STARTD</tt> should be empty)<br/>
<span style="color: #43761b"><span style="font-size: small">(16:54:48)</span> <b>blin:</b></span> <tt>_condor_TOOL_DEBUG="D_CAT D_ALWAYS:2" condor_ce_q -debug</tt> should give you some more helpful logging<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:55:17)</span> <b>andrew.melo:</b></span> that config is empty<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:55:59)</span> <b>andrew.melo:</b></span> <pre>[root@ce5-vanderbilt ~]# _condor_TOOL_DEBUG="D_CAT D_ALWAYS:2" condor_ce_q -debug<br/>08/24/21 16:55:23 (D_ALWAYS:2) Result of reading /etc/issue:  \S<br/> <br/>08/24/21 16:55:23 (D_ALWAYS:2) Result of reading /etc/redhat-release:  CentOS Linux release 7.9.2009 (Core)<br/> <br/>08/24/21 16:55:23 (D_ALWAYS:2) Using IDs: 2 processors, 2 CPUs, 0 HTs<br/>08/24/21 16:55:23 (D_ALWAYS:2) Enumerating interfaces: lo 127.0.0.1 up<br/>08/24/21 16:55:23 (D_ALWAYS:2) Enumerating interfaces: int0 10.0.64.102 up<br/>08/24/21 16:55:23 (D_ALWAYS:2) Enumerating interfaces: eth1 129.59.197.77 up<br/>08/24/21 16:55:23 (D_ALWAYS:2) Enumerating interfaces: lo ::1 up<br/>08/24/21 16:55:23 (D_ALWAYS:2) Enumerating interfaces: int0 fe80::5054:ff:fe1c:19dd up<br/>08/24/21 16:55:23 (D_ALWAYS:2) Enumerating interfaces: eth1 fe80::e493:15ff:fea3:ac1e up<br/>08/24/21 16:55:23 (D_ALWAYS:2) Will use TCP to update collector <a href="http://ce5-vanderbilt.sites.opensciencegrid.org">ce5-vanderbilt.sites.opensciencegrid.org</a> &lt;129.59.197.77:9619?alias=ce5-vanderbilt.sites.opensciencegrid.org&gt;<br/>08/24/21 16:55:43 (D_ALWAYS) condor_read(): timeout reading 5 bytes from schedd at &lt;129.59.197.77:2368&gt;.<br/>08/24/21 16:55:43 (D_ALWAYS) IO: Failed to read packet header<br/>08/24/21 16:55:43 (D_ALWAYS:2) FAILED to get number of expressions.<br/>08/24/21 16:55:43 (D_ALWAYS) SECMAN: no classad from server, failing<br/><br/>-- Failed to fetch ads from: &lt;129.59.197.77:2368?alias=ce5-vanderbilt.sites.opensciencegrid.org&gt; : <a href="http://ce5-vanderbilt.sites.opensciencegrid.org">ce5-vanderbilt.sites.opensciencegrid.org</a><br/>SECMAN:2007:Failed to end classad message.</pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(16:56:35)</span> <b>andrew.melo:</b></span> <pre>[root@ce5-vanderbilt ~]# route -n<br/>Kernel IP routing table<br/>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface<br/>0.0.0.0         129.59.197.1    0.0.0.0         UG    0      0        0 eth1<br/>0.0.0.0         10.0.64.1       0.0.0.0         UG    999    0        0 int0<br/>10.0.0.0        10.0.64.1       255.255.0.0     UG    0      0        0 int0<br/>10.0.64.0       0.0.0.0         255.255.252.0   U     0      0        0 int0<br/>129.59.197.0    0.0.0.0         255.255.255.0   U     0      0        0 eth1<br/>169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 int0<br/>169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(16:56:50)</span> <b>blin:</b></span> <tt>condor_ce_status -any</tt>?<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:57:17)</span> <b>andrew.melo:</b></span> very long. what do you want out of it?<br/>
<span style="color: #43761b"><span style="font-size: small">(16:57:38)</span> <b>blin:</b></span> how about <tt>condor_ce_status -sched</tt>  instead?<br/>
<span style="color: #a72f79"><span style="font-size: small">(16:58:29)</span> <b>andrew.melo:</b></span> <pre>Name               Resource           Batch    CEVer CondorVer Uptime       Resource                                          <br/><br/>ce5-vanderbilt.sit undefined          undefine 5.1.1 9.0.4       0+01:27:51 condor <a href="http://ce5-vanderbilt.sites.opensciencegrid.org">ce5-vanderbilt.sites.opensciencegrid.org</a> ce<br/><br/>                TotalRunningJobs      TotalIdleJobs      TotalHeldJobs<br/><br/>              <br/>         Total              3293                486                  3<br/>[root@ce5-vanderbilt ~]# </pre><br/>
<span style="color: #43761b"><span style="font-size: small">(17:03:53)</span> <b>blin:</b></span> do you see any corresponding messages in <tt>/var/log/condor-ce/CollectorLog</tt> when running <tt>condor_ce_q</tt><br/>
<span style="color: #43761b"><span style="font-size: small">(17:03:55)</span> <b>blin:</b></span> (or the SchedLog)<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:23:50)</span> <b>andrew.melo:</b></span> <pre>[root@ce5-vanderbilt ~]# tail -f /var/log/condor-ce/CollectorLog | grep -v -e 'Job start' -e 'Job stop'<br/>08/24/21 17:23:34 Python exception occurred when invoking update function: (Another exception occurred while generating a traceback)<br/>08/24/21 17:23:34 Python exception occurred when invoking update function: (Another exception occurred while generating a traceback)<br/>08/24/21 17:23:34 Python exception occurred when invoking update function: (Another exception occurred while generating a traceback)<br/>08/24/21 17:23:35 Python exception occurred when invoking update function: (Another exception occurred while generating a traceback)</pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(17:24:39)</span> <b>andrew.melo:</b></span> appears to be nothing relevant in schedlog<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:26:25)</span> <b>andrew.melo:</b></span> how about this?<br/><pre>08/24/21 17:24:51 condor_write(): Socket closed when trying to write 169 bytes to &lt;188.184.99.97:28790&gt;, fd is 31<br/>08/24/21 17:24:51 Buf::write(): condor_write() failed<br/>08/24/21 17:24:51 (cid:17746) actOnJobs: couldn't send results to client: aborting<br/>08/24/21 17:24:51 condor_write(): Socket closed when trying to write 45 bytes to &lt;129.59.197.77:30503&gt;, fd is 18<br/>08/24/21 17:24:51 Buf::write(): condor_write() failed<br/>08/24/21 17:24:51 condor_write(): Socket closed when trying to write 45 bytes to &lt;129.59.197.77:6117&gt;, fd is 18<br/>08/24/21 17:24:51 Buf::write(): condor_write() failed<br/>08/24/21 17:24:51 condor_write(): Socket closed when trying to write 45 bytes to &lt;129.59.197.77:26746&gt;, fd is 18<br/>08/24/21 17:24:51 Buf::write(): condor_write() failed<br/>08/24/21 17:24:51 condor_write(): Socket closed when trying to write 45 bytes to &lt;129.59.197.77:11686&gt;, fd is 18<br/>08/24/21 17:24:51 Buf::write(): condor_write() failed<br/>08/24/21 17:24:51 condor_write(): Socket closed when trying to write 45 bytes to &lt;129.59.197.77:30136&gt;, fd is 18<br/>08/24/21 17:24:51 Buf::write(): condor_write() failed<br/>08/24/21 17:24:51 condor_write(): Socket closed when trying to write 45 bytes to &lt;129.59.197.77:22598&gt;, fd is 18<br/>08/24/21 17:24:51 Buf::write(): condor_write() failed<br/>08/24/21 17:24:51 condor_write(): Socket closed when trying to write 13 bytes to &lt;169.228.38.43:23874&gt;, fd is 27<br/>08/24/21 17:24:51 Buf::write(): condor_write() failed<br/>08/24/21 17:24:51 relisock_gsi_get (read from socket) failure<br/>08/24/21 17:24:51 Condor GSI authentication failure<br/>    globus_gss_assist token :-1: read failure: Operation not permitted<br/><br/>08/24/21 17:24:51 (cid:17683) Command=QMGMT_WRITE_CMD, peer=&lt;169.228.38.43:23874&gt;<br/>08/24/21 17:24:51 (cid:17683) Authentication Failed, MethodsTried=GSI<br/>08/24/21 17:24:51 DC_AUTHENTICATE: authentication of &lt;169.228.38.43:23874&gt; did not result in a valid mapped user name, which is required for this command (1112 QMGMT_WRITE_CMD), so aborting.<br/>08/24/21 17:24:51 DC_AUTHENTICATE: reason for authentication failure: AUTHENTICATE:1006:exceeded 1629843819 deadline during authentication|GSI:5004:Failed to authenticate.  Globus is reporting error (17367040:0)<br/>08/24/21 17:24:51 condor_write(): Socket closed when trying to write 13 bytes to &lt;188.184.104.127:33755&gt;, fd is 30<br/>08/24/21 17:24:51 Buf::write()</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(17:28:13)</span> <b>blin:</b></span> :eyes:<br/>
<span style="color: #43761b"><span style="font-size: small">(17:28:49)</span> <b>blin:</b></span> what's your <tt>/etc/condor-ce/condor_mapfile</tt> and <tt>/etc/condor-ce/mapfiles.d/</tt>  look like?<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:29:09)</span> <b>andrew.melo:</b></span> I should say tha tI never got the .rpmnew versions when I ugraded<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:29:15)</span> <b>andrew.melo:</b></span> upgraded<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:29:43)</span> <b>andrew.melo:</b></span> all the stock<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:29:54)</span> <b>andrew.melo:</b></span> <pre>[root@ce5-vanderbilt ~]# cat /etc/condor-ce/condor_mapfile /etc/condor-ce/mapfiles.d/*<br/>###############################################################################<br/>#<br/># HTCondor-CE authentication mapfile<br/>#<br/># <a href="https://htcondor.readthedocs.io/en/v8_9_11/admin-manual/security.html#the-unified-map-file-for-authentication">https://htcondor.readthedocs.io/en/v8_9_11/admin-manual/security.html#the-unified-map-file-for-authentication</a><br/>#<br/># DO NOT EDIT THIS FILE!  It will be overwritten upon RPM upgrade.<br/># If you wish to make changes to the HTCondor-CE mappings, create files<br/># in /etc/condor-ce/mapfiles.d containing your changes.<br/>#<br/>###############################################################################<br/><br/># Place local authentication mapping customizations<br/># in /etc/condor-ce/mapfiles.d<br/>@include /etc/condor-ce/mapfiles.d/<br/><br/># Default mappings - DO NOT EDIT!<br/>@include /usr/share/condor-ce/mapfiles.d/<br/>###############################################################################<br/>#<br/># HTCondor-CE manual GSI/VOMS authentication mappings<br/>#<br/># This file will NOT be overwritten upon RPM upgrade.<br/>#<br/>###############################################################################<br/><br/># Using GSI authentication for certificates requires the issuer CAs to be<br/># installed in /etc/grid-security/certificates. If you would also like to<br/># authenticate VOMS attributes, *.lsc files should be installed in<br/># /etc/grid-security/vomsdir/<br/><br/># To configure authorization for users submitting jobs to your HTCondor-CE,<br/># uncomment and replace &lt;DISTINGUISHED NAME&gt; and &lt;USERNAME&gt; (escaping any '/'<br/># with '\/') with the Distinguished Name (DN) of the incoming user certificate<br/># and the unix account under which the job should run, respectively:<br/>#<br/># GSI /&lt;DISTINGUISHED NAME&gt;/ &lt;USERNAME&gt;<br/><br/># VOMS attributes can also be used for mapping:<br/>#<br/># GSI /&lt;DISTINGUISHED NAME&gt;,&lt;VOMS FQAN 1&gt;,&lt;VOMS FQAN 2&gt;,...,&lt;VOMSFQAN N&gt;/ &lt;USERNAME&gt;<br/><br/># The second field should be a Perl Compatible Regular Expression (PCRE), thus<br/># allowing you to accept any DN with a given VOMS FQAN. For example, to map any<br/># GLOW certificate with the 'htpc' role to the 'glow' user, add a line that<br/># looks like the following:<br/>#<br/># GSI /.*,\/GLOW\/Role=htpc.*/ glow<br/>#<br/>###############################################################################<br/>#<br/># HTCondor-CE manual SciTokens authentication mappings<br/>#<br/># This file will NOT be overwritten upon RPM upgrade.<br/>#<br/>###############################################################################<br/><br/># Authentication of SciTokens and WLCG tokens requires CA certificates<br/># installed in the standard system (/etc/pki/tls/certs/ca-bundle.crt)<br/># or Grid (/etc/grid-security/certificates) locations. If using Grid<br/># certificates, be sure to set 'AUTH_SSL_*' configuration values as<br/># appropriate in /etc/condor-ce/config.d/<br/><br/># To allow clients with SciToken or WLCG tokens to submit jobs to your<br/># HTCondor-CE, add lines of the following format:<br/>#<br/># SCITOKENS /&lt;TOKEN ISSUER&gt;,&lt;TOKEN SUBJECT&gt;/ &lt;USERNAME&gt;<br/>#<br/># Where the second field (between the '/') should be a Perl Compatible<br/># Regular Expression (PCRE). For example, to map all clients with<br/># SciTokens issued by the OSG VO regardless of subject to the local<br/># 'osg' user, add the following line to this file:<br/>#<br/># SCITOKENS /^https:\/\/scitokens.org\/osg-connect,.*/ osg<br/>###############################################################################<br/>#<br/># HTCondor-CE authentication mapping for GSI callouts<br/>#<br/># This file will NOT be overwritten upon RPM upgrade.<br/>#<br/>###############################################################################<br/><br/># The special token GSS_ASSIST_GRIDMAP indicates one should use the Globus Toolkit<br/># callout mechanism (which may involve plugins such as LCMAPS or Argus).<br/># Comment this out if you are not using a Globus Toolkit callout for mappings<br/>GSI /(.*)/ GSS_ASSIST_GRIDMAP<br/>[root@ce5-vanderbilt ~]# </pre><br/>
<span style="color: #43761b"><span style="font-size: small">(17:33:14)</span> <b>blin:</b></span> mmk yeah that all looks good<br/>
<span style="color: #43761b"><span style="font-size: small">(17:34:25)</span> <b>blin:</b></span> this line from the schedlog was interesting:<br/><pre>globus_gss_assist token :-1: read failure: Operation not permitted</pre><br/>there may be some useful lines in the <tt>journalctl -eu condor-ce</tt> wrt lcmaps<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:34:45)</span> <b>andrew.melo:</b></span> <pre>[root@ce5-vanderbilt ~]# journalctl -eu condor-ce | grep lcmaps<br/>[root@ce5-vanderbilt ~]# </pre><br/>
<span style="color: #43761b"><span style="font-size: small">(17:35:06)</span> <b>blin:</b></span> but i'm not sure those lines are entirely relevant, as long as you have the appropriate files in <tt>/usr/share/condor-ce/mapfiles.d/</tt>, your <tt>condor_ce_q</tt> queries should be coming in with <tt>FS</tt> authentication and so GSI/GSI callouts shouldn't matter<br/>
<span style="color: #43761b"><span style="font-size: small">(17:35:25)</span> <b>blin:</b></span> how about <tt>grep -i lcamps</tt> ?<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:36:10)</span> <b>andrew.melo:</b></span> hmm. why did that one fail?<br/><pre>Aug 24 15:14:07 ce5-vanderbilt htcondor-ce[2715405]: Callout to "LCMAPS" returned local user (service condor): "lscpilot"<br/>Aug 24 15:18:47 ce5-vanderbilt htcondor-ce[2715403]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 15:22:39 ce5-vanderbilt htcondor-ce[2715403]: Callout to "LCMAPS" returned local user (service condor): "lscpilot"<br/>Aug 24 15:28:40 ce5-vanderbilt htcondor-ce[2715405]: Callout to "LCMAPS" returned local user (service condor): "lcgadmin"<br/>Aug 24 15:30:31 ce5-vanderbilt htcondor-ce[2904384]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 15:30:50 ce5-vanderbilt htcondor-ce[2904384]: Warning: failed mapping. LCMAPS returned: 1<br/>Aug 24 15:30:50 ce5-vanderbilt htcondor-ce[2904384]: Execution of LCMAPS failed.<br/>Aug 24 15:30:51 ce5-vanderbilt htcondor-ce[2904384]: Callout to "LCMAPS" returned local user (service condor): "lscpilot"<br/>Aug 24 15:31:00 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "lscpilot"<br/>Aug 24 15:31:05 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 15:32:00 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "lcgadmin"<br/>Aug 24 15:59:17 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 16:04:10 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "lcgadmin"<br/>Aug 24 16:04:20 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 16:05:14 ce5-vanderbilt htcondor-ce[2904384]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 16:22:55 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "lscpilot"<br/>Aug 24 16:23:02 ce5-vanderbilt htcondor-ce[2904384]: Callout to "LCMAPS" returned local user (service condor): "lscpilot"<br/>Aug 24 16:36:12 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "lcgadmin"<br/>Aug 24 16:36:49 ce5-vanderbilt htcondor-ce[2904384]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 16:41:26 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 16:42:06 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 16:47:22 ce5-vanderbilt htcondor-ce[2904384]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 16:53:07 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "lscpilot"<br/>Aug 24 17:06:54 ce5-vanderbilt htcondor-ce[2904384]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 17:10:55 ce5-vanderbilt htcondor-ce[2904384]: Callout to "LCMAPS" returned local user (service condor): "lscpilot"<br/>Aug 24 17:16:37 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 17:16:42 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "cmspilot"<br/>Aug 24 17:32:38 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "lscpilot"<br/>Aug 24 17:32:45 ce5-vanderbilt htcondor-ce[2904386]: Callout to "LCMAPS" returned local user (service condor): "lcgadmin"<br/>[root@ce5-vanderbilt ~]# </pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(17:36:41)</span> <b>andrew.melo:</b></span> timestamp is wrong though, the other one was 17:24<br/>
<span style="color: #43761b"><span style="font-size: small">(17:38:49)</span> <b>blin:</b></span> the surrounding lines for the failure may provide some clues<br/>
<span style="color: #43761b"><span style="font-size: small">(17:38:56)</span> <b>blin:</b></span> otherwise you'll have to bump the lcamps debugging <a href="https://opensciencegrid.org/docs/security/lcmaps-voms-authentication/#htcondor-ce-hosts">https://opensciencegrid.org/docs/security/lcmaps-voms-authentication/#htcondor-ce-hosts</a><br/>
<span style="color: #43761b"><span style="font-size: small">(17:39:28)</span> <b>blin:</b></span> do you have anything in <tt>/usr/share/condor-ce/mapfiles.d/</tt> other than <a href="https://github.com/htcondor/htcondor-ce/blob/V5-branch/config/mapfiles.d/50-common-default.conf">https://github.com/htcondor/htcondor-ce/blob/V5-branch/config/mapfiles.d/50-common-default.conf</a>?<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:39:32)</span> <b>andrew.melo:</b></span> well, that failure is at the wrong time<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:40:21)</span> <b>andrew.melo:</b></span> no, I got<br/><pre>[root@ce5-vanderbilt condor-ce]# ls mapfiles.d/<br/>10-gsi.conf  10-scitokens.conf  50-gsi-callout.conf</pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(17:40:24)</span> <b>andrew.melo:</b></span> three files<br/>
<span style="color: #43761b"><span style="font-size: small">(17:41:38)</span> <b>blin:</b></span> those files are what i'd expect in <tt>/etc/condor-ce/mapfiles.d/</tt>  not <tt>/usr/share/condor-ce/mapfiles.d/</tt><br/>
<span style="color: #a72f79"><span style="font-size: small">(17:42:28)</span> <b>andrew.melo:</b></span> oh sorry, looked in the wrong place<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:42:50)</span> <b>andrew.melo:</b></span> I have only 50-common-default.conf<br/>
<span style="color: #43761b"><span style="font-size: small">(17:44:46)</span> <b>blin:</b></span> <tt>_condor_SEC_CLIENT_AUTHENTICATION_METHODS=FS _condor_TOOL_DEBUG=D_SECURITY:2 condor_ce_ping READ</tt><br/>
<span style="color: #a72f79"><span style="font-size: small">(17:46:02)</span> <b>andrew.melo:</b></span> conveniently, I have lcmaps dumped out, and nothing happens at 15:30<br/><pre>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:15:08Z: freeing plugin lcmaps_dummy_good.mod at address 0x55c0d4a0d0c0<br/>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:15:08Z: freeing plugin lcmaps_voms_localaccount.mod at address 0x55c0cb1d2d60<br/>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:15:08Z: freeing plugin lcmaps_voms_localaccount2.mod at address 0x55c1169b9c90<br/>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:58:46Z: lcmaps_log_open(): setting log level to 5 (LCMAPS_DEBUG_LEVEL), which translates to Syslog level "LOG_DEBUG".<br/>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:58:46Z: Initialization LCMAPS version 1.6.6<br/>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:58:46Z: lcmaps.mod-lcmaps_startPluginManager(): doing lcmaps_startEvaluationManager(/etc/lcmaps.db)<br/>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:58:46Z: Checking policy 'authorize_only' for recursions.<br/>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:58:46Z: No recursions were found.<br/>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:58:46Z: Checking policy 'xrootd_policy' for recursions.<br/>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:58:46Z: No recursions were found.<br/>lcmaps[1730350]   LOG_DEBUG: 2021-08-24.15:58:46Z: lcmaps.mod-lcmaps_startPluginManager(): Reading LCMAPS database /etc/lcmaps.db</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(17:46:51)</span> <b>blin:</b></span> this is just a CE, right? i don't think you should have an <tt>xrootd_policy</tt>...<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:47:32)</span> <b>andrew.melo:</b></span> I use the same lcmaps.db for all the hosts<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:48:09)</span> <b>andrew.melo:</b></span> <pre>[root@ce5-vanderbilt condor-ce]# _condor_SEC_CLIENT_AUTHENTICATION_METHODS=FS _condor_TOOL_DEBUG=D_SECURITY:2 condor_ce_ping READ<br/>^C<br/>[root@ce5-vanderbilt condor-ce]# date; _condor_SEC_CLIENT_AUTHENTICATION_METHODS=FS _condor_TOOL_DEBUG=D_SECURITY:2 condor_ce_ping READ; date<br/>Tue Aug 24 17:46:55 CDT 2021<br/>READ command using (no encryption, no integrity, and no authentication) succeeded as unauthenticated@unmapped to local schedd.<br/>Tue Aug 24 17:47:42 CDT 2021<br/>[root@ce5-vanderbilt condor-ce]# </pre><br/>nearly a minute?<br/>
<span style="color: #43761b"><span style="font-size: small">(17:48:18)</span> <b>blin:</b></span> wild, ok i guess that can work<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:48:39)</span> <b>andrew.melo:</b></span> well, if it takes a minute, then the timeouts are probably going to creep up?<br/>
<span style="color: #43761b"><span style="font-size: small">(17:48:54)</span> <b>blin:</b></span> could you shoot an email containing <tt>condor_ce_config_val -dump</tt> to <a href="mailto:help@opensciencegrid.org">help@opensciencegrid.org</a>?<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:49:38)</span> <b>andrew.melo:</b></span> yessir<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:54:18)</span> <b>andrew.melo:</b></span> #67880<br/>
<span style="color: #43761b"><span style="font-size: small">(17:54:27)</span> <b>blin:</b></span> got it, thanks<br/>
<span style="color: #9e3997"><span style="font-size: small">(17:54:50)</span> <b>bbockelm:</b></span> &gt;  I guess I should look at /proc to see what the UID is when I see it next, but I watched "watch" for an hour and it was always cmspilot<br/>&gt; and I couldn't do condor_ce_q when that was happening<br/>That's likely related.  80% of the cases, when things look like they're stuck as a non-condor user it's because an underlying filesystem that condor is getting slow.  This causes the euid to be "stuck" as non-condor and, since things are single-threaded, causes <tt>condor_q</tt> to be relatively unresponsive.<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:55:40)</span> <b>andrew.melo:</b></span> So, we actually moved the block device off the VM-hosted ceph storage to a local SSD to try and get it to be better<br/>
<span style="color: #a72f79"><span style="font-size: small">(17:58:07)</span> <b>andrew.melo:</b></span> it probably doesn't help that there's a shitton of jobs completed but not being removed for some reason: <a href="https://opensciencegrid.slack.com/archives/C08K1QJMA/p1629840993239000">https://opensciencegrid.slack.com/archives/C08K1QJMA/p1629840993239000</a><br/>
<span style="color: #43761b"><span style="font-size: small">(18:01:30)</span> <b>blin:</b></span> the CE should be removing completed jobs that have been completed for &gt; 30 days <a href="https://github.com/htcondor/htcondor-ce/blob/V5-branch/config/01-ce-router-defaults.conf#L58-L60">https://github.com/htcondor/htcondor-ce/blob/V5-branch/config/01-ce-router-defaults.conf#L58-L60</a><br/>
<span style="color: #43761b"><span style="font-size: small">(18:02:00)</span> <b>blin:</b></span> were you able to get the gratia probe to run and clear out that history dir?<br/>
<span style="color: #a72f79"><span style="font-size: small">(18:02:35)</span> <b>andrew.melo:</b></span> no, because we don't actually allow direct access to mysql from other places, so we have to change the firewall<br/>
<span style="color: #a72f79"><span style="font-size: small">(18:03:59)</span> <b>andrew.melo:</b></span> normally, slurm clients go through the slurmdbd service which proxies the requests<br/>
<span style="color: #a72f79"><span style="font-size: small">(18:15:27)</span> <b>andrew.melo:</b></span> the disk is unloaded:<br/><pre>Total DISK READ :	0.00 B/s | Total DISK WRITE :      38.45 K/s<br/>Actual DISK READ:	0.00 B/s | Actual DISK WRITE:     249.94 K/s<br/>    TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&gt;    COMMAND                                                       <br/>    285 be/3 root        0.00 B/s   15.38 K/s  0.00 %  0.07 % [jbd2/sda5-8]<br/>    481 be/3 root        0.00 B/s    0.00 B/s  0.00 %  0.04 % auditd<br/>2904384 be/4 condor	 0.00 B/s    3.85 K/s  0.00 %  0.00 % condor_collector<br/>    480 be/3 root        0.00 B/s    7.69 K/s  0.00 %  0.00 % auditd<br/>    995 be/4 root        0.00 B/s   11.54 K/s  0.00 %  0.00 % rsyslogd -n [rs:main Q:Reg]<br/>   1024 be/4 root  	 0.00 B/s    0.00 B/s  0.00 %  0.00 % auditbeat --environment systemd ~at -path.logs /var/log/auditbeat<br/>      1 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % systemd --switched-root --system --deserialize 22<br/>      2 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kthreadd]<br/>   1027 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % auditbeat --environment systemd ~at -path.logs /var/log/auditbeat<br/>      4 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/0:0H]<br/>      6 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/0]<br/>      7 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/0]<br/>      8 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_bh]<br/>      9 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_sched]<br/>     10 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [lru-add-drain]<br/>     11 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [watchdog/0]<br/>     12 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [watchdog/1]<br/>     13 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/1]<br/>     14 be/4 ro</pre><br/>
<span style="color: #9e3997"><span style="font-size: small">(18:22:30)</span> <b>bbockelm:</b></span> One thing that might be useful is a <tt>pstack</tt> output on the top schedd process — might have a suggestion of where it’s getting stuck.<br/>
<span style="color: #a72f79"><span style="font-size: small">(18:33:37)</span> <b>andrew.melo:</b></span> guess I gotta dig through the threads to find the right pid<br/><pre>[root@ce5-vanderbilt ~]# pstack 2904386<br/>#0  0x00007f13ab46fe87 in rename () from /usr/lib64/libc.so.6<br/>#1  0x00007f13ad527252 in rotate_file_dprintf () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#2  0x0000559fe37779a7 in UpdateGSICredContinuation::finish_update(ReliSock*, ReliSock::x509_delegation_result) ()<br/>#3  0x0000559fe3778975 in UpdateGSICredContinuation::finish(Stream*) ()<br/>#4  0x00007f13ad754020 in DaemonCore::CallSocketHandler_worker(int, bool, Stream*) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#5  0x00007f13ad7540bd in DaemonCore::CallSocketHandler_worker_demarshall(void*) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#6  0x00007f13ad58cef5 in CondorThreads::pool_add(void (*)(void*), void*, int*, char const*) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#7  0x00007f13ad74fde7 in DaemonCore::CallSocketHandler(int&amp;, bool) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#8  0x00007f13ad758ade in DaemonCore::Driver() () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#9  0x00007f13ad76d4e2 in dc_main(int, char**) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#10 0x00007f13ab426555 in __libc_start_main () from /usr/lib64/libc.so.6<br/>#11 0x0000559fe37039dd in _start ()</pre><br/>
<span style="color: #9e3997"><span style="font-size: small">(18:34:38)</span> <b>bbockelm:</b></span> Should be pretty obvious from “ps faux” which one is the parent. I usually hit it a few times and look for commonalities <br/>
<span style="color: #a72f79"><span style="font-size: small">(18:38:54)</span> <b>andrew.melo:</b></span> It seems like that's the parent...<br/><pre>condor   2904333  0.0  0.0  86248  5716 ?        Ss   15:30   0:00 condor_master<br/>root     2904381  0.0  0.0  24916  7032 ?        S    15:30   0:03  \_ condor_procd -A /var/lock/condor-ce/procd_<br/>condor   2904382  0.0  0.0  61708  6188 ?        Ss   15:30   0:11  \_ condor_shared_port<br/>condor   2904384  8.4  7.0 1409260 1142780 ?     Ss   15:30  15:46  \_ condor_collector<br/>cmspilot 2904386  5.7  1.4 406312 231916 ?       Ss   15:30  10:49  \_ condor_schedd<br/>cmspilot 3101224  1.4  0.3 170392 54672 ?        S    18:20   0:15  |   \_ condor_gridmanager -f -C (Owner=?="cms<br/>cmspilot 3101237  0.4  0.0 1095112 4820 ?        S    18:20   0:04  |   |   \_ /usr/bin/blahpd<br/>lscpilot 3101229  0.0  0.0 126284 10540 ?        S    18:20   0:01  |   \_ condor_gridmanager -f -C (Owner=?="lsc<br/>lscpilot 3101396  0.0  0.0 1234448 4156 ?        Sl   18:20   0:00  |   |   \_ /usr/bin/blahpd<br/>lscpilot 3120014  4.0  0.0 210364 10864 ?        Ss   18:37   0:00  |   |       \_ /usr/bin/python3 /usr/libexec/<br/>lscpilot 3120029  3.5  0.0 210364 10876 ?        Ss   18:37   0:00  |   |       \_ /usr/bin/python3 /usr/libexec/<br/>lscpilot 3120076  4.0  0.0 137268  7840 ?        S    18:37   0:00  |   |       |   \_ /accre/admin/venv-36a/bin/<br/>lscpilot 3120077  1.0  0.0  36240  2160 ?        S    18:37   0:00  |   |       |       \_ /usr/bin/squeue -o %i <br/>lscpilot 3120030  3.5  0.0 210364 10864 ?        Ss   18:37   0:00  |   |       \_ /usr/bin/python3 /usr/libexec/<br/>lscpilot 3120031  3.5  0.0 210364 10864 ?        Ss   18:37   0:00  |   |       \_ /usr/bin/python3 /usr/libexec/<br/>&lt;snip&gt;<br/>lscpilot 3120068  3.5  0.0 210364 10868 ?        Ss   18:37   0:00  |   |       \_ /usr/bin/python3 /usr/libexec/<br/>condor   3119720  0.0  0.0      0     0 ?        Z    18:37   0:00  |   \_ [condor_schedd] &lt;defunct&gt;<br/>cmspilot 2904387  2.1  2.4 477932 399276 ?       Ss   15:30   3:57  \_ condor_job_router</pre><br/>
<span style="color: #9e3997"><span style="font-size: small">(18:39:51)</span> <b>bbockelm:</b></span> Yup, looks right. So, if you do that 4-5 times, any patterns<br/>
<span style="color: #a72f79"><span style="font-size: small">(18:41:04)</span> <b>andrew.melo:</b></span> seeing a lot of this from pstack<br/><pre>#0  0x00007f13ab4f51d7 in unlink () from /usr/lib64/libc.so.6<br/>#1  0x00007f13ad511088 in Directory::do_remove_file(char const*) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#2  0x00007f13ad512ba2 in Directory::do_remove(char const*, bool) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#3  0x00007f13ad512c78 in Directory::Remove_Entire_Directory() () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#4  0x00007f13ad63981b in remove_spool_directory(char const*) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#5  0x00007f13ad63ba18 in SpooledJobFiles::removeJobSpoolDirectory(classad::ClassAd*) () from /usr/lib64/libcondor_utils_9_0_4.so</pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(18:41:25)</span> <b>andrew.melo:</b></span> maybe metadata stuff doesn't show up in iotop<br/>
<span style="color: #9e3997"><span style="font-size: small">(18:41:57)</span> <b>bbockelm:</b></span> Yeah.  Might be latency bound, not data rate bound<br/>
<span style="color: #a72f79"><span style="font-size: small">(18:42:31)</span> <b>andrew.melo:</b></span> generating some prime numbers...<br/><pre>#0  0x00007f13ac70caca in probable_prime () from /usr/lib64/libcrypto.so.10<br/>#1  0x00007f13ac70d52c in BN_generate_prime_ex () from /usr/lib64/libcrypto.so.10<br/>#2  0x00007f13ac73acf7 in RSA_generate_key_ex () from /usr/lib64/libcrypto.so.10<br/>#3  0x00007f13a6bf3d02 in globus_gsi_proxy_create_req () from /usr/lib64/libglobus_gsi_proxy_core.so.0<br/>#4  0x00007f13ad60beed in x509_receive_delegation(char const*, int (*)(void*, void**, unsigned long*), void*, int (*)(void*, void*, unsigned long), void*, void**) () from /usr/lib64/libcondor_utils_9_0_4.so<br/>#5  0x00007f13ad6bd23e in ReliSock::get_x509_delegation(char const*, bool, void**) () from /usr/lib64/libcondor_utils_9_0_4.so</pre><br/>
<span style="color: #9e3997"><span style="font-size: small">(18:45:17)</span> <b>bbockelm:</b></span> That’s a little surprising, I thought that happened in a child process. Regardless, if you’re seeing things hanging out as cmspilot, I might still lean toward blaming IO.  Oh!  There’s a some statistics you can query from the schedd about timing of each RPC. … not recalling the best way to get it. Some variant of condor_status -direct.<br/>
<span style="color: #a72f79"><span style="font-size: small">(18:46:41)</span> <b>andrew.melo:</b></span> let me try to figure out the incantation. gotta jump out for a sec and make/eat dinner, but thanks for your help, you guys!<br/>
<span style="color: #9e3997"><span style="font-size: small">(18:46:53)</span> <b>bbockelm:</b></span> Good luck!<br/>
</body>
</html>
