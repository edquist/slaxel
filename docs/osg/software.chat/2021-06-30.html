<!DOCTYPE html>
<html>
<head>
<title>Wed Jun 30, 2021 : #software (osg)</title>
</head>
<body>
<h3>Wed Jun 30, 2021 : #software (osg)</h3>
<span style="color: #e96699"><span style="font-size: small">(10:02:15)</span> <b>lincoln:</b></span> @tim.theisen I can, but our use of that particular feature is a bit weird via SLATE.<br/>
<span style="color: #e96699"><span style="font-size: small">(10:02:24)</span> <b>lincoln:</b></span> If you just want me to test if it runs, then sure, assuming the container is updated<br/>
<span style="color: #43761b"><span style="font-size: small">(10:03:13)</span> <b>blin:</b></span> @lincoln i'm pretty sure you're already running the bugfix. do you have a container that you can exec into to <tt>rpm -q frontier-squid</tt>?<br/>
<span style="color: #e96699"><span style="font-size: small">(10:03:25)</span> <b>lincoln:</b></span> sure<br/>
<span style="color: #73769d"><span style="font-size: small">(10:03:26)</span> <b>tim.theisen:</b></span> I don't need you to test the bug fix. Just that it works properly for you.<br/>
<span style="color: #e96699"><span style="font-size: small">(10:03:33)</span> <b>lincoln:</b></span> one moment please<br/>
<span style="color: #e96699"><span style="font-size: small">(10:04:10)</span> <b>lincoln:</b></span> <pre>sh-4.4# rpm -q frontier-squid<br/>frontier-squid-4.15-1.2.osg35.el8.x86_64</pre><br/>
<span style="color: #e96699"><span style="font-size: small">(10:04:30)</span> <b>lincoln:</b></span> I have been running this version for 2 weeks at IU<br/>
<span style="color: #43761b"><span style="font-size: small">(10:05:44)</span> <b>blin:</b></span> sick. we should think about adding that info into the container metadata so that you don't have to shell in<br/>
<span style="color: #43761b"><span style="font-size: small">(10:06:06)</span> <b>blin:</b></span> it gets a little bit trickier with containers that have a bunch of RPM versions that we care about, though<br/>
<span style="color: #73769d"><span style="font-size: small">(10:06:25)</span> <b>tim.theisen:</b></span> Cool. Thank you.<br/>
<span style="color: #c386df"><span style="font-size: small">(10:07:42)</span> <b>matyas:</b></span> I wrote this a few months ago, maybe we can add it to the GHAs:<br/><pre>% cat add-rpms-image-labels.sh <br/>#!/bin/bash<br/>set -e<br/>image=${1?Need image name:tag}<br/>labels=$(docker run --rm "$image" sh -c 'rpm -qa --qf rpms.%{NAME}=\"%{EVR}\"\\n' | sed 's/$/ \\/')<br/>docker build -t "$image" -f- . &lt;&lt;TLDR<br/>FROM $image<br/>LABEL \<br/>$labels<br/><br/>TLDR</pre><br/><br/>
<span style="color: #c386df"><span style="font-size: small">(10:08:59)</span> <b>matyas:</b></span> you run it like <tt>add-rpms-image-labels.sh frontier-squid:release</tt> and it will plop out a new <tt>frontier-squid:release</tt> with labels like <tt>rpms.frontier-squid="0:4.15-1.2.osg35.el8"</tt> (for every RPM)<br/>
<span style="color: #e96699"><span style="font-size: small">(10:09:44)</span> <b>lincoln:</b></span> in other news.. I am trying a fresh HTCondor pool setup with 9.0.1 as provided via 3.5-upcoming and having some trouble with initial setup.<br/>
<span style="color: #e96699"><span style="font-size: small">(10:10:56)</span> <b>lincoln:</b></span> I want to be entirely idtoken based auth. I'm using<br/><pre>use security:recommended_v9_0</pre><br/>from 00-htcondor-9.0.conf<br/><br/>with another file that adds "DAEMON_LIST = MASTER, COLLECTOR, NEGOTIATOR"<br/><br/>but alas..<br/><br/><pre>[root@head01 config.d]# condor_status<br/>Error: can't find collector<br/><br/>[root@head01 config.d]# ps faux | grep collector<br/>root     12428  0.0  0.0 112824  2312 pts/0    S+   10:10   0:00          \_ grep --color=auto collector<br/>condor    5476  0.0  0.0  49504 10544 ?        Ss   10:06   0:00  \_ condor_collector</pre><br/>
<span style="color: #e96699"><span style="font-size: small">(10:11:42)</span> <b>lincoln:</b></span> I guess CONDOR_HOST needs defined, too<br/>
<span style="color: #e96699"><span style="font-size: small">(10:13:14)</span> <b>lincoln:</b></span> If I want to build a pool from this, should I just run ..<br/><pre>condor_token_request_auto_approve -netblock</pre><br/>and join my nodes to the pool ?<br/>
<span style="color: #e96699"><span style="font-size: small">(10:13:34)</span> <b>lincoln:</b></span> (definining CONDOR_HOST got me past the previous problem)<br/>
<span style="color: #43761b"><span style="font-size: small">(10:14:49)</span> <b>blin:</b></span> i believe that's the case. @tim.theisen would know the details<br/>
<span style="color: #e96699"><span style="font-size: small">(10:15:19)</span> <b>lincoln:</b></span> I am attempting to RTFM<br/>
<span style="color: #43761b"><span style="font-size: small">(10:15:46)</span> <b>blin:</b></span> yeah, it's better than before but also not 100% clear...<br/>
<span style="color: #43761b"><span style="font-size: small">(10:16:01)</span> <b>blin:</b></span> i think it's maybe RTFS for the get_htcondor script<br/>
<span style="color: #e96699"><span style="font-size: small">(10:16:08)</span> <b>lincoln:</b></span> hah, ok<br/>
<span style="color: #43761b"><span style="font-size: small">(10:17:39)</span> <b>blin:</b></span> hrm, it doesn't look like it actually uses <tt>condor_token_request_auto_approve</tt> and instead uses a shared pool password to generate the tokens<br/>
<span style="color: #43761b"><span style="font-size: small">(10:18:15)</span> <b>blin:</b></span> i /think/ you're right about using that, though, for an existing pool<br/>
<span style="color: #e96699"><span style="font-size: small">(10:18:15)</span> <b>lincoln:</b></span> well, I want something I can throw into config management or a container, so auto approve isnt necessarily what I want anyhow<br/>
<span style="color: #43761b"><span style="font-size: small">(10:18:45)</span> <b>blin:</b></span> well you could run it the first time and then use the tokens that the hosts get in config management<br/>
<span style="color: #e96699"><span style="font-size: small">(10:18:59)</span> <b>lincoln:</b></span> cool<br/>
<span style="color: #43761b"><span style="font-size: small">(10:19:04)</span> <b>blin:</b></span> @tannenba or @bbockelm may have suggestions<br/>
<blockquote>
<span style="color: #de5f24"><span style="font-size: small">(10:35:01)</span> <b>tannenba:</b></span> @lincoln @blin I likely do have suggestions [ don't I always?  :slightly_smiling_face: ]... but when I am tagged it would help if I could have a question, or at least a statement about what you would like suggestions on....  In other words, if the "log" of free-flowing conversation could be compressed down to a problem statement or a question(s) I'd appreciate it.  Or we can do a quick  zoom today to discuss whatever it is you'd like ... this afternoon is looking very open for me at the moment...  Thanks!<br/>
<span style="color: #e96699"><span style="font-size: small">(10:37:46)</span> <b>lincoln:</b></span> Hi Todd, thanks. I'm working on setting up a new HTCondor pool w/ 9.0.1 and IDTOKEN auth. Just working through the process of issuing tokens etc. I think I've worked through my initial problems but I will let you know if I have something specific that comes up!<br/>
<span style="color: #de5f24"><span style="font-size: small">(11:08:51)</span> <b>tannenba:</b></span> @lincoln Are you using get_htcondor ? (hopefully!)   Yes, it still has the issue that you will need to provide a secure passphrase to join a pool (can come from the environment, or a file...) which is a bit of a hassle in a puppet world, but that is a limitation we hope to remedy before the next stable series...<br/>
<span style="color: #e96699"><span style="font-size: small">(11:12:09)</span> <b>lincoln:</b></span> I am not! I should look into that.  Right now I am wondering what I am doing wrong with <tt>condor_token_create</tt> and why my Schedd is 1) autogenerating new tokens and asking me to approve them on my central manager , 2) not allowing me to condor_status with the autogenerated token<br/>
<span style="color: #e96699"><span style="font-size: small">(11:13:56)</span> <b>lincoln:</b></span> so maybe I will take you up on that zoom offer @tannenba! Do you have time between 1 and 3?<br/>
<span style="color: #43761b"><span style="font-size: small">(11:15:34)</span> <b>blin:</b></span> for (2) i think you just need to add <tt>READ</tt> to your token<br/>
<span style="color: #e96699"><span style="font-size: small">(11:18:03)</span> <b>lincoln:</b></span> well the schedd autogenerated it! it should add READ! :slightly_smiling_face:<br/>
<span style="color: #43761b"><span style="font-size: small">(11:18:35)</span> <b>blin:</b></span> you should be able to inspect the token scopes with <tt>condor_token_list</tt><br/>
<span style="color: #de5f24"><span style="font-size: small">(11:21:48)</span> <b>tannenba:</b></span> @lincoln Happy to have a zoom, lets say 2pm central at URL  <a href="https://uwmadison.zoom.us/my/tannenba">https://uwmadison.zoom.us/my/tannenba</a> ...  Once nice thing about get_htcondor is you are left with a secure pool that uses tokens, ready for you to drop any additional customizaitons into /etc/condor/config.d.... Hopefully using get_htcondor gets you out of the "how do I set all the knobs to setup token based security?" headache....<br/>
<span style="color: #43761b"><span style="font-size: small">(11:22:27)</span> <b>blin:</b></span> also, theoretically, <tt>get_htcondor</tt> should work with the OSG repos as well<br/>
<span style="color: #e96699"><span style="font-size: small">(11:33:57)</span> <b>lincoln:</b></span> while I have you Todd, would also appreciate if I could pick your brain about running schedds remotely and having the tools do condor_submit etc across the network<br/>
<span style="color: #de5f24"><span style="font-size: small">(12:20:15)</span> <b>tannenba:</b></span> Sure...<br/>
</blockquote>
<span style="color: #e96699"><span style="font-size: small">(10:19:33)</span> <b>lincoln:</b></span> so what you're saying is.. I should have a cron to continuously run <tt>condor_token_request_auto_approve</tt> for my netblock ! :upside_down_face:<br/>
<span style="color: #43761b"><span style="font-size: small">(10:20:51)</span> <b>blin:</b></span> :foot::skin-tone-3:  meet :gun:<br/>
<span style="color: #e96699"><span style="font-size: small">(10:20:55)</span> <b>lincoln:</b></span> hehehe<br/>
<span style="color: #e96699"><span style="font-size: small">(10:22:18)</span> <b>lincoln:</b></span> looking thru the docs I am guessing I should use <tt>condor_token_create</tt> to make tokens for each of my daemon types? a <tt>worker-node</tt> that has <tt>-authz ADVERTISE_STARTD</tt> and <tt>-authz ADVERTISE_MASTER</tt> ? And then a scheduler token that does the same thing for the schedd side?<br/>
<span style="color: #e96699"><span style="font-size: small">(10:22:55)</span> <b>lincoln:</b></span> I assume that a single token shared among all of my workers is no worse than a pool password<br/>
<span style="color: #43761b"><span style="font-size: small">(10:23:09)</span> <b>blin:</b></span> that all sounds right to me<br/>
<span style="color: #e96699"><span style="font-size: small">(10:23:54)</span> <b>lincoln:</b></span> my 9.0.1 collector was very unhappy with whatever crufty config I dragged over from 8.x and blew up on startup, which was fun<br/>
<span style="color: #43761b"><span style="font-size: small">(10:24:09)</span> <b>blin:</b></span> for config management, maybe you can have your WNs request a token upon rebuild or whatever, then you'd approve them at the CM<br/>
<span style="color: #e96699"><span style="font-size: small">(10:24:24)</span> <b>lincoln:</b></span> yeah, could do that.<br/>
<span style="color: #43761b"><span style="font-size: small">(10:24:45)</span> <b>blin:</b></span> you probably don't want that for the initial 9.0.1 install but that seems reasonable for rebuilds that'd probably just be a handful of WNs at a time<br/>
<span style="color: #e96699"><span style="font-size: small">(10:52:19)</span> <b>lincoln:</b></span> I am revisiting my containerized workers- do y'all have a recommended container image that I can start from?<br/>
<span style="color: #e96699"><span style="font-size: small">(10:52:52)</span> <b>lincoln:</b></span> something with HTCondor 9<br/>
<span style="color: #e96699"><span style="font-size: small">(10:52:55)</span> <b>lincoln:</b></span> and IDTOKEN auth<br/>
<span style="color: #c386df"><span style="font-size: small">(10:57:52)</span> <b>matyas:</b></span> OSG or non-OSG?<br/>
<span style="color: #e96699"><span style="font-size: small">(10:59:26)</span> <b>lincoln:</b></span> either I guess?<br/>
<span style="color: #e96699"><span style="font-size: small">(10:59:32)</span> <b>lincoln:</b></span> I'll be laying ATLAS stuff on top of it<br/>
<span style="color: #c386df"><span style="font-size: small">(11:01:54)</span> <b>matyas:</b></span> try <tt>htcondor/execute:9.0.1-el7</tt><br/>
<span style="color: #e96699"><span style="font-size: small">(11:02:35)</span> <b>lincoln:</b></span> ok cool will do<br/>
<span style="color: #e96699"><span style="font-size: small">(11:02:39)</span> <b>lincoln:</b></span> thanks<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:01:20)</span> <b>andrew.melo:</b></span> If you're running CVMFS on an internal network, is it possible to disable the GEOIP stuff? I don't think it breaks anything, but it's noisy<br/>
<span style="color: #235e5b"><span style="font-size: small">(12:28:27)</span> <b>dweitzel:</b></span> There's a <tt>CVMFS_USE_*GEO*API</tt> option.  But it appears to turn it off for everything.  Normal CVMFS traffic, and StashCache like traffic (with external servers).<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:34:58)</span> <b>andrew.melo:</b></span> Even if I set it just for a single domain? Actually, looking into it further, something's not quite right. We (@eric.appelt) and I went down this rabbit hole because some cvmfs mounts were failing to pass our nagios checks within the 10 sec timeout. If I understand these log messages right, it's taking 10 secs to get the ordering from FNAL?<br/><pre>Jun 30 12:30:54 vm-qa-flatearth1 cvmfs2: (<a href="http://atlas.cern.ch">atlas.cern.ch</a>) CernVM-FS: running in debug mode<br/>Jun 30 12:31:04 vm-qa-flatearth1 cvmfs2: (<a href="http://atlas.cern.ch">atlas.cern.ch</a>) geographic order of servers retrieved from <a href="http://cvmfs-s1fnal.opensciencegrid.org">cvmfs-s1fnal.opensciencegrid.org</a></pre><br/><br/>
<span style="color: #235e5b"><span style="font-size: small">(12:36:27)</span> <b>dweitzel:</b></span> That seems slow<br/>
<span style="color: #235e5b"><span style="font-size: small">(12:36:36)</span> <b>dweitzel:</b></span> @dwd Bringing in Dave!<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:37:15)</span> <b>andrew.melo:</b></span> If l look at the debug logs for cvmfs, that's how long it takes for the CVMFS process to get control:<br/><pre>echo "TIME IS $(date)" &gt; /tmp/cvmfs-2.log ; time ls /cvmfs/atlas.cern.ch ; echo "TIME IS $(date)" &gt;&gt; /tmp/cvmfs-2.log <br/><br/>..then..<br/><br/>TIME IS Wed Jun 30 12:30:54 CDT 2021<br/>(cvmfs) Options:<br/>&lt;snip&gt;<br/>CVMFS_USE_GEOAPI=yes    # from /etc/cvmfs/default.d/60-osg.conf<br/>    [06-30-2021 12:31:04 CDT]</pre><br/>
<span style="color: #235e5b"><span style="font-size: small">(12:38:29)</span> <b>dweitzel:</b></span> Is that from 0?  are all CVMFS processes off before <tt>ls</tt>?<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:39:25)</span> <b>andrew.melo:</b></span> No, there's some other repos mounted<br/>
<span style="color: #99a949"><span style="font-size: small">(12:40:16)</span> <b>dwd:</b></span> That’s an option at the beginning of the debug log?  That happens before the geo ordering happens.  The /var/log/messages entry does not indicate 10 seconds just to get the geo order, but it includes everything that  happens before then<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:41:04)</span> <b>andrew.melo:</b></span> <tt>(cvmfs) Options:</tt> is the very first line in the log, then it lists the options for the repo which I snipped, except for the final option<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:41:34)</span> <b>andrew.melo:</b></span> FWIW, this is what comes after<br/><pre>(cvmfs) setting up cache manager instance default    [06-30-2021 12:31:04 CDT]<br/>(quota) trying to connect to existing pipe    [06-30-2021 12:31:04 CDT]<br/>(quota) connected to existing cache manager pipe    [06-30-2021 12:31:04 CDT]</pre><br/>
<span style="color: #99a949"><span style="font-size: small">(12:41:58)</span> <b>dwd:</b></span> But the delay is before the debug log starts<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:44:02)</span> <b>andrew.melo:</b></span> I guess the problem is that the timestamps aren't lower than second resolution, so it's hard to figure out the causality<br/>
<span style="color: #99a949"><span style="font-size: small">(12:44:45)</span> <b>dwd:</b></span> I just did the same thing on my test machine at FNAL and got in /var/log/messages<br/><pre>un 30 12:40:49 fnalimage cvmfs2: (<a href="http://dwd-config.opensciencegrid.org">dwd-config.opensciencegrid.org</a>) CernVM-FS: linking /cvmfs/dwd-config.opensciencegrid.org to repository <a href="http://dwd-config.opensciencegrid.org">dwd-config.opensciencegrid.org</a><br/>Jun 30 12:40:49 fnalimage cvmfs2: (<a href="http://atlas.cern.ch">atlas.cern.ch</a>) CernVM-FS: running in debug mode<br/>Jun 30 12:40:53 fnalimage cvmfs2: (<a href="http://atlas.cern.ch">atlas.cern.ch</a>) geographic order of servers retrieved from <a href="http://cernvmfs.gridpp.rl.ac.uk">cernvmfs.gridpp.rl.ac.uk</a><br/>Jun 30 12:40:53 fnalimage cvmfs2: (<a href="http://atlas.cern.ch">atlas.cern.ch</a>) CernVM-FS: linking /cvmfs/atlas.cern.ch to repository <a href="http://atlas.cern.ch">atlas.cern.ch</a></pre><br/>and in the debug log the first timestamp was halfway in between<br/><pre>CVMFS_USE_GEOAPI=yes    # from /etc/cvmfs/default.d/60-osg.conf<br/>    [06-30-2021 12:40:51 CDT]</pre><br/><br/>
<span style="color: #99a949"><span style="font-size: small">(12:45:37)</span> <b>dwd:</b></span> (I have my own test config repo right now)<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:47:30)</span> <b>andrew.melo:</b></span> I guess at the end of the day -- why is it taking 10 seconds to get started? If I understand your ordering:<br/><br/>1. cvmfs running in debug mode (49s)<br/>2. cvmfs debuglog first timestamp (51s)<br/>3. order of servers determined (53s)<br/>Do you have just a standard client config for <a href="http://atlas.cern.ch">atlas.cern.ch</a>?<br/>
<span style="color: #99a949"><span style="font-size: small">(12:48:05)</span> <b>dwd:</b></span> Yes, other than enabling debug<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:48:35)</span> <b>andrew.melo:</b></span> Hmmmmmmmmmmm<br/>
<span style="color: #99a949"><span style="font-size: small">(12:49:26)</span> <b>dwd:</b></span> The debug log further shows that the geo ordering request started at the 52s timestamp, went to RAL, and finished at 53s.  With only 1 second granularity that could be anywhere from 1 to 1999 milliseconds<br/>
<span style="color: #99a949"><span style="font-size: small">(12:53:42)</span> <b>dwd:</b></span> If you umount /cvmfs/atlas.cern.ch and mount it manually somewhere else, e.g. /mnt with <tt>mount -t cvmfs <a href="http://atlas.cern.ch">atlas.cern.ch</a> /mnt</tt> then it will give you more debug messages that come before the log file begins<br/>
<span style="color: #a72f79"><span style="font-size: small">(12:54:45)</span> <b>andrew.melo:</b></span> let me try that<br/>
<span style="color: #99a949"><span style="font-size: small">(12:54:47)</span> <b>dwd:</b></span> Mainly it is the parsing of config files by sh:<br/><pre>Debug: using library /usr/lib64/libcvmfs_fuse_stub.so<br/>CernVM-FS: running with credentials 994:991<br/>CernVM-FS: running in debug mode<br/>CernVM-FS: loading Fuse module... (cvmfs) Parsing config file /etc/cvmfs/default.conf    [06-30-2021 12:52:36 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 4623)    [06-30-2021 12:52:36 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/default.d/60-osg.conf    [06-30-2021 12:52:36 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 4625)    [06-30-2021 12:52:37 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/default.d/80-computecanada.conf    [06-30-2021 12:52:37 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 4627)    [06-30-2021 12:52:37 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/default.d/95-dwd.conf    [06-30-2021 12:52:37 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 4629)    [06-30-2021 12:52:37 CDT]<br/>(cvmfs) Parsing config file /cvmfs/dwd-config.opensciencegrid.org/etc/cvmfs/default.conf    [06-30-2021 12:52:37 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 4633)    [06-30-2021 12:52:37 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/default.local    [06-30-2021 12:52:37 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 4635)    [06-30-2021 12:52:38 CDT]<br/>(cvmfs) Parsing config file /cvmfs/dwd-config.opensciencegrid.org/etc/cvmfs/domain.d/cern.ch.conf    [06-30-2021 12:52:38 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 4643)    [06-30-2021 12:52:38 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/domain.d/cern.ch.conf    [06-30-2021 12:52:38 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/domain.d/cern.ch.local    [06-30-2021 12:52:38 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 4645)    [06-30-2021 12:52:38 CDT]<br/>(cvmfs) Parsing config file /cvmfs/dwd-config.opensciencegrid.org/etc/cvmfs/config.d/atlas.cern.ch.conf    [06-30-2021 12:52:38 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/config.d/atlas.cern.ch.conf    [06-30-2021 12:52:38 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/config.d/atlas.cern.ch.local    [06-30-2021 12:52:38 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 4654)    [06-30-2021 12:52:38 CDT]<br/>done<br/>CernVM-FS: mounted cvmfs on /mnt/cvmfs</pre><br/><br/>
<span style="color: #a72f79"><span style="font-size: small">(13:13:14)</span> <b>andrew.melo:</b></span> ahhhhhh, ok, now we're getting closer:<br/><pre>CernVM-FS: loading Fuse module... (cvmfs) Parsing config file /etc/cvmfs/default.conf    [06-30-2021 13:12:42 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 28063)    [06-30-2021 13:12:44 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/default.d/60-osg.conf    [06-30-2021 13:12:44 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 28069)    [06-30-2021 13:12:46 CDT]<br/>(cvmfs) Parsing config file /cvmfs/config-osg.opensciencegrid.org/etc/cvmfs/default.conf    [06-30-2021 13:12:46 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 28074)    [06-30-2021 13:12:48 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/default.local    [06-30-2021 13:12:48 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 28077)    [06-30-2021 13:12:50 CDT]<br/>(cvmfs) Parsing config file /cvmfs/config-osg.opensciencegrid.org/etc/cvmfs/domain.d/cern.ch.conf    [06-30-2021 13:12:50 CDT]<br/>(cvmfs) execve'd /bin/sh (PID: 28086)    [06-30-2021 13:12:51 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/domain.d/cern.ch.conf    [06-30-2021 13:12:51 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/domain.d/cern.ch.local    [06-30-2021 13:12:51 CDT]<br/>(cvmfs) Parsing config file /cvmfs/config-osg.opensciencegrid.org/etc/cvmfs/config.d/atlas.cern.ch.conf    [06-30-2021 13:12:51 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/config.d/atlas.cern.ch.conf    [06-30-2021 13:12:51 CDT]<br/>(cvmfs) Parsing config file /etc/cvmfs/config.d/atlas.cern.ch.local    [06-30-2021 13:12:51 CDT]</pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(13:20:37)</span> <b>andrew.melo:</b></span> I don't get it, <tt>/etc/cvmfs/default.d/60-osg.conf</tt> is like 5 lines of bash, and it's just assigning variables, how is it taking nearly 2 seconds to parse/execute?<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:21:39)</span> <b>andrew.melo:</b></span> Ohhhhhhhh<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:21:55)</span> <b>andrew.melo:</b></span> I bet this<br/><pre>CVMFS_CONFIG_REPOSITORY=<a href="http://config-osg.opensciencegrid.org">config-osg.opensciencegrid.org</a></pre><br/>is a magic word<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:22:14)</span> <b>andrew.melo:</b></span> to load <tt>/cvmfs/config-osg.opensciencegrid.org/</tt><br/>
<span style="color: #43761b"><span style="font-size: small">(13:24:27)</span> <b>blin:</b></span> yup<br/>
<span style="color: #a72f79"><span style="font-size: small">(13:25:42)</span> <b>andrew.melo:</b></span> ok, so why is THAT taking so long, the config-osg mount has been up since Jun12, so it's not like it's waiting for the config mount to come up<br/>
<span style="color: #a72f79"><span style="font-size: small">(14:56:05)</span> <b>andrew.melo:</b></span> when you run cvmfs_config showconfig, is it doing the same parsing, or is it asking the existing processes for what their configs are<br/>
<span style="color: #a63024"><span style="font-size: small">(15:15:06)</span> <b>miwalls:</b></span> <tt>cvmfs_config showconfig</tt> parses directly from /etc/cvmfs/ in my experience.<br/>
<span style="color: #a63024"><span style="font-size: small">(15:16:31)</span> <b>miwalls:</b></span> As an example it uses these two repositories in this file. Even though a lot are mounted in general in my case due to monitoring.<br/><pre>/etc/cvmfs/default.local <br/>CVMFS_REPOSITORIES="<a href="http://oasis.opensciencegrid.org">oasis.opensciencegrid.org</a>,<a href="http://cms.cern.ch">cms.cern.ch</a>"</pre><br/>
</body>
</html>
