<!DOCTYPE html>
<html>
<head>
<title>Wed Sep 4, 2019 : #rift-osg (osg)</title>
</head>
<body>
<h3>Wed Sep 4, 2019 : #rift-osg (osg)</h3>
<span style="color: #53b759"><span style="font-size: small">(13:34:40)</span> <b>isfiligoi:</b></span> Found another example of RIFT job that does not use any GPU:<br/><pre><br/>ligo     10098 10094  0 04:28 ?        00:00:00         /bin/bash /var/lib/condor/execute/dir_10094/condor_exec.exe -v std -name gfactory_instance -entry Glow_US_UCSD_xcache_gpu -clientname osg-ligo-1-t2-ucsd-edu_OSG_gWMSFrontend.main-gpu -schedd <a href="mailto:schedd_glideins6@gfactory-2.opensciencegrid.org">schedd_glideins6@gfactory-2.opensciencegrid.org</a> -proxy None -factory OSG -web <a href="http://gfactory-2.opensciencegrid.org/factory/stage">http://gfactory-2.opensciencegrid.org/factory/stage</a> -sign 8cf8cf9fbccfddbc6cea17800ea49e3f2ddb4e20 -signentry 428ac488b2863867e981531e8f781a169a5c042a -signtype sha1 -descript description.j927zU.cfg -descriptentry description.j927zU.cfg -dir . -param_GLIDEIN_Client osg-ligo-1-t2-ucsd-edu_OSG_gWMSFrontend.main-gpu -submitcredid 534414 -slotslayout fixed -clientweb <a href="http://osg-ligo-1.t2.ucsd.edu/vofrontend/stage">http://osg-ligo-1.t2.ucsd.edu/vofrontend/stage</a> -clientsign f7c4c101ca82cf83373662db2657d7133f0843bb -clientsigntype sha1 -clientdescript description.j8u71g.cfg -clientgroup main-gpu -clientwebgroup <a href="http://osg-ligo-1.t2.ucsd.edu/vofrontend/stage/group_main-gpu">http://osg-ligo-1.t2.ucsd.edu/vofrontend/stage/group_main-gpu</a> -clientsigngroup bcb79ff513fd79d82e4d8680fb04e530e5da34d3 -clientdescriptgroup description.j8u71g.cfg -param_CONDOR_VERSION 8.dot,8.dot,x -param_GLIDEIN_CLAIM_WORKLIFE 10800 -param_GLIDEIN_Job_Max_Time 36200 -param_GLIDECLIENT_ReqNode gfactory.minus,2.dot,opensciencegrid.dot,org -param_GLIDECLIENT_Rank 1 -param_GLIDEIN_Report_Failed NEVER -param_MIN_DISK_GBS 1 -param_UPDATE_COLLECTOR_WITH_TCP True -param_GLIDEIN_Glexec_Use NEVER -param_GLIDEIN_Max_Idle 2400 -param_GLIDEIN_Monitoring_Enabled False -param_CONDOR_ARCH default -param_OSG_SINGULARITY_EL7_PERCENT 100 -param_STARTD_JOB_ATTRS x509userproxysubject.comma,x509UserProxyFQAN.comma,x509UserProxyVOName.comma,x509UserProxyEmail.comma,x509UserProxyExpiration.comma,ProjectName -param_USE_MATCH_AUTH True -param_CONDOR_OS default -param_GLIDEIN_Collector osg.minus,ligo.minus,1.dot,t2.dot,ucsd.dot,edu.colon,9620.minus,9630 -cluster 573229 -subcluster 0<br/>ligo     18287 10098  0 04:29 ?        00:00:00           /bin/bash /var/lib/condor/execute/dir_10094/glide_tTQxC5/main/condor_startup.sh glidein_config<br/>ligo     19292 18287  0 04:29 ?        00:00:15             /var/lib/condor/execute/dir_10094/glide_tTQxC5/main/condor/sbin/condor_master -f -pidfile /var/lib/condor/execute/dir_10094/glide_tTQxC5/condor_master2.pid<br/>ligo     19294 19292  0 04:29 ?        00:00:04               condor_procd -A /var/lib/condor/execute/dir_10094/glide_tTQxC5/log/procd_address -L /var/lib/condor/execute/dir_10094/glide_tTQxC5/log/ProcLog -R 1000000 -S 60 -C 3004<br/>ligo     19295 19292  0 04:29 ?        00:00:54               condor_startd -f<br/>ligo     20716 19295  0 04:31 ?        00:00:14                 condor_starter -f -a slot1_1 <a href="http://ldas-osg.ligo.caltech.edu">ldas-osg.ligo.caltech.edu</a><br/>ligo     20772 20716  0 04:31 ?        00:00:00                   Singularity runtime parent<br/>ligo     21340 20772 99 04:31 ?        14:02:07                     python /opt/lscsoft/rift/MonteCarloMarginalizeCode/Code/integrate_likelihood_extrinsic_batchmode --output-file CME_out-39550-14846076-1.xml --event 39550 --n-chunk 10000 --time-marginalization --reference-freq 20.0 --adapt-weight-exponent 0.1 --event-time 1000000000 --save-P 0.1 --cache-file local.cache --fmin-template 10 --n-max 4000000 --fmax 1900 --save-deltalnL inf --l-max 2 --n-eff 300 --approximant SEOBNRv4 --adapt-floor-level 0.1 --maximize-only --d-max 4000 --d-min 1500 --psd-file H1=H1-psd.xml.gz --psd-file L1=L1-psd.xml.gz --psd-file V1=V1-psd.xml.gz --channel-name H1=FAKE-STRAIN --channel-name L1=FAKE-STRAIN --channel-name V1=FAKE-STRAIN --inclination-cosine-sampler --declination-cosine-sampler --no-adapt-after-first --no-adapt-distance --srate 4096 --fmin-ifo H1=20 --fmin-ifo L1=20 --fmin-ifo V1=20 --data-start-time 999999986.0 --data-end-time 1000000002.0 --inv-spec-trunc-time 0 --window-shape 0.05 --vectorized --gpu --n-events-to-analyze 50 --sim-xml .//overlap-grid-0.xml.gz<br/></pre><br/>
<span style="color: #53b759"><span style="font-size: small">(13:34:55)</span> <b>isfiligoi:</b></span> according to our monitoring, no GPu was used in the past 4 hours<br/>
<span style="color: #53b759"><span style="font-size: small">(13:36:29)</span> <b>isfiligoi:</b></span> GlobalJobId = “<a href="http://ldas-osg.ligo.caltech.edu#14846076.1#1567460382">ldas-osg.ligo.caltech.edu#14846076.1#1567460382</a>”<br/>
<span style="color: #53b759"><span style="font-size: small">(13:37:07)</span> <b>isfiligoi:</b></span> it definitely had requested a GPU<br/><pre><br/>RequestGPUs = 1<br/></pre><br/>
<span style="color: #a2a5dc"><span style="font-size: small">(13:38:20)</span> <b>james.clark:</b></span> wow, let me pass that on. apologies, this is clearly absurd<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(13:41:24)</span> <b>james.clark:</b></span> @isfiligoi just to check, are *any* jobs using GPU, even if it's with poor efficiency?<br/>
<span style="color: #53b759"><span style="font-size: small">(13:43:13)</span> <b>isfiligoi:</b></span> not sure… let me check<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(13:43:43)</span> <b>james.clark:</b></span> I ask because the RIFT software will fallback to numpy if cupy fails.  first thing i can certainly check (beyond pointing this out to the RIFT folks) is that there are no problems in the container with cupy<br/>
<span style="color: #53b759"><span style="font-size: small">(13:43:48)</span> <b>isfiligoi:</b></span> could use better monitoring on my side :disappointed:<br/>
<span style="color: #53b759"><span style="font-size: small">(13:44:26)</span> <b>isfiligoi:</b></span> anyway, any easy way to check on the WN if it is using the wrong numpy?<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(13:46:03)</span> <b>james.clark:</b></span> yep - the log does print that information.  is the job id buried in there somewhere?  i might be able to dig out where/who this is running..<br/>
<span style="color: #53b759"><span style="font-size: small">(13:47:13)</span> <b>isfiligoi:</b></span> this one is using some GPU, but very little<br/><pre><br/>GlobalJobId = "<a href="http://ldas-osg.ligo.caltech.edu#14846290.1#1567460423">ldas-osg.ligo.caltech.edu#14846290.1#1567460423</a>"<br/></pre><br/>
<span style="color: #53b759"><span style="font-size: small">(13:47:39)</span> <b>isfiligoi:</b></span> @james.clark See above for the jobid (“<a href="http://ldas-osg.ligo.caltech.edu#14846076.1">ldas-osg.ligo.caltech.edu#14846076.1</a>)<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(13:48:06)</span> <b>james.clark:</b></span> :thumbsup: i'll see what i can dig out<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(13:55:09)</span> <b>james.clark:</b></span> well, this is weird.  *that* job was at least able to import and use cupy, as far as i can see.  but i do see other jobs in that workflow where the import failed.  digging further..<br/>
<span style="color: #53b759"><span style="font-size: small">(13:57:02)</span> <b>isfiligoi:</b></span> This is what Condor sees:<br/><pre><br/>no gpu use<br/>[root@osg-wn-gpu-opt-86b76cdc78-gdmpv glide_tTQxC5]# cat <a href="http://gpu.ad">gpu.ad</a> <br/>CUDACapability=1024.64<br/>CUDAClockMhz=0.00<br/>CUDAComputeUnits=0<br/>CUDACoresPerCU=192<br/>CUDADeviceName="GeForce GTX 1070"<br/>CUDADriverVersion=10.0<br/>CUDAECCEnabled=true<br/>CUDAGlobalMemoryMb=7272198376950<br/>CUDAOpenCLVersion=1.2<br/>CUDARuntimeVersion=10.0<br/>some gpu use<br/>[root@osg-wn-gpu-opt-86b76cdc78-wnxq2 glide_MGJG37]# cat <a href="http://gpu.ad">gpu.ad</a> <br/>CUDACapability=1024.64<br/>CUDAClockMhz=0.00<br/>CUDAComputeUnits=0<br/>CUDACoresPerCU=192<br/>CUDADeviceName="GeForce RTX 2080 Ti"<br/>CUDADriverVersion=10.10<br/>CUDAECCEnabled=true<br/>CUDAGlobalMemoryMb=10097330495722<br/>CUDAOpenCLVersion=1.2<br/>CUDARuntimeVersion=10.0<br/></pre><br/>
<span style="color: #a2a5dc"><span style="font-size: small">(14:00:46)</span> <b>james.clark:</b></span> If i gave you these other jobs' ids, would you be able to check their GPU usage?<br/>
<span style="color: #53b759"><span style="font-size: small">(14:01:07)</span> <b>isfiligoi:</b></span> probably<br/>
<span style="color: #53b759"><span style="font-size: small">(14:01:38)</span> <b>isfiligoi:</b></span> if you know the node they are running, that would be the easiest<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(14:02:05)</span> <b>james.clark:</b></span> thanks - it looks like <tt>14846300.0</tt> and <tt>14846076.1</tt> show the warning that cupy is unavailable.   ah ok, 1 second, i think i can find that<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(14:04:22)</span> <b>james.clark:</b></span> hmm.  actually, it looks like those jobs were evicted and then aborted by the user..  ah, i just got a response from the user..hold on<br/>
<span style="color: #53b759"><span style="font-size: small">(14:06:11)</span> <b>isfiligoi:</b></span> FYI: Just checked <a href="http://ldas-osg.ligo.caltech.edu#14846076.1">ldas-osg.ligo.caltech.edu#14846076.1</a>, aka node osg-wn-gpu-opt-86b76cdc78-gdmpv<br/>and I am able to import cupy iinside the container<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(14:06:51)</span> <b>james.clark:</b></span> starting to look like there's a user environment issue involved..<br/>
<span style="color: #53b759"><span style="font-size: small">(14:07:03)</span> <b>isfiligoi:</b></span> ah, that would explain<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(14:07:07)</span> <b>james.clark:</b></span> Jake's just removed his jobs btw<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(14:08:08)</span> <b>james.clark:</b></span> yep - submitted from inside a virtualenv.  that's not good<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(14:21:30)</span> <b>james.clark:</b></span> i've suggested a) a modification to optionally use GPUs and have the code fail if there's a cupy failure, rather than falling back to numpy and b) they resubmit with <tt>-maxjobs 5</tt> for a limited test to see if the problem repeats<br/>
</body>
</html>
