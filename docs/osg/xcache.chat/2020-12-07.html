<!DOCTYPE html>
<html>
<head>
<title>Mon Dec 7, 2020 : #xcache (osg)</title>
</head>
<body>
<h3>Mon Dec 7, 2020 : #xcache (osg)</h3>
<span style="color: #c386df"><span style="font-size: small">(14:09:33)</span> <b>matyas:</b></span> Should humans be able to access protected data in origins? Right now we have this snippet in LIGO.yaml:<br/><pre>DataFederations:<br/>  StashCache:<br/>    Namespaces:<br/>      /user/ligo:<br/>        - FQAN: /osg/ligo</pre><br/>which says that people with the /osg/ligo FQAN should be able to access stuff in the /user/ligo namespace. The Authfile generated for caches lets them do that, but the Authfile generated for origins does not.<br/>
<span style="color: #c386df"><span style="font-size: small">(14:09:52)</span> <b>matyas:</b></span> Is that what we want?<br/>
<span style="color: #235e5b"><span style="font-size: small">(14:12:45)</span> <b>dweitzel:</b></span> I _think_ origins should be accessed only by the caches.  proxies are not propagated.<br/>
<span style="color: #235e5b"><span style="font-size: small">(14:12:57)</span> <b>dweitzel:</b></span> this is different with tokens, tokens are actually propagated.<br/>
<span style="color: #235e5b"><span style="font-size: small">(14:13:17)</span> <b>dweitzel:</b></span> So the authfile for the origin should only have entries for the cache DNs<br/>
<span style="color: #235e5b"><span style="font-size: small">(14:13:21)</span> <b>dweitzel:</b></span> I _think_<br/>
<span style="color: #c386df"><span style="font-size: small">(14:17:22)</span> <b>matyas:</b></span> So what's a good way to test that directories are being correctly exported for authenticated origins? I have <a href="https://opensciencegrid.org/docs/data/stashcache/install-origin/#testing-directory-export">https://opensciencegrid.org/docs/data/stashcache/install-origin/#testing-directory-export</a> but that's not going to work if the human can't get direct access.<br/>
<span style="color: #c386df"><span style="font-size: small">(14:17:35)</span> <b>matyas:</b></span> (This is for Andres's ticket.)<br/>
<span style="color: #e96699"><span style="font-size: small">(16:10:55)</span> <b>lincoln:</b></span> hi folks, how do i confirm that <tt>stashcp</tt> is pulling from the closest cache?<br/>
<span style="color: #e96699"><span style="font-size: small">(16:14:24)</span> <b>lincoln:</b></span> I'm working with the GATech folks, we would like to confirm that their cache is happy and serving files to their local cluster.<br/>
<span style="color: #235e5b"><span style="font-size: small">(16:15:09)</span> <b>dweitzel:</b></span> I think there's a <tt>--closest</tt> flag that just calculates and prints out what it thinks is the closest cache.<br/>
<span style="color: #235e5b"><span style="font-size: small">(16:15:38)</span> <b>dweitzel:</b></span> You will have to log into somewhere nearby to run it.<br/>
<span style="color: #e96699"><span style="font-size: small">(16:17:28)</span> <b>lincoln:</b></span> ah wonderful<br/>
<span style="color: #e96699"><span style="font-size: small">(16:17:31)</span> <b>lincoln:</b></span> thanks Derek!<br/>
<span style="color: #a63024"><span style="font-size: small">(16:58:59)</span> <b>efajardo:</b></span> Hi @blin I found an annoying<br/>
<span style="color: #a63024"><span style="font-size: small">(16:59:11)</span> <b>efajardo:</b></span> nbeahviour<br/>
<span style="color: #a63024"><span style="font-size: small">(16:59:16)</span> <b>efajardo:</b></span> from the xcache image<br/>
<span style="color: #a63024"><span style="font-size: small">(16:59:30)</span> <b>efajardo:</b></span> even though I do not have <tt>/xcache/data1</tt> in my partitions<br/>
<span style="color: #a63024"><span style="font-size: small">(16:59:49)</span> <b>efajardo:</b></span> the iamge creates and then xrootd starts using it<br/>
<span style="color: #a63024"><span style="font-size: small">(17:00:09)</span> <b>efajardo:</b></span> I think this is the problematic part of the code<br/>
<span style="color: #a63024"><span style="font-size: small">(17:00:13)</span> <b>efajardo:</b></span> <pre>[root@xcache-11 image-config.d]# cat 10-single-host-disk.sh<br/>#!/bin/bash<br/><br/># If the user is mounting a single disk onto /xcache, create oss.localroot for them<br/># (image default: /xcache/namespace).<br/>namespace_dir="$XC_ROOTDIR"<br/>mkdir -p "$namespace_dir"<br/><br/># Ensure that data and meta disk dirs exist using the prescribed format<br/># This allows users to easily transition to a multi-disk setup<br/>for dirtype in meta data; do<br/>    # Requires $XC_ROOT_DIR to be set in container environment, which<br/>    # is set by default in the atlas-xcache, cms-xcache, stash-cache,<br/>    # and stash-origin images. <a href="http://oss.space">oss.space</a> directives can look like:<br/>    # <a href="http://oss.space">oss.space</a> data /xcache/data*<br/>    # <a href="http://oss.space">oss.space</a> meta /xcache/disk*<br/>    space_dirs=$(cconfig -c "/etc/xrootd/xrootd-$XC_IMAGE_NAME.cfg" 2&gt;&amp;1 \<br/>                     | awk "/^<a href="http://oss.space">oss.space</a> $dirtype/ {print \$3}")<br/><br/>    # If <a href="http://oss.space">oss.space</a> dirs from the config don't already exist, create<br/>    # one. We use 'ls -l' here since "$space_dirs" can include<br/>    # wildcards (*).<br/>    # N.B. As long as a single path specified in an <a href="http://oss.space">oss.space</a><br/>    # directive exists, XRootD is happy<br/>    if [[ -z $(ls -l "$space_dirs" 2&gt; /dev/null) ]]; then<br/>        default_dir="/xcache/$dirtype"1<br/>        mkdir -p "$default_dir"<br/>    fi<br/>done</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(17:02:23)</span> <b>blin:</b></span> @efajardo are you specifying your own <tt><a href="http://oss.space">oss.space</a> data</tt> directive?<br/>
<span style="color: #43761b"><span style="font-size: small">(17:02:54)</span> <b>blin:</b></span> because it shouldn't create/use it if you're specifying your own<br/>
<span style="color: #a63024"><span style="font-size: small">(17:03:05)</span> <b>efajardo:</b></span> nop<br/>
<span style="color: #a63024"><span style="font-size: small">(17:03:06)</span> <b>efajardo:</b></span> I am not<br/>
<span style="color: #a63024"><span style="font-size: small">(17:03:08)</span> <b>efajardo:</b></span> <pre> cconfig -c "/etc/xrootd/xrootd-cms-xcache.cfg" <br/>xrd.port 1094<br/>all.role server<br/>continue /etc/xrootd/config.d<br/>Config continuing with file /etc/xrootd/config.d/10-common-site-local.cfg ...<br/>Config continuing with file /etc/xrootd/config.d/10-docker-env-var.cfg ...<br/>Config continuing with file /etc/xrootd/config.d/10-xrootd-lcmaps.cfg ...<br/>Config continuing with file /etc/xrootd/config.d/30-cms-xcache-authz.cfg ...<br/>xrd.allow host * <br/>sec.protocol /usr/lib64 gsi -certdir:/etc/grid-security/certificates -cert:/etc/grid-security/xrd/xrdcert.pem -key:/etc/grid-security/xrd/xrdkey.pem -crl:1 -authzfun:libXrdLcmaps.so -authzfunparms:lcmapscfg=/etc/xrootd/lcmaps.cfg,loglevel=1,no-authz -gmapopt:10 -gmapto:0 <br/>acc.authdb /etc/xrootd/Authfile-cms-xcache <br/>sec.protbind * gsi <br/>ofs.authorize 1 <br/>acc.audit deny grant <br/>xrootd.seclib /usr/lib64/libXrdSec.so <br/>Config continuing with file /etc/xrootd/config.d/40-cms-xcache-plugin.cfg ...<br/>ofs.osslib libXrdPss.so <br/>pss.cachelib libXrdFileCache.so <br/>pss.origin <a href="http://redirector.osgstorage.org:1094">redirector.osgstorage.org:1094</a> <br/>pss.setopt ParallelEvtLoop 10 <br/>pss.setopt RequestTimeout 25 <br/>pss.setopt ConnectTimeout 25 <br/>pss.setopt ConnectionRetry 2 <br/>pfc.blocksize 512k <br/>pfc.ram 12g <br/>pfc.prefetch 10 <br/>pfc.diskusage 0.95 0.97 <br/>Config continuing with file /etc/xrootd/config.d/40-xcache-auth.cfg ...<br/>Config continuing with file /etc/xrootd/config.d/40-xrootd-lcmaps.cfg ...<br/>Config continuing with file /etc/xrootd/config.d/50-cms-xcache-paths.cfg ...<br/>all.export /store <br/>Config continuing with file /etc/xrootd/config.d/50-docker-paths.cfg ...<br/>pfc.spaces data meta <br/><a href="http://oss.space">oss.space</a> meta /xcache/meta* <br/><a href="http://oss.space">oss.space</a> data /xcache/data* <br/>Config continuing with file /etc/xrootd/config.d/50-osg-http.cfg ...<br/>Config continuing with file /etc/xrootd/config.d/50-osg-monitoring.cfg ...<br/>all.sitename UCSD-XCACHE <br/>xrd.report <a href="http://xrd-report.osgstorage.org:9931">xrd-report.osgstorage.org:9931</a> <br/>xrootd.monitor all auth flush 30s window 5s fstat 60 lfn ops xfr 5 dest redir fstat info user <a href="http://xrd-report.osgstorage.org:9930">xrd-report.osgstorage.org:9930</a> dest fstat info user <a href="http://xrd-mon.osgstorage.org:9930">xrd-mon.osgstorage.org:9930</a> <br/>Config continuing with file /etc/xrootd/config.d/50-osg-paths.cfg ...<br/>all.adminpath /var/spool/xrootd <br/>all.pidpath /run/xrootd <br/>oss.localroot /xcache/namespace <br/>Config continuing with file /etc/xrootd/config.d/90-cms-xcache-disks.cfg ...<br/>Config continuing with file /etc/xrootd/config.d/90-cms-xcache-local-redirector.cfg ...<br/>Config continuing with file /etc/xrootd/config.d/90-xcache-logging.cfg ...<br/>xrootd.trace emsg login stall redirect <br/>pfc.trace info <br/>pss.setopt DebugLevel 1 <br/>Config continuing with file /etc/xrootd/config.d/95-cms-xcache-logging.cfg ...<br/>xrootd.trace emsg login stall <br/>xrd.trace conn <br/>ofs.trace delay <br/>pfc.trace debug <br/>Config continuing with file /etc/xrootd/config.d/95-local-ucsd.cfg ...<br/>all.manager all <a href="http://xrootd.t2.ucsd.edu:2041">xrootd.t2.ucsd.edu:2041</a><br/>all.manager <a href="http://xcache.ultralight.org:2041">xcache.ultralight.org:2041</a><br/>xrootd.monitor all auth flush 30s window 5s fstat 60 lfn ops xfr 5 dest files io info user <a href="http://xrootd.t2.ucsd.edu:9930">xrootd.t2.ucsd.edu:9930</a> dest fstat info user <a href="http://xrd-mon.osgstorage.org:9930">xrd-mon.osgstorage.org:9930</a> </pre><br/>
<span style="color: #a63024"><span style="font-size: small">(17:03:22)</span> <b>efajardo:</b></span> I thought that was the whole point of <tt>/etc/xrootd/config.d/50-docker-paths.cfg</tt><br/>
<span style="color: #43761b"><span style="font-size: small">(17:07:36)</span> <b>blin:</b></span> if you don't specify any directives, it'll create space and meta dirs for you<br/>
<span style="color: #43761b"><span style="font-size: small">(17:08:13)</span> <b>blin:</b></span> with the idea being that you can more easily switch to a multidisk setup further down the line<br/>
<span style="color: #a63024"><span style="font-size: small">(17:08:27)</span> <b>efajardo:</b></span> but I already have a mutlidisk setup<br/>
<span style="color: #a63024"><span style="font-size: small">(17:08:32)</span> <b>efajardo:</b></span> I have<br/>
<span style="color: #a63024"><span style="font-size: small">(17:08:55)</span> <b>efajardo:</b></span> It just doesnâ€™t include <tt>/xcache/data1</tt><br/>
<span style="color: #a63024"><span style="font-size: small">(17:09:03)</span> <b>efajardo:</b></span> and that script is creating it against my will<br/>
<span style="color: #a63024"><span style="font-size: small">(17:09:05)</span> <b>efajardo:</b></span> <pre>df -h<br/>Filesystem               Size  Used Avail Use% Mounted on<br/>overlay                  124G   47G   78G  38% /<br/>tmpfs                     64M     0   64M   0% /dev<br/>tmpfs                     24G     0   24G   0% /sys/fs/cgroup<br/>/dev/mapper/vg1-root     124G   47G   78G  38% /xcache<br/>/dev/mapper/vg12-data11  2.8T  2.7T  118G  96% /xcache/data11<br/>/dev/mapper/vg8-data7    2.8T  2.7T  119G  96% /xcache/data7<br/>/dev/mapper/vg4-data3    2.8T  2.7T  117G  96% /xcache/data3<br/>/dev/mapper/vg7-data6    2.8T  2.7T  102G  97% /xcache/data6<br/>/dev/mapper/vg5-data4    2.8T  2.7T  118G  96% /xcache/data4<br/>/dev/mapper/vg6-data5    2.8T  2.7T  115G  96% /xcache/data5<br/>/dev/mapper/vg10-data9   2.8T  2.7T  117G  96% /xcache/data9<br/>/dev/mapper/vg9-data8    2.8T  2.7T  118G  96% /xcache/data8<br/>/dev/mapper/vg11-data10  2.8T  2.7T  118G  96% /xcache/data10<br/>shm                       64M     0   64M   0% /dev/shm<br/>tmpfs                     24G   12K   24G   1% /run/secrets/kubernetes.io/serviceaccount<br/>tmpfs                     24G     0   24G   0% /proc/acpi<br/>tmpfs                     24G     0   24G   0% /proc/scsi<br/>tmpfs                     24G     0   24G   0% /sys/firmware</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(17:11:11)</span> <b>blin:</b></span> what's the output of this command?<br/><pre>cconfig -c "/etc/xrootd/xrootd-cms-xcache.cfg" 2&gt;&amp;1 \<br/>                     | awk "/^<a href="http://oss.space">oss.space</a> data/ {print \$3}"</pre><br/><br/>
<span style="color: #a63024"><span style="font-size: small">(17:11:28)</span> <b>efajardo:</b></span> <pre>cconfig -c "/etc/xrootd/xrootd-cms-xcache.cfg" 2&gt;&amp;1 \<br/>&gt;                      | awk "/^<a href="http://oss.space">oss.space</a> data/ {print \$3}"<br/>/xcache/data*</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(17:12:45)</span> <b>blin:</b></span> and <tt>ls -l /xcache/data* 2&gt; /dev/null</tt>?<br/>
<span style="color: #a63024"><span style="font-size: small">(17:13:12)</span> <b>efajardo:</b></span> <pre>ls -l /xcache/data* 2&gt; /dev/null<br/>/xcache/data1:<br/>total 0<br/>drwxr-xr-x 2 xrootd xrootd 6 Dec  7 22:57 data<br/><br/>/xcache/data10:<br/>total 4<br/>drwxr-xr-x 130 xrootd xrootd 4096 Nov 24 18:29 data<br/>drwxr-xr-x   3 xrootd xrootd   18 Nov 13  2019 xcache<br/><br/>/xcache/data11:<br/>total 4<br/>drwxr-xr-x 131 xrootd xrootd 4096 Dec  3 23:37 data<br/>drwxr-xr-x   3 xrootd xrootd   26 Nov 13  2019 xcache<br/><br/>/xcache/data3:<br/>total 4<br/>drwxr-xr-x  130 xrootd xrootd 4096 Nov 23 19:27 data<br/>drwxr-x---.   2 xrootd xrootd    6 Nov  8  2019 public<br/>drwxr-xr-x    3 xrootd xrootd   26 Nov 13  2019 xcache<br/><br/>/xcache/data4:<br/>total 4<br/>drwxr-xr-x  130 xrootd xrootd 4096 Nov 22 21:31 data<br/>drwxr-x---.   2 xrootd xrootd    6 Nov  8  2019 public<br/>drwxr-xr-x    3 xrootd xrootd   26 Nov 13  2019 xcache<br/><br/>/xcache/data5:<br/>total 4<br/>drwxr-xr-x  131 xrootd xrootd 4096 Dec  5 00:14 data<br/>drwxr-x---.   2 xrootd xrootd    6 Nov  8  2019 public<br/>drwxr-xr-x    3 xrootd xrootd   26 Nov 13  2019 xcache<br/><br/>/xcache/data6:<br/>total 4<br/>drwxr-xr-x  130 xrootd xrootd 4096 Dec  2 22:39 data<br/>drwxr-x---.   2 xrootd xrootd    6 Nov  8  2019 public<br/>drwxr-xr-x    3 xrootd xrootd   26 Nov 13  2019 xcache<br/><br/>/xcache/data7:<br/>total 4<br/>drwxr-xr-x 130 xrootd xrootd 4096 Nov 23 19:24 data<br/>drwxr-xr-x   3 xrootd xrootd   18 Nov 13  2019 xcache<br/><br/>/xcache/data8:<br/>total 4<br/>drwxr-xr-x 130 xrootd xrootd 4096 Nov 22 02:47 data<br/>drwxr-xr-x   3 xrootd xrootd   18 Nov 13  2019 xcache<br/><br/>/xcache/data9:<br/>total 4<br/>drwxr-xr-x 130 xrootd xrootd 4096 Nov 23 01:22 data<br/>drwxr-xr-x   3 xrootd xrootd   26 Nov 13  2019 xcache</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(17:13:34)</span> <b>blin:</b></span> that seems like it should be workign fine to me<br/>
<span style="color: #a63024"><span style="font-size: small">(17:14:05)</span> <b>efajardo:</b></span> well not cause it creates <tt>/xcache/data1</tt><br/>
<span style="color: #a63024"><span style="font-size: small">(17:14:10)</span> <b>efajardo:</b></span> which was not there<br/>
<span style="color: #43761b"><span style="font-size: small">(17:14:13)</span> <b>blin:</b></span> you could try modifying the script to pass <tt>set -x</tt> and commenting out the dir creation and running it manually<br/>
<span style="color: #a63024"><span style="font-size: small">(17:14:13)</span> <b>efajardo:</b></span> then xrootd starts using it<br/>
<span style="color: #43761b"><span style="font-size: small">(17:14:19)</span> <b>blin:</b></span> yeah i gotchu<br/>
<span style="color: #a63024"><span style="font-size: small">(17:14:27)</span> <b>efajardo:</b></span> then it fills out my SSD<br/>
<span style="color: #43761b"><span style="font-size: small">(17:14:34)</span> <b>blin:</b></span> it just looks fine from what i can tell<br/>
<span style="color: #a63024"><span style="font-size: small">(17:14:35)</span> <b>efajardo:</b></span> which were meant only for the meta<br/>
<span style="color: #43761b"><span style="font-size: small">(17:15:32)</span> <b>blin:</b></span> try running the single disk script with <tt>set -x</tt> and maybe that'll help us find the bug<br/>
<span style="color: #a63024"><span style="font-size: small">(17:15:38)</span> <b>efajardo:</b></span> <pre>[root@xcache-11 image-config.d]# rm -rf /xcache/data1<br/>[root@xcache-11 image-config.d]# ls /xcache/data1<br/>ls: cannot access /xcache/data1: No such file or directory<br/>[root@xcache-11 image-config.d]# ./10-single-host-disk.sh <br/>[root@xcache-11 image-config.d]# ls /xcache/data1</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(17:16:19)</span> <b>blin:</b></span> do you have time to screen share for a second?<br/>
<span style="color: #43761b"><span style="font-size: small">(17:22:55)</span> <b>blin:</b></span> @efajardo ^^<br/>
<span style="color: #43761b"><span style="font-size: small">(17:23:05)</span> <b>blin:</b></span> i was planning on signing off soon otherwise<br/>
<span style="color: #a63024"><span style="font-size: small">(17:23:21)</span> <b>efajardo:</b></span> We can follow this tomorrow<br/>
<span style="color: #a63024"><span style="font-size: small">(17:23:25)</span> <b>efajardo:</b></span> I wil ltrake to get a PR done<br/>
<span style="color: #43761b"><span style="font-size: small">(17:24:09)</span> <b>blin:</b></span> alright, i'll keep an eye out for it<br/>
</body>
</html>
