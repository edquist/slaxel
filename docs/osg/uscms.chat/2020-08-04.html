<!DOCTYPE html>
<html>
<head>
<title>Tue Aug 4, 2020 : #uscms (osg)</title>
</head>
<body>
<h3>Tue Aug 4, 2020 : #uscms (osg)</h3>
<span style="color: #a72f79"><span style="font-size: small">(10:36:22)</span> <b>andrew.melo:</b></span> Is there an easy way to go from a SLURM job ID to the corresponding condor job in the CE?<br/>
<span style="color: #a72f79"><span style="font-size: small">(10:38:18)</span> <b>andrew.melo:</b></span> I see this ad in the job <tt>GridJobId = "batch slurm <a href="http://ce6.accre.vanderbilt.edu">ce6.accre.vanderbilt.edu</a>_9619_<a href="http://ce6.accre.vanderbilt.edu#437544.0#1596554970">ce6.accre.vanderbilt.edu#437544.0#1596554970</a> slurm/20200804/22592901"</tt> and 22592901 is a slurm job id, I just can't write the const expression to search that<br/>
<span style="color: #e06b56"><span style="font-size: small">(10:41:41)</span> <b>jthiltges:</b></span> It's not very pretty. =/<br/><pre>condor_ce_q -const 'regexp("\/22592901$", GridJobId)'</pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(10:43:41)</span> <b>andrew.melo:</b></span> If it works, it's pretty enough :slightly_smiling_face: Thanks<br/>
<span style="color: #a72f79"><span style="font-size: small">(10:47:37)</span> <b>andrew.melo:</b></span> Hmmm, what does this mean?<br/><pre>RemoveReason = "CE job removed by SYSTEM_PERIODIC_REMOVE due to disabled job retries"</pre><br/>
<span style="color: #a72f79"><span style="font-size: small">(10:47:53)</span> <b>andrew.melo:</b></span> Is this saying that the slurm half died and the CE didn't want to resubmit it?<br/>
<span style="color: #a72f79"><span style="font-size: small">(10:50:32)</span> <b>andrew.melo:</b></span> And then <tt>RemoveReason = "JobRouter aborted job (by user condor)"</tt> -- it looks like all the jobs @ Vanderbilt are running for like an hour and then evaporating. I have no idea why<br/>
<span style="color: #e06b56"><span style="font-size: small">(10:50:57)</span> <b>jthiltges:</b></span> Silly question, are they getting into SLURM with the expected TimeLimit?<br/>
<span style="color: #619a4f"><span style="font-size: small">(10:51:29)</span> <b>clundstedt:</b></span> Are they hitting a memory limit and getting booted by the worker?<br/>
<span style="color: #a72f79"><span style="font-size: small">(11:01:11)</span> <b>andrew.melo:</b></span> Yeah, so we have a queue of "nogpfs" nodes (for price reasons, we don't mount GPFS on every node), and it's exclusively used by CMS, and those nodes are scheduled wholenode. Very annoyingly, I just saw that the GridJobId gets set to "undefined" for everything in condor_ce_history :disappointed:<br/>
<span style="color: #a72f79"><span style="font-size: small">(11:21:27)</span> <b>andrew.melo:</b></span> :neutral_face:<br/><pre>08/04/20 11:02:14 [485626] GAHP[485679] &lt;- 'BLAH_JOB_CANCEL 4385478 slurm/20200804/22592521'<br/>08/04/20 11:02:14 [485626] (437385.0) gm state change: GM_SUBMITTED -&gt; GM_CANCEL<br/>08/04/20 11:02:14 [485626] GAHP[485679] &lt;- 'BLAH_JOB_CANCEL 4385479 slurm/20200804/22592499'<br/>08/04/20 11:02:14 [485626] (437377.0) gm state change: GM_SUBMITTED -&gt; GM_CANCEL<br/>08/04/20 11:02:14 [485626] GAHP[485679] &lt;- 'BLAH_JOB_CANCEL 4385480 slurm/20200804/22592498'<br/>08/04/20 11:02:14 [485626] (437369.0) gm state change: GM_SUBMITTED -&gt; GM_CANCEL</pre><br/><br/>
<span style="color: #a72f79"><span style="font-size: small">(11:22:21)</span> <b>andrew.melo:</b></span> <pre>[root@cn1426 slurm]# rtracejob 22592521<br/>+---------------------------+-------------------------------------------+<br/>+ User name: cmspilot       | job ID: 22592521                           <br/>+---------------------------+-------------------------------------------+<br/>+ Account                   | cms                                     <br/>+ Job Name                  | bl_da9f1bf497a0                         <br/>+ State                     | cancelled by 9201                       <br/>+ Exit Code                 | 0:0                                     <br/>+ Requested Time            | 2-00:00:00                              <br/>+ Requested Memory          | 0n                                      <br/>+ Memory Used               | 0                                       <br/>+ CPUs Requested            | 1                                       <br/>+ CPUs Used                 | 1                                       <br/>+ Nodes                     | 1                                       <br/>+ Node List                 | none assigned                           <br/>+ Wait Time                 | 01:00:08                                <br/>+ Run Time                  | 00:00:00                                <br/>+ Submit Time               | 2020-08-04t10:02:07                     <br/>+ Start Time                | 2020-08-04t11:02:15                     <br/>+ End Time                  | 2020-08-04t11:02:15                     <br/>+---------------------------+-------------------------------------------+<br/>+ Today's date              | 2020-08-04 11:21:40<br/>+---------------------------+-------------------------------------------+</pre><br/>(9201 is the cmspilot account)<br/>
<span style="color: #a72f79"><span style="font-size: small">(19:32:17)</span> <b>andrew.melo:</b></span> So I left tail running on the relevant logs ... blah is cancelling the jobs.... I have no idea why, but it's not good. Has any other SLURM site seen something similar with recent condor updates?<br/>
</body>
</html>
