<!DOCTYPE html>
<html>
<head>
<title>Wed Aug 26, 2020 : #icecube-condor (osg)</title>
</head>
<body>
<h3>Wed Aug 26, 2020 : #icecube-condor (osg)</h3>
<span style="color: #c386df"><span style="font-size: small">(14:46:29)</span> <b>matyas:</b></span> Talking to the collector (on the central manager) is the simplest thing to do and doesn't require host networking, just exposing port 9618.<br/>You can get a handle to the collector with <tt>htcondor.Collector("&lt;HOST&gt;:&lt;PORT&gt;")</tt> from the bindings.<br/>
<span style="color: #c386df"><span style="font-size: small">(14:46:42)</span> <b>matyas:</b></span> you can do the equivalent of <tt>condor_status</tt> queries that way.<br/>
<span style="color: #c386df"><span style="font-size: small">(14:47:01)</span> <b>matyas:</b></span> On the other hand, talking to the schedd (on the submit host) is more complicated<br/>
<span style="color: #c386df"><span style="font-size: small">(14:58:28)</span> <b>matyas:</b></span> You don't give the &lt;HOST&gt;:&lt;PORT&gt; of the schedd directly to the bindings; instead you ask the collector to locate it for you, so something like<br/><pre>coll = htcondor.Collector("&lt;HOST&gt;:&lt;PORT&gt;")<br/>schedd_ads = coll.locateAll(htcondor.DaemonTypes.Schedd)<br/>if schedd_ads:<br/>    schedd = htcondor.Schedd(schedd_ads[0])   # get the first schedd<br/>else: ...   # error: couldn't find any schedds</pre><br/><br/>
<span style="color: #c386df"><span style="font-size: small">(15:00:16)</span> <b>matyas:</b></span> If you're not using host networking, then essentially those daemons are behind NAT, and the address of the schedd (from the collector's point of view) is not the same as the address of the schedd from outside.<br/>
<span style="color: #c386df"><span style="font-size: small">(15:01:21)</span> <b>matyas:</b></span> There are a couple of ways around that -- simplest is to use host networking for the schedd.<br/>
<span style="color: #c386df"><span style="font-size: small">(15:03:03)</span> <b>matyas:</b></span> Or, you could run your Python Condor API program from the central manager or the submit host or some other host within the NAT.<br/>
<span style="color: #c386df"><span style="font-size: small">(15:05:55)</span> <b>matyas:</b></span> Or, you could configure the schedd to advertise to the collector via its external IP address. @blin might remember more but I think the magic knob to set (in the config for the submit host) is TCP_FORWARDING_HOST.<br/>
<span style="color: #c386df"><span style="font-size: small">(15:06:14)</span> <b>matyas:</b></span> (Set it to the external IP of the submit host)<br/>
<span style="color: #50a0cf"><span style="font-size: small">(15:06:14)</span> <b>dschultz:</b></span> advanced question: if you wanted to run two condor clusters at the same time (to test glideins, for example), that would require docker networking or something like that, right?<br/>
<span style="color: #50a0cf"><span style="font-size: small">(15:07:18)</span> <b>dschultz:</b></span> because you can't have two collectors both with the same port 9618 on the host<br/>
<span style="color: #c386df"><span style="font-size: small">(15:07:39)</span> <b>matyas:</b></span> Right.<br/>
<span style="color: #c386df"><span style="font-size: small">(15:07:54)</span> <b>matyas:</b></span> But you could also configure the daemons to use different ports<br/>
<span style="color: #50a0cf"><span style="font-size: small">(15:08:53)</span> <b>dschultz:</b></span> that's probably simpler, or at least I can wrap my head around it<br/>
<span style="color: #50a0cf"><span style="font-size: small">(15:09:21)</span> <b>dschultz:</b></span> @jamie.rajewski does this help you at all?<br/>
<span style="color: #43761b"><span style="font-size: small">(15:12:40)</span> <b>blin:</b></span> for a multi-container condor setup, you probably also want to force the daemons to talk to each other over the private IP space:<br/>• config file for the CE container: <a href="https://github.com/slateci/slate-catalog/blob/master/incubator/open-science-ce/open-science-ce/templates/configmap.yaml#L76-L78">https://github.com/slateci/slate-catalog/blob/master/incubator/open-science-ce/open-science-ce/templates/configmap.yaml#L76-L78</a><br/>• config file for the local condor submit: <a href="https://github.com/slateci/slate-catalog/blob/master/incubator/open-science-ce/open-science-ce/templates/configmap.yaml#L190-L192">https://github.com/slateci/slate-catalog/blob/master/incubator/open-science-ce/open-science-ce/templates/configmap.yaml#L190-L192</a><br/>
<span style="color: #43761b"><span style="font-size: small">(15:13:48)</span> <b>blin:</b></span> if you have a public IP + DNS record, for a given daemon, you'll want to set <tt>TCP_FORWARDING_HOST</tt> as Mat said and <tt>NETWORK_HOSTNAME</tt><br/>
<span style="color: #827327"><span style="font-size: small">(15:30:04)</span> <b>jamie.rajewski:</b></span> Thanks everyone for your insight, it is definitely helpful! @matyas I think the concept of running the python API within the NAT sounds the most straightforward, but I don't think that fits our use case here since I will be deploying local versions of the glidein server/client on my machine and then interacting with the multi-condor container setup from that (unless @dschultz thinks it can be done all within the containers?) As David said, the ultimate goal here is to get a test platform set up with the containers to test changes to the pyglidein, so perhaps that context provides a bit more information<br/>
<span style="color: #827327"><span style="font-size: small">(15:30:37)</span> <b>jamie.rajewski:</b></span> @blin I will have a look at that, thanks for the info and I will keep everyone posted<br/>
<span style="color: #827327"><span style="font-size: small">(17:57:49)</span> <b>jamie.rajewski:</b></span> <b>@here</b> A question for everyone: I have all of the containers supposedly set up and configured properly, but I had one question that doesn't seem to have an explanation in the docs. I'm following the example here: <a href="https://github.com/htcondor/htcondor/blob/master/build/docker/services/README.md#example">https://github.com/htcondor/htcondor/blob/master/build/docker/services/README.md#example</a><br/><br/>At the start, they state that they will use the identity of <tt><a href="mailto:dockerworker@example.net">dockerworker@example.net</a></tt>  for the execute node. Does this have to be set to anything in particular? I wasn't sure, so I set it to <tt>dockerworker@jamie</tt> just to test in both the configuration for the central manager like it says, and also the token generation. I couldn't find where the token was stored to as outlined in the docs for <a href="https://htcondor.readthedocs.io/en/v8_9_5/man-pages/condor_token_create.html">https://htcondor.readthedocs.io/en/v8_9_5/man-pages/condor_token_create.html</a><br/>so I just sent it to stdout and saved it in a volume mount. I then mounted it to the submit and execute containers with all the settings outlined in the example, but when I hop on to one of the containers and run <tt>condor_status</tt> I get nothing. When I was messing around and set it incorrectly, it gave me authentication errors, but now that it doesn't that makes me think it is at least partially working?<br/>
<span style="color: #827327"><span style="font-size: small">(18:04:28)</span> <b>jamie.rajewski:</b></span> For reference, I wrote a little script to launch them all:<br/><pre>#!/bin/bash<br/><br/># Central Manager:<br/>docker run --detach -p 9618:9618 --name=cm \<br/>       -v $(pwd -P)/cm/condor_config.local:/etc/condor/condor_config.local \<br/>       -v $(pwd -P)/cm/create_token.sh:/home/create_token.sh \<br/>       -v $(pwd -P)/secrets:/root/secrets \<br/>       htcondor/cm:8.9.7-el7<br/><br/># Generate token and store it in /root/secrets/token<br/>docker exec cm /home/create_token.sh<br/><br/># Submit:<br/>docker run --detach --network host --name=submit \<br/>       -e CONDOR_HOST='localhost:9618' \<br/>       -v $(pwd -P)/secrets:/root/secrets:ro \<br/>       htcondor/submit:8.9.7-el7<br/><br/># Execute:<br/>docker run --detach --network host --name=execute \<br/>       --env-file=$(pwd -P)/execute/env \<br/>       -e CONDOR_HOST='localhost:9618' \<br/>       --cpus=2 --memory-reservation=$(( 4096 * 1048576 )) \<br/>       -v $(pwd -P)/secrets:/root/secrets:ro \<br/>       htcondor/execute:8.9.7-el7</pre><br/>In the <tt>cm</tt> condor_config.local, I just inserted the lines from the example, with the identity at the bottom switched to mine. The create_token.sh script is just<br/><pre>condor_token_create -authz ADVERTISE_MASTER \<br/>         -authz ADVERTISE_STARTD -authz READ -identity dockerworker@jamie \<br/>         &gt;&gt; /root/secrets/token</pre><br/>where the /root/secrets directory was set up on the host as stated in the example. Finally, the <tt>env</tt> file that is mounted to the execute is exactly what is outlined in the guide, with the host modified for my local scenario:<br/><pre>CONDOR_HOST='localhost:9618'<br/>NUM_CPUS=2<br/>MEMORY=4096</pre><br/><br/>
<span style="color: #827327"><span style="font-size: small">(18:06:58)</span> <b>jamie.rajewski:</b></span> Finally, when I enter the submit container and run <tt>condor_status</tt> this is what happens:<br/><pre>jamie@pop-os:~/Documents/testing$ docker exec -ti submit /bin/bash<br/>[root@pop-os /]# condor_status<br/>[root@pop-os /]# </pre><br/>I also checked to make sure the environment variables for the execute container were being set correctly and they were, so I'm at a loss here as to what is going on<br/>
<span style="color: #c386df"><span style="font-size: small">(18:09:10)</span> <b>matyas:</b></span> in addition to the token, you have to make sure that the central manager gives it write access. Look at /etc/condor/config.d/01-security.conf -- you'll see <a href="mailto:dockerworker@example.net">dockerworker@example.net</a> listed in there in several places<br/>
<span style="color: #c386df"><span style="font-size: small">(18:09:45)</span> <b>matyas:</b></span> wait, you already mentioned that.<br/>
<span style="color: #827327"><span style="font-size: small">(18:15:34)</span> <b>jamie.rajewski:</b></span> Yea, for additional context here is the tree layout of my testing directory:<br/><pre>.<br/>├── cm<br/>│   ├── condor_config.local<br/>│   └── create_token.sh<br/>├── execute<br/>│   └── env<br/>├── launch.sh<br/>├── secrets<br/>│   ├── pool_password<br/>│   └── token<br/>└── submit</pre><br/>
<span style="color: #827327"><span style="font-size: small">(18:16:45)</span> <b>jamie.rajewski:</b></span> One thing that I did not do was add the configuration that @blin suggested above as I didnt know exactly how to do that, so I figured I would just start with this example<br/>
<span style="color: #827327"><span style="font-size: small">(18:18:02)</span> <b>jamie.rajewski:</b></span> Perhaps tomorrow I will bundle up my progress and make a public git repo that you guys can poke around with to see if that makes debugging easier than me trying to paste all of my configurations!<br/>
<span style="color: #827327"><span style="font-size: small">(18:18:43)</span> <b>jamie.rajewski:</b></span> The contents of <tt>condor_config.local</tt> :<br/><pre>ALLOW_ADVERTISE_MASTER = \<br/>    $(ALLOW_ADVERTISE_MASTER) \<br/>    $(ALLOW_WRITE_COLLECTOR) \<br/>    dockerworker@jamie<br/>ALLOW_ADVERTISE_STARTD = \<br/>    $(ALLOW_ADVERTISE_STARTD) \<br/>    $(ALLOW_WRITE_COLLECTOR) \<br/>    dockerworker@jamie</pre><br/>
<span style="color: #c386df"><span style="font-size: small">(18:20:39)</span> <b>matyas:</b></span> That might help. I would also suggest adding<br/><pre>COLLECTOR_DEBUG = D_SECURITY:2</pre><br/>to condor_config.local for the cm, and looking at <tt>/var/log/condor/CollectorLog</tt><br/>
</body>
</html>
