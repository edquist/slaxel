<!DOCTYPE html>
<html>
<head>
<title>Fri Oct 4, 2019 : #operations (osg)</title>
</head>
<body>
<h3>Fri Oct 4, 2019 : #operations (osg)</h3>
<span style="color: #e23f99"><span style="font-size: small">(09:48:18)</span> <b>marco.mascheroni:</b></span> Speaking of supporting multiple VOs for the hostedCEs, few things I had in mind.<br/>1) Are you going to generate a default job router configuration fiule based on the osg-configure .ini file? E.g., this need to change:<br/><pre><br/>[root@hosted-ce25 ~]# cat /etc/condor-ce/config.d/02-ce-bosco.conf<br/>###############################################################################<br/>#<br/># HTCondor-CE BOSCO configuration file.<br/>#<br/>###############################################################################<br/><br/># Basic route for submitting to BOSCO<br/># Use osg-configure to set BOSCO_RMS and BOSCO_ENDPOINT<br/>JOB_ROUTER_ENTRIES = \<br/>   [ \<br/>     GridResource = "batch $(BOSCO_RMS) $(BOSCO_ENDPOINT)"; \<br/>     TargetUniverse = 9; \<br/>     name = "Local_BOSCO"; \<br/>     set_default_queue = "grid"; \<br/>   ]<br/></pre><br/>2) What about variables in the 99-local.ini file, things like this will need to point to the homedir of the specific osg01-20 user:<br/><pre><br/>grid_dir = /home/gluex/osg-wn-client/<br/></pre><br/>3) Same thing for the local settings in <tt>/etc/osg/config.d/40-localsettings.ini</tt> (with the difference I manually override them from time to time)? What if I need to specify a path that depends on the user. Can I put $HOME in there and hope is is expanded correctly only at the worker node, for example? On a few places I had to explicitly set X509_CERT_DIR to /home/osgNN/osg-wn-client/etc/grid-security/certificates (you might argue this specific workaround should not be necessary, but what if in the future we will need to set custom variables this way?)<br/>4) Something to think about. I talked to Dirk Hufnagel, Antony Tiradani, and Steve Timm. Fremilab is using HPC resources like NESC, and they are accessing them via bosco+ssh as well (not via hostedCE right now). However, they have (will have) a different ssh key for each VO (Dune, fife, CMS etc), and this seems to be a requirement. They are getting these ssh key on the gwms frontend, and they are short lived keys IIUC (weeks). Right now the ssh key is passed from the frontend to the factory, and the factory directly connect to the cluster head node (the gridtype of the entry in the factory is "batch+slurm" in place of "condor"). I am still not sure if this has an impact on the multiVO work, but I wonder if we need to think about this use case: say that in the future they would like to put a CE in front of these resources, or if they wanted to access TACC resources in the same way (which is currently a hostedCE)..<br/>
<span style="color: #c386df"><span style="font-size: small">(10:36:55)</span> <b>matyas:</b></span> that's a lot of stuff that should probably be in an email<br/>
<span style="color: #c386df"><span style="font-size: small">(10:44:30)</span> <b>matyas:</b></span> osg-configure was really not designed to have what is essentially multiple batch systems on the same CE<br/>
<span style="color: #c386df"><span style="font-size: small">(10:45:41)</span> <b>matyas:</b></span> it would take a lot of retrofitting to get this to work and maybe it would be better to create something new instead of doing that<br/>
<span style="color: #e96699"><span style="font-size: small">(10:49:34)</span> <b>ian_cancercomputer:</b></span> I assume this is different from how a regular CE now can support multiple VOs (or multiple batch systems, for that matter)?  Also is it actually likely that hostedCE's are going to be able to support batch systems other than HTCondor?<br/>
<span style="color: #c386df"><span style="font-size: small">(10:51:09)</span> <b>matyas:</b></span> pretty sure osg-configure can only support multiple batch systems if they're different batch systems (e.g. slurm and condor) and not multiple copies of the same batch system<br/>
<span style="color: #c386df"><span style="font-size: small">(10:51:30)</span> <b>matyas:</b></span> and hosted CEs already support batch systems other than HTCondor<br/>
<span style="color: #c386df"><span style="font-size: small">(11:06:53)</span> <b>matyas:</b></span> @marco.mascheroni everything in [Local Settings] is expanded on the worker node when the job runs so $HOME will get expanded -- but only if $HOME is in the job environment on the execute node which may not always be the case<br/>
<span style="color: #e23f99"><span style="font-size: small">(11:52:03)</span> <b>marco.mascheroni:</b></span> Yes, that should have been an email.. I intended to write only few small things and got carried away :smile:<br/>
<span style="color: #e23f99"><span style="font-size: small">(11:52:32)</span> <b>marco.mascheroni:</b></span> I'll sent it via email as well to you and Brian Lin and Jeff (anyone else I should include?)<br/>
<span style="color: #de5f24"><span style="font-size: small">(12:52:35)</span> <b>ztzhang:</b></span> <a href="mailto:ztzhang@unl.edu">ztzhang@unl.edu</a><br/>
<span style="color: #a63024"><span style="font-size: small">(13:28:05)</span> <b>paschos:</b></span> @jdost321 i updated the notes from Uchicago. Sorry there were three conflicting meetings in the same time slot this week.<br/>
<span style="color: #a63024"><span style="font-size: small">(13:28:19)</span> <b>paschos:</b></span> If you have any questions or you need some clarifications on the notes, let me know.<br/>
</body>
</html>
