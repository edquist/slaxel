<!DOCTYPE html>
<html>
<head>
<title>Tue Dec 22, 2020 : #operations (osg)</title>
</head>
<body>
<h3>Tue Dec 22, 2020 : #operations (osg)</h3>
<span style="color: #385a86"><span style="font-size: small">(11:42:44)</span> <b>jdost321:</b></span> @blin here's the syracuse gpu factory monitoring, I don't see any GLOW pilots claiming real jobs <a href="http://gfactory-2.opensciencegrid.org/factory/monitor/factoryStatus.html?entry=Glow_US_Syracuse2_condor_gpu&amp;frontend=glowVO2_frontend&amp;infoGroup=running&amp;elements=StatusRunningCores,ClientCoresTotal,ClientCoresRunning,ClientCoresIdle,&amp;rra=0&amp;window_min=0&amp;window_max=0&amp;timezone=-8">http://gfactory-2.opensciencegrid.org/factory/monitor/factoryStatus.html?entry=Glow_US_Syra[â€¦]oresIdle,&amp;rra=0&amp;window_min=0&amp;window_max=0&amp;timezone=-8</a><br/>
<span style="color: #385a86"><span style="font-size: small">(11:43:15)</span> <b>jdost321:</b></span> at least since about Dec 14<br/>
<span style="color: #43761b"><span style="font-size: small">(11:44:23)</span> <b>blin:</b></span> i see a huge spike in idle jobs for our GPU group starting yesterday in general<br/>
<span style="color: #43761b"><span style="font-size: small">(11:45:00)</span> <b>blin:</b></span> i did push the change to requiring singularity for icecube groups so maybe our match exprs are off<br/>
<span style="color: #43761b"><span style="font-size: small">(11:45:20)</span> <b>blin:</b></span> do you know if syracuse has singularity?<br/>
<span style="color: #385a86"><span style="font-size: small">(11:45:26)</span> <b>jdost321:</b></span> yeah looks like you're requesting them, and the pilots start up, but user jobs just don't match them<br/>
<span style="color: #385a86"><span style="font-size: small">(11:55:49)</span> <b>jdost321:</b></span> a random pilot log shows <tt>HAS_SINGULARITY = True</tt><br/>
<span style="color: #385a86"><span style="font-size: small">(11:56:18)</span> <b>jdost321:</b></span> let me know if you want to see more env vars<br/>
<span style="color: #43761b"><span style="font-size: small">(11:56:22)</span> <b>blin:</b></span> ah yeah, and it looks like all the GPU pilots have singularity<br/>
<span style="color: #43761b"><span style="font-size: small">(11:57:57)</span> <b>blin:</b></span> and really, all pilots are reporting singularity so i don't think this is related to my change<br/>
<span style="color: #43761b"><span style="font-size: small">(13:32:40)</span> <b>blin:</b></span> well the good thing is that there's use of GPU pilots, generally:<br/><pre>blin@blin-latitude:~$ condor_status -pool <a href="http://glidein2.chtc.wisc.edu">glidein2.chtc.wisc.edu</a> -const 'GLIDECLIENT_Group == "glowGPU"' -total<br/><br/>               Machines Owner Claimed Unclaimed Matched Preempting  Drain<br/><br/>  X86_64/LINUX      219     0      87       132       0          0      0<br/><br/>         Total      219     0      87       132       0          0      0</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(13:41:25)</span> <b>blin:</b></span> @jdost321 @efajardo i'm not entirely sure how to get say a list of jobs that an FE group is matching on but i suspect that we're getting more GPUs because GLOW gpu pilots can accept glow/icecube gpu jobs and icecube has its own specific GPU group, too<br/>
<span style="color: #43761b"><span style="font-size: small">(13:42:51)</span> <b>blin:</b></span> i'm not entirely sure we can avoid this sort of inefficiency with this setup<br/>
<span style="color: #385a86"><span style="font-size: small">(14:01:31)</span> <b>jdost321:</b></span> my worry in that output is the amount unclaimed<br/>
<span style="color: #385a86"><span style="font-size: small">(14:01:32)</span> <b>jdost321:</b></span> is there an analyze query in condor where you can filter only the gpu jobs to see why they don't match?<br/>
<span style="color: #385a86"><span style="font-size: small">(14:01:59)</span> <b>jdost321:</b></span> maybe other requirements for this particular workfow don't fit the syracuse nodes<br/>
<span style="color: #43761b"><span style="font-size: small">(14:10:42)</span> <b>blin:</b></span> I was hoping that there was an easy way to see that through the FE. we've got a lot of schedds and i'm not sure i have access to all of them<br/>
<span style="color: #385a86"><span style="font-size: small">(14:12:30)</span> <b>jdost321:</b></span> ah gotcha. well the fe matchmaking for submission is at a different level, the actual matching of jobs to pilots is all vanilla condor at that point<br/>
<span style="color: #43761b"><span style="font-size: small">(14:15:10)</span> <b>blin:</b></span> yeah but my question is what jobs are causing us to send pilots<br/>
<span style="color: #43761b"><span style="font-size: small">(14:15:51)</span> <b>blin:</b></span> e.g. if all the glow user GPU jobs are all running, that means that the pressure's coming from elsewhere<br/>
<span style="color: #385a86"><span style="font-size: small">(14:17:27)</span> <b>jdost321:</b></span> maybe i have some of that info in the logs of the unmatch pilots<br/>
<span style="color: #385a86"><span style="font-size: small">(14:17:29)</span> <b>jdost321:</b></span> on the factory<br/>
<span style="color: #385a86"><span style="font-size: small">(14:18:38)</span> <b>jdost321:</b></span> if a subset of schedds are in a particular fe group.. i'm seeing this<br/><pre>client_name       = 'chtc2.glowGPU'<br/>client_group      = 'glowGPU'</pre><br/>
<span style="color: #385a86"><span style="font-size: small">(14:19:38)</span> <b>jdost321:</b></span> for all of them<br/>
<span style="color: #43761b"><span style="font-size: small">(14:20:27)</span> <b>blin:</b></span> i'm not sure that narrows it down because the glowGPU group accepts jobs from icecube and glow schedd's<br/>
<span style="color: #385a86"><span style="font-size: small">(14:20:53)</span> <b>jdost321:</b></span> ah i see now what you were saying. right. only would have helped if they were separated<br/>
<span style="color: #385a86"><span style="font-size: small">(14:22:12)</span> <b>jdost321:</b></span> i think from the pilot pov it only knows the group it belongs to, in the logs i don't see any info about the jobs that requested it or the origin schedds<br/>
<span style="color: #43761b"><span style="font-size: small">(14:22:56)</span> <b>blin:</b></span> yeah i figured :disappointed:<br/>
<span style="color: #43761b"><span style="font-size: small">(14:23:13)</span> <b>blin:</b></span> i'll try to poke on the FE end. i was hoping something would pop up in the NegotiatorLog but i don't see anything<br/>
<span style="color: #385a86"><span style="font-size: small">(14:23:41)</span> <b>jdost321:</b></span> maybe @efajardo knows where to look in fe logs<br/>
<span style="color: #a63024"><span style="font-size: small">(14:47:22)</span> <b>efajardo:</b></span> I am sorry<br/>
<span style="color: #a63024"><span style="font-size: small">(14:47:26)</span> <b>efajardo:</b></span> I am lost what is the problem<br/>
<span style="color: #385a86"><span style="font-size: small">(14:48:09)</span> <b>jdost321:</b></span> how do we find from fe logs what user schedd caused the pilot submission<br/>
<span style="color: #385a86"><span style="font-size: small">(14:48:27)</span> <b>jdost321:</b></span> we're starting up lots of gpu pilots for glow that are going 100% unmatched<br/>
<span style="color: #43761b"><span style="font-size: small">(14:57:34)</span> <b>blin:</b></span> hrm, maybe this is the problem?<br/><pre>[2020-12-22 20:54:30,781] DEBUG: glideinFrontendLib:657: Running glidein ids at (u'<a href="http://gfactory-2.opensciencegrid.org">gfactory-2.opensciencegrid.org</a>', 'Glow_US_Syracuse2_condor_gpu@gfactory_instance@OSG', u'<a href="mailto:feglow@gfactory-2.opensciencegrid.org">feglow@gfactory-2.opensciencegrid.org</a>') (total glideins: 0, total jobs 0, cluster matches: 0):<br/>[2020-12-22 20:54:31,254] DEBUG: glideinFrontendElement:893: failed to fetch /var/lib/gwms-frontend/.condor/tokens.d/SU-ITS.token<br/>[2020-12-22 20:54:31,254] DEBUG: glideinFrontendElement:894: Command '/usr/sbin/frontend_condortoken SU-ITS' returned non-zero exit status 127: unable to write 'random state'<br/>mkdir: cannot create directory '~': Permission denied<br/>/usr/sbin/frontend_condortoken: line 36: sudo: command not found</pre><br/>
<span style="color: #a63024"><span style="font-size: small">(15:14:31)</span> <b>efajardo:</b></span> you cannot find that<br/>
<span style="color: #385a86"><span style="font-size: small">(15:25:09)</span> <b>jdost321:</b></span> @efajardo any ideas on how to interpret the token errors ^ ?<br/>
<span style="color: #9e3997"><span style="font-size: small">(15:28:28)</span> <b>bbockelm:</b></span> looks like missing dep on sudo?<br/>
<span style="color: #43761b"><span style="font-size: small">(15:33:22)</span> <b>blin:</b></span> yeah, we could override that in the container for the time being -- @efajardo where do you build the FE image from?<br/>
<span style="color: #a63024"><span style="font-size: small">(15:33:51)</span> <b>efajardo:</b></span> that error is harmeless<br/>
<span style="color: #a63024"><span style="font-size: small">(15:34:07)</span> <b>efajardo:</b></span> but I suggest we use the officail Glideinwms that @didavila build<br/>
<span style="color: #a63024"><span style="font-size: small">(15:34:29)</span> <b>efajardo:</b></span> <a href="https://github.com/glideinWMS/containers/tree/main/frontend">https://github.com/glideinWMS/containers/tree/main/frontend</a><br/>
<span style="color: #43761b"><span style="font-size: small">(15:34:50)</span> <b>blin:</b></span> ah i missed the re-review request diego made<br/>
<span style="color: #43761b"><span style="font-size: small">(16:05:26)</span> <b>blin:</b></span> yeah it's all icecube jobs, there's hardly any glow gpu jobs<br/>
<span style="color: #43761b"><span style="font-size: small">(16:20:01)</span> <b>blin:</b></span> i'm at a loss as to where to go from here: there are 1000s of ice cube jobs from two users and i've spotchecked a bunch of them. one user has jobs that should run on syracuse, another has jobs that are requesting 24gb of memory so i don't think those are triggering pilots to the GPU queue<br/>
<span style="color: #43761b"><span style="font-size: small">(16:23:40)</span> <b>blin:</b></span> the syracuse GPU machines don't appear to show up in the negotiator log for whatever reason<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(16:40:43)</span> <b>didavila:</b></span> @blin if the problem is that jobs are not matching could you do a condor_q -bet -reverse -machine  &lt;GPU MACHINE&gt; &lt;JOB_ID&gt;  ?<br/>
<span style="color: #43761b"><span style="font-size: small">(16:41:27)</span> <b>blin:</b></span> yeah, i did that with some spot checks. there are thousands of potential gpu jobs<br/>
<span style="color: #43761b"><span style="font-size: small">(16:41:35)</span> <b>blin:</b></span> some of them match, some of them don't<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(16:42:27)</span> <b>didavila:</b></span> so what happens if you take one specific Idle job and an unclaimed machine?<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(16:42:53)</span> <b>didavila:</b></span> that command (Including the -reverse -machine args) should do a 1 to 1 comparison<br/>
<span style="color: #43761b"><span style="font-size: small">(16:43:09)</span> <b>blin:</b></span> generally they'll say that the job/machine match but the job hasn't been considered by the negotiator<br/>
<span style="color: #43761b"><span style="font-size: small">(16:43:44)</span> <b>blin:</b></span> <pre>$ condor_q -name <a href="http://sub-1.icecube.wisc.edu">sub-1.icecube.wisc.edu</a> -pool <a href="http://glidein2.chtc.wisc.edu">glidein2.chtc.wisc.edu</a> -better 176823068.0 -machine SURGE-OSG-C7-GPU-10-5-88-10 | tail<br/>176823068.000:  Job has not yet been considered by the matchmaker.<br/><br/><br/>176823068.000:  Run analysis summary ignoring user priority.  Of 3 machines,<br/>      0 are rejected by your job's requirements<br/>      0 reject your job because of their own requirements<br/>      0 match and are already running your jobs<br/>      0 match but are serving other users<br/>      3 are able to run your job</pre><br/>
<span style="color: #73769d"><span style="font-size: small">(16:44:33)</span> <b>tim.theisen:</b></span> The hasn't been considered by the negotiator is a bit of a red herring and the message has been dropped in the current development version.<br/>
<span style="color: #43761b"><span style="font-size: small">(16:44:42)</span> <b>blin:</b></span> and with reverse:<br/><pre>$ condor_q -name <a href="http://sub-1.icecube.wisc.edu">sub-1.icecube.wisc.edu</a> -pool <a href="http://glidein2.chtc.wisc.edu">glidein2.chtc.wisc.edu</a> -better 176823068.0 -reverse -machine SURGE-OSG-C7-GPU-10-5-88-10 | tail<br/>[17]          1  isUndefined(TARGET.estimated_run_hours)<br/>[22]          1  TARGET.Requestgpus &gt;= 1<br/>[26]        now  CurrentTime &lt; GLIDEIN_ToRetire<br/>[29]     always  true<br/>[31]          1  WithinResourceLimits<br/><br/>slot1@glidein_5430_709198524@SURGE-OSG-C7-GPU-10-5-88-10: Run analysis summary of 1 jobs.<br/>    1 (100.00 %) match both slot and job requirements.<br/>    1 match the requirements of this slot.<br/>    1 have job requirements that match this slot.</pre><br/>
<span style="color: #385a86"><span style="font-size: small">(16:44:45)</span> <b>jdost321:</b></span> dumb q just curious are there multiple negotiators for glow / ice cube? is that even possible?<br/>
<span style="color: #43761b"><span style="font-size: small">(16:45:16)</span> <b>blin:</b></span> i only see the one:<br/><pre>$ condor_status -negotiator<br/>Name         LastCycleEnd (Sec)   Slots Submitrs Schedds    Jobs Matches Rejections<br/><br/>NEGOTIATOR    12/22 16:40     7     200       37      12   22547       8         47</pre><br/>
<span style="color: #a2a5dc"><span style="font-size: small">(16:45:21)</span> <b>didavila:</b></span> is there any NEGOTIATOR_SLOT_CONSTRAINT for that Negotiator ?<br/>
<span style="color: #43761b"><span style="font-size: small">(16:46:06)</span> <b>blin:</b></span> nope<br/>
<span style="color: #43761b"><span style="font-size: small">(16:48:56)</span> <b>blin:</b></span> hrmmmm, so the user whose jobs would match the syracuse machines shows up in the negotiator with:<br/><pre>NegotiatorLog:12/22/20 16:47:40   Submitter <a href="mailto:jmicallef@icecube.wisc.edu">jmicallef@icecube.wisc.edu</a> got all it wants; removing it.<br/>NegotiatorLog:12/22/20 16:47:40  resources used by <a href="mailto:jmicallef@icecube.wisc.edu">jmicallef@icecube.wisc.edu</a> are 0.000000</pre><br/>
<span style="color: #385a86"><span style="font-size: small">(16:49:37)</span> <b>jdost321:</b></span> haha lies, never enough gpus<br/>
<span style="color: #43761b"><span style="font-size: small">(16:50:36)</span> <b>blin:</b></span> yeah and they've got 1k idle jobs o.O<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(16:54:01)</span> <b>didavila:</b></span> it looks like the Negotiator is not matching anything:<br/><pre>condor_status -pool <a href="http://glidein2.chtc.wisc.edu">glidein2.chtc.wisc.edu</a> -negotiator -l<br/>LastNegotiationCycleDuration0 = 5<br/>LastNegotiationCycleDuration1 = 5<br/>LastNegotiationCycleDuration2 = 6<br/><br/>LastNegotiationCycleMatches0 = 0<br/>LastNegotiationCycleMatches1 = 0<br/>LastNegotiationCycleMatches2 = 0</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(16:55:35)</span> <b>blin:</b></span> yikes<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(16:56:02)</span> <b>didavila:</b></span> anything obvious from the Negotiator logs?<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(16:56:31)</span> <b>didavila:</b></span> <pre>LastNegotiationCycleSubmittersFailed0 = "<a href="mailto:whills@chtc.wisc.edu">whills@chtc.wisc.edu</a>"<br/>LastNegotiationCycleSubmittersFailed1 = "<a href="mailto:whills@chtc.wisc.edu">whills@chtc.wisc.edu</a>"<br/>LastNegotiationCycleSubmittersFailed2 = "<a href="mailto:whills@chtc.wisc.edu">whills@chtc.wisc.edu</a>"</pre><br/>
<span style="color: #a2a5dc"><span style="font-size: small">(16:56:52)</span> <b>didavila:</b></span> could the jobs of that user be causing the negotiator cycle to break?<br/>
<span style="color: #43761b"><span style="font-size: small">(16:57:36)</span> <b>blin:</b></span> aha, maybe<br/>
<span style="color: #43761b"><span style="font-size: small">(17:02:17)</span> <b>blin:</b></span> greg's gonna take a look<br/>
</body>
</html>
