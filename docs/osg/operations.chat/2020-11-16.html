<!DOCTYPE html>
<html>
<head>
<title>Mon Nov 16, 2020 : #operations (osg)</title>
</head>
<body>
<h3>Mon Nov 16, 2020 : #operations (osg)</h3>
<span style="color: #e96699"><span style="font-size: small">(11:33:30)</span> <b>lincoln:</b></span> @jdost321 we had a cooling issue this morning in the data center where River is housed. Cluster was down but should be back/recovering now. What do we need to do to check the HostedCEs?<br/>
<span style="color: #385a86"><span style="font-size: small">(14:11:17)</span> <b>jdost321:</b></span> @lincoln thanks for the heads up. how do we know when the cluster is 100% back up? I spot checked a few factory entries but looks like CEs are mostly not recovered, at first pass we can try kicking them. @jpeterson can you go through the list? start with CC* CEs as they are most important<br/>
<span style="color: #3c8c69"><span style="font-size: small">(14:14:07)</span> <b>jpeterson:</b></span> which particular list?<br/>
<span style="color: #385a86"><span style="font-size: small">(14:15:01)</span> <b>jdost321:</b></span> the list of hosted ces you have that you go through for the statuses<br/>
<span style="color: #385a86"><span style="font-size: small">(14:15:19)</span> <b>jdost321:</b></span> basically all of them i thik we only have 1 or 2 that aren't hosted in river<br/>
<span style="color: #3c8c69"><span style="font-size: small">(14:29:10)</span> <b>jpeterson:</b></span> looking at the <tt>slate instance logs</tt> on the CEs it looks like most of them came up<br/>
<span style="color: #e96699"><span style="font-size: small">(14:34:03)</span> <b>lincoln:</b></span> :thumbsup:<br/>
<span style="color: #e96699"><span style="font-size: small">(14:34:18)</span> <b>lincoln:</b></span> The cluster ought to be back up now- we had some excitement with the Ceph pool but it seems fine<br/>
<span style="color: #3c8c69"><span style="font-size: small">(15:00:35)</span> <b>jpeterson:</b></span> actually looks like many had network issues coming back up initially, I wasn’t looking back far enough in the log output. re-deploying to see if that fixes<br/>
<span style="color: #e96699"><span style="font-size: small">(15:01:31)</span> <b>lincoln:</b></span> some nodes might have goofy networking - if you find anything that especially looks like it's unable to resolve DNS or otherwise not make connections outbound let me know<br/>
<span style="color: #e96699"><span style="font-size: small">(15:01:34)</span> <b>lincoln:</b></span> and I'll check the node its on<br/>
<span style="color: #3c8c69"><span style="font-size: small">(15:02:55)</span> <b>jpeterson:</b></span> <pre>osg-hosted-ce-amnh-hel            uchicago-river-v2 instance_SiNGcq_rCcs</pre><br/>
<span style="color: #3c8c69"><span style="font-size: small">(15:03:19)</span> <b>jpeterson:</b></span> amnh-ares did as well, but I re-deployed and it must have found a node that worked<br/>
<span style="color: #385a86"><span style="font-size: small">(15:09:15)</span> <b>jdost321:</b></span> i'm still seing some weird stuff in ares that would suggest its not come up cleanly, although it looks different than the prev attempt that had DNS errors<br/>
<span style="color: #385a86"><span style="font-size: small">(15:09:17)</span> <b>jdost321:</b></span> <pre>/usr/lib64/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.<br/>  return _compile(pattern, flags).split(string, maxsplit)<br/>WARNING  OSG_APP ("app_dir" in the [Storage]) section is not configured. If it is not available, explicitly set it to UNSET. Otherwise, point it to the directory VO software can be obtained from.<br/>Running /usr/sbin/fetch-crl, this process may take some time to fetch all the crl updates<br/>fetch-crl script had some errors:<br/>ERROR verify called on empty data blob<br/>ERROR CRL verification failed for IGCA2/0 (IGCA2)<br/>VERBOSE(0) IGCA2/0: 0<br/>VERBOSE(0) IGCA2/0: downloaded CRL lastUpdate could not be derived<br/>VERBOSE(0) Download error <a href="http://www.mren-ca.ac.me/ca/crl-v2.crl">http://www.mren-ca.ac.me/ca/crl-v2.crl</a>: timed out after 30s<br/>VERBOSE(0) Download error <a href="http://www.psc.edu/ca/crl/4b2783ac.crl">http://www.psc.edu/ca/crl/4b2783ac.crl</a>: 501 Protocol scheme 'https' is not supported (LWP::Protocol::https not installed)<br/><br/>ERROR    Error while running fetch-crl script<br/>CRITICAL Can't configure module, exiting<br/>Can't configure module, exiting<br/>You may be able to get more details rerunning /usr/sbin/osg-configure with the -d option and/or by examining /var/log/osg/osg-configure.log</pre><br/>
<span style="color: #385a86"><span style="font-size: small">(15:09:44)</span> <b>jdost321:</b></span> looks like python2 vs 3 mismatch? @blin ?<br/>
<span style="color: #c386df"><span style="font-size: small">(15:10:15)</span> <b>matyas:</b></span> why?<br/>
<span style="color: #c386df"><span style="font-size: small">(15:10:21)</span> <b>matyas:</b></span> doesn't look like that to me.<br/>
<span style="color: #43761b"><span style="font-size: small">(15:10:27)</span> <b>blin:</b></span> do you have any more of the stacktrace?<br/>
<span style="color: #c386df"><span style="font-size: small">(15:10:28)</span> <b>matyas:</b></span> &gt;  501 Protocol scheme 'https' is not supported (LWP::Protocol::https not installed)<br/>
<span style="color: #c386df"><span style="font-size: small">(15:11:06)</span> <b>matyas:</b></span> try yum installing perl-LWP-Protocol-https<br/>
<span style="color: #385a86"><span style="font-size: small">(15:11:09)</span> <b>jdost321:</b></span> the first line future warning thing..<br/>
<span style="color: #43761b"><span style="font-size: small">(15:12:26)</span> <b>blin:</b></span> are there more line to the stacktrace?<br/>
<span style="color: #385a86"><span style="font-size: small">(15:13:57)</span> <b>jdost321:</b></span> here's the full thing until osg_configure bails out<br/>
<span style="color: #385a86"><span style="font-size: small">(15:14:00)</span> <b>jdost321:</b></span> <pre>slate instance logs instance_Y1zMzFE02Qk --container osg-hosted-ce --max-lines 0<br/>========================================<br/>Pod: osg-hosted-ce-amnh-ares-87956b49-xqs5l Container: osg-hosted-ce<br/>  File: '/tmp/99-local.ini'<br/>  Size: 556       	Blocks: 8          IO Block: 4096   regular file<br/>Device: 803h/2051d	Inode: 16786555    Links: 1<br/>Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)<br/>Access: 2020-11-16 20:57:02.051107742 +0000<br/>Modify: 2020-11-16 20:56:40.453314993 +0000<br/>Change: 2020-11-16 20:56:40.453314993 +0000<br/> Birth: -<br/>Trying to populate hostname in 99-local.ini with a better value..<br/>/etc/osg/config.d /<br/>$_CONDOR_NETWORK_HOSTNAME is nonempty, substituting it in..<br/>/<br/>Running OSG configure..<br/>WARNING  No max_wall_time specified for some sections; defaulting to 1440.<br/>Add 'max_wall_time=1440' to the following section(s) to clear this warning:<br/>'Subcluster AMNH-ARES'<br/>/usr/lib64/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.<br/>  return _compile(pattern, flags).split(string, maxsplit)<br/>WARNING  OSG_APP ("app_dir" in the [Storage]) section is not configured. If it is not available, explicitly set it to UNSET. Otherwise, point it to the directory VO software can be obtained from.<br/>Running /usr/sbin/fetch-crl, this process may take some time to fetch all the crl updates<br/>fetch-crl script had some errors:<br/>ERROR verify called on empty data blob<br/>ERROR CRL verification failed for IGCA2/0 (IGCA2)<br/>VERBOSE(0) IGCA2/0: 0<br/>VERBOSE(0) IGCA2/0: downloaded CRL lastUpdate could not be derived<br/>VERBOSE(0) Download error <a href="http://www.mren-ca.ac.me/ca/crl-v2.crl">http://www.mren-ca.ac.me/ca/crl-v2.crl</a>: timed out after 30s<br/>VERBOSE(0) Download error <a href="http://www.psc.edu/ca/crl/4b2783ac.crl">http://www.psc.edu/ca/crl/4b2783ac.crl</a>: 501 Protocol scheme 'https' is not supported (LWP::Protocol::https not installed)<br/><br/>ERROR    Error while running fetch-crl script<br/>CRITICAL Can't configure module, exiting<br/>Can't configure module, exiting<br/>You may be able to get more details rerunning /usr/sbin/osg-configure with the -d option and/or by examining /var/log/osg/osg-configure.log</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(15:14:53)</span> <b>blin:</b></span> yeah, i'm with Mat on this one. the python3 thing looks like just a warning<br/>
<span style="color: #c386df"><span style="font-size: small">(15:14:54)</span> <b>matyas:</b></span> but it's failing because fetch-crl errored out<br/>
<span style="color: #3c8c69"><span style="font-size: small">(15:16:02)</span> <b>jpeterson:</b></span> possible that that last person to deploy the hosted-ce yaml didn’t check it in, so when I pulled and re-deployed it  it was a broken version?<br/>
<span style="color: #43761b"><span style="font-size: small">(15:16:56)</span> <b>blin:</b></span> i don't think the problem is really an issue with anything that we're doing<br/>
<span style="color: #43761b"><span style="font-size: small">(15:17:21)</span> <b>blin:</b></span> <a href="http://psc.edu">psc.edu</a>'s CRL update has broken fetch-crl. i'm seeing the same thing on a test host<br/>
<span style="color: #385a86"><span style="font-size: small">(15:17:48)</span> <b>jdost321:</b></span> so this could prevent *all* hosted CEs from spinning up at the moment<br/>
<span style="color: #43761b"><span style="font-size: small">(15:18:14)</span> <b>blin:</b></span> yup<br/>
<span style="color: #c386df"><span style="font-size: small">(15:21:02)</span> <b>matyas:</b></span> so the good news is that if you install perl-LWP-Protocol-https, <a href="http://psc.edu">psc.edu</a>'s problem goes away<br/>
<span style="color: #e96699"><span style="font-size: small">(15:21:15)</span> <b>lincoln:</b></span> good ol' fetch-crl :slightly_smiling_face:<br/>
<span style="color: #c386df"><span style="font-size: small">(15:21:16)</span> <b>matyas:</b></span> the bad news is IGCA2 is still broken and it still fails the script<br/>
<span style="color: #43761b"><span style="font-size: small">(15:21:33)</span> <b>blin:</b></span> son of a<br/>
<span style="color: #43761b"><span style="font-size: small">(15:21:48)</span> <b>blin:</b></span> we really should just warn on fetch-crl failure in osg-configure<br/>
<span style="color: #c386df"><span style="font-size: small">(15:22:43)</span> <b>matyas:</b></span> yeah...<br/>
<span style="color: #c386df"><span style="font-size: small">(15:23:10)</span> <b>matyas:</b></span> we should also add that perl module to the image though -- I think CRLs oughta be downloaded with https...<br/>
<span style="color: #43761b"><span style="font-size: small">(15:23:24)</span> <b>blin:</b></span> is that easy to patch? we could do another hot-fix in the CE container<br/>
<span style="color: #c386df"><span style="font-size: small">(15:23:54)</span> <b>matyas:</b></span> yeah, probably another one-liner<br/>
<span style="color: #43761b"><span style="font-size: small">(15:24:38)</span> <b>blin:</b></span> we should submit a patch upstream to fetch-crl<br/>
<span style="color: #c386df"><span style="font-size: small">(15:25:04)</span> <b>matyas:</b></span> that too<br/>
<span style="color: #c386df"><span style="font-size: small">(15:27:15)</span> <b>matyas:</b></span> it's a little worrying that up until now, all CRLs were served unauthenticated and unencrypted<br/>
<span style="color: #e06b56"><span style="font-size: small">(15:28:15)</span> <b>jthiltges:</b></span> All CRLs are signed (to my knowledge). And forcing HTTPS would prevent caching.<br/>
<span style="color: #c386df"><span style="font-size: small">(15:28:39)</span> <b>matyas:</b></span> ah<br/>
<span style="color: #c386df"><span style="font-size: small">(15:29:03)</span> <b>matyas:</b></span> well, in this case it looks like psc is doing an http-&gt;https redirect<br/>
<span style="color: #3c8c69"><span style="font-size: small">(15:40:25)</span> <b>jpeterson:</b></span> just say “when” there are patches in or want me to re-deploy these again<br/>
<span style="color: #3c8c69"><span style="font-size: small">(15:40:53)</span> <b>jpeterson:</b></span> somehow at least one of them came back up and is working from the original incident<br/>
<span style="color: #3c8c69"><span style="font-size: small">(15:41:15)</span> <b>jpeterson:</b></span> at least partially<br/>
<span style="color: #c386df"><span style="font-size: small">(15:47:44)</span> <b>matyas:</b></span> <a href="https://github.com/opensciencegrid/osg-configure/pull/116">https://github.com/opensciencegrid/osg-configure/pull/116</a> though you've probably already seen it<br/>
<span style="color: #43761b"><span style="font-size: small">(15:50:54)</span> <b>blin:</b></span> :thumbsup: could you whip up a ticket real quick? i'd like to reference it in the update to the CE container<br/>
<span style="color: #c386df"><span style="font-size: small">(15:54:35)</span> <b>matyas:</b></span> done<br/>
<span style="color: #43761b"><span style="font-size: small">(16:02:06)</span> <b>blin:</b></span> <a href="https://github.com/opensciencegrid/docker-hosted-ce/pull/94">https://github.com/opensciencegrid/docker-hosted-ce/pull/94</a><br/>
<span style="color: #9e3997"><span style="font-size: small">(16:02:39)</span> <b>bbockelm:</b></span> &gt;  well, in this case it looks like psc is doing an http-&gt;https redirect<br/>Indeed - this is completely unnecessary because the CRL signature always needs to be checked regardless and affects the CRL distribution scalability.<br/><br/>That said, these "mom and pop shop" CAs running at larger computing centers typically don't have the time / effort to go through the internal process to get an exception to continue running a non-HTTPS service.<br/>
<span style="color: #43761b"><span style="font-size: small">(16:14:45)</span> <b>blin:</b></span> @jpeterson should be good to go once <a href="https://github.com/opensciencegrid/docker-hosted-ce/runs/1409005418?check_suite_focus=true">https://github.com/opensciencegrid/docker-hosted-ce/runs/1409005418?check_suite_focus=true</a> finishes running<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:18:37)</span> <b>jpeterson:</b></span> redeployed<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:19:20)</span> <b>jpeterson:</b></span> <tt>slate instance logs --container osg-hosted-ce --max-lines 0 instance_cGZWvvn-OPw</tt><br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:22:15)</span> <b>jpeterson:</b></span> <pre>Running OSG configure..<br/>WARNING  No max_wall_time specified for some sections; defaulting to 1440.<br/>Add 'max_wall_time=1440' to the following section(s) to clear this warning:<br/>'Subcluster AMNH-ARES'<br/>/usr/lib64/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.<br/>  return _compile(pattern, flags).split(string, maxsplit)<br/>WARNING  OSG_APP ("app_dir" in the [Storage]) section is not configured. If it is not available, explicitly set it to UNSET. Otherwise, point it to the directory VO software can be obtained from.<br/>WARNING  Could not determine default allowed VOs for subclusters/resource entries.<br/>WARNING  Install vo-client-lcmaps-voms to obtain default mappings for VOs, and/or create your own mapfile at /etc/grid-security/voms-mapfile.<br/>WARNING  No max_wall_time specified for some sections; defaulting to 1440.<br/>Add 'max_wall_time=1440' to the following section(s) to clear this warning:<br/>'Subcluster AMNH-ARES'<br/>Running /usr/sbin/fetch-crl, this process may take some time to fetch all the crl updates<br/>fetch-crl script had some errors:<br/>ERROR verify called on empty data blob<br/>ERROR CRL verification failed for IGCA2/0 (IGCA2)<br/>VERBOSE(0) IGCA2/0: 0<br/>VERBOSE(0) IGCA2/0: downloaded CRL lastUpdate could not be derived<br/>VERBOSE(0) Download error <a href="http://www.psc.edu/ca/crl/4b2783ac.crl">http://www.psc.edu/ca/crl/4b2783ac.crl</a>: 501 Protocol scheme 'https' is not supported (LWP::Protocol::https not installed)<br/><br/>ERROR    Error while running fetch-crl script<br/>CRITICAL Can't configure module, exiting<br/>Can't configure module, exiting<br/>You may be able to get more details rerunning /usr/sbin/osg-configure with the -d option and/or by examining /var/log/osg/osg-configure.log</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(16:24:30)</span> <b>blin:</b></span> what's the sha digest of the hosted-ce container that you're using?<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:26:53)</span> <b>jpeterson:</b></span> <tt>Image: opensciencegrid/hosted-ce:stable</tt><br/>        <tt>ImageID: bcf147d1b60178dea26d692dbfd0895a547f96ceb2d48dec8ed628a4e2ea6c12</tt><br/>
<span style="color: #43761b"><span style="font-size: small">(16:28:22)</span> <b>blin:</b></span> oh, you'll need to use <tt>fresh</tt><br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:28:36)</span> <b>jpeterson:</b></span> so they all get to be changed.  whee<br/>
<span style="color: #43761b"><span style="font-size: small">(16:31:42)</span> <b>blin:</b></span> wait<br/>
<span style="color: #43761b"><span style="font-size: small">(16:31:58)</span> <b>blin:</b></span> try deploying that one with fresh, then we can tag it as stable<br/>
<span style="color: #43761b"><span style="font-size: small">(16:32:02)</span> <b>blin:</b></span> then you can redeploy the rest<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:32:14)</span> <b>jpeterson:</b></span> deployed with fresh<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:32:27)</span> <b>jpeterson:</b></span> wasn’t going to touch the rest until we had a working one anyway<br/>
<span style="color: #43761b"><span style="font-size: small">(16:33:45)</span> <b>blin:</b></span> seems sensible :smile:<br/>
<span style="color: #43761b"><span style="font-size: small">(16:35:14)</span> <b>blin:</b></span> once we get that working, we'll need the sha so we can tag the new <tt>stable</tt> tag<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:35:42)</span> <b>jpeterson:</b></span> <pre>   Containers:<br/>      logging-sidecar<br/>        State: running since 2020-11-16T22:32:00Z<br/>        Ready: true<br/>        Restarts: 0<br/>        Image: nginx:1.15.9<br/>        ImageID: 98efe605f61725fd817ea69521b0eeb32bef007af0e3d0aeb6258c6e6fe7fc1a<br/>      osg-hosted-ce<br/>        State: waiting<br/>        Ready: false<br/>        Restarts: 4<br/>        Image: opensciencegrid/hosted-ce:fresh<br/>        ImageID: 4f44c89f9e19324a0616311feee8472d136db97dde46d2991a858d93f6969213<br/>        Last State: terminated with status 23 at 2020-11-16T22:34:09Z<br/>                      Started at 2020-11-16T22:34:02Z<br/>                      Reason: Error</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(16:36:06)</span> <b>blin:</b></span> sigh<br/>
<span style="color: #43761b"><span style="font-size: small">(16:36:27)</span> <b>blin:</b></span> what's the instance ID?<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:36:42)</span> <b>jpeterson:</b></span> <tt>osg-hosted-ce-amnh-ares           uchicago-river-v2 instance_nQSAZTjNuZE</tt><br/>
<span style="color: #a63024"><span style="font-size: small">(16:37:11)</span> <b>paschos:</b></span> @jdost321 can you take a look at 66184?<br/>
<span style="color: #385a86"><span style="font-size: small">(16:37:58)</span> <b>jdost321:</b></span> Hi @paschos sure<br/>
<span style="color: #a63024"><span style="font-size: small">(16:39:43)</span> <b>paschos:</b></span> also, let me know who should be tagged here for these kinds of requests …<br/>
<span style="color: #43761b"><span style="font-size: small">(16:40:24)</span> <b>blin:</b></span> @jpeterson this looks like some sort of issue with the bosco overrides for ARES<br/><pre>++ OVERRIDE_DIR=/etc/condor-ce/bosco_override<br/>++ /usr/local/bin/bosco-override-setup.sh <a href="mailto:git@gitlab.mwt2.org">git@gitlab.mwt2.org</a>:osg/hosted-ce-config.git AMNH-ARES /etc/osg/git.key<br/># <a href="http://gitlab.mwt2.org:22">gitlab.mwt2.org:22</a> SSH-2.0-OpenSSH_7.4<br/># <a href="http://gitlab.mwt2.org:22">gitlab.mwt2.org:22</a> SSH-2.0-OpenSSH_7.4<br/># <a href="http://gitlab.mwt2.org:22">gitlab.mwt2.org:22</a> SSH-2.0-OpenSSH_7.4<br/>Cloning into '/tmp/tmp.94oMbd1JzO'...<br/>Warning: Permanently added the RSA host key for IP address '128.135.158.205' to the list of known hosts.<br/>rsync: change_dir "/tmp/tmp.94oMbd1JzO/AMNH-ARES//bosco_override" failed: No such file or directory (2)<br/>rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1179) [sender=3.1.2]</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(16:40:31)</span> <b>blin:</b></span> maybe in the hosted-ce-config repo?<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:42:21)</span> <b>jpeterson:</b></span> there isn’t any overrides in the hosted-ce repo for this of course, yet they are enabled.<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:42:43)</span> <b>jpeterson:</b></span> pointing at the old git repo<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:43:02)</span> <b>jpeterson:</b></span> <pre>109 BoscoOverrides:<br/>110   Enabled: true<br/>111   GitEndpoint: "<a href="mailto:git@gitlab.mwt2.org">git@gitlab.mwt2.org</a>:osg/hosted-ce-config.git"<br/>112   # If GitEndpoint requires authentication, create a SLATE secret with<br/>113   # 'git.key' containing the private SSH key that can access<br/>114   # it. Specify the name of the secret in GitKeySecret:<br/>115   GitKeySecret: hosted-ce-gitlab-secret<br/>116   RepoNeedsPrivKey: true</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(16:44:05)</span> <b>blin:</b></span> oh ok, then try disabling it and redeploying<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:45:49)</span> <b>jpeterson:</b></span> already re-deployed a different AMNH that has overrides and they are in the new location and actually there<br/>
<span style="color: #43761b"><span style="font-size: small">(16:46:13)</span> <b>blin:</b></span> great, what's the sha?<br/>
<span style="color: #385a86"><span style="font-size: small">(16:46:43)</span> <b>jdost321:</b></span> @paschos you can assign "why aren't i getting pilots" type of tickets to factory ops. It could be any combination of me, marco, edita, or marian<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:46:49)</span> <b>jpeterson:</b></span> don’t know if it actually works yet<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:47:03)</span> <b>jpeterson:</b></span> <tt>slate instance logs --container osg-hosted-ce --max-lines 0 instance_dAvc9dj3rgk</tt><br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:47:38)</span> <b>jpeterson:</b></span> extra chatty.<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:48:16)</span> <b>jpeterson:</b></span> <pre>Containers:<br/>      logging-sidecar<br/>        State: running since 2020-11-16T22:44:28Z<br/>        Ready: true<br/>        Restarts: 0<br/>        Image: nginx:1.15.9<br/>        ImageID: 98efe605f61725fd817ea69521b0eeb32bef007af0e3d0aeb6258c6e6fe7fc1a<br/>      osg-hosted-ce<br/>        State: running since 2020-11-16T22:44:30Z<br/>        Ready: true<br/>        Restarts: 0<br/>        Image: opensciencegrid/hosted-ce:fresh<br/>        ImageID: 5f5c50ba4385f643a1bf84de4687e7d14aa9e6fa8a50078b69bfd338690927d2</pre><br/>
<span style="color: #43761b"><span style="font-size: small">(16:48:45)</span> <b>blin:</b></span> yeah, our latest images use <tt>set -x</tt>  in a bunch of the scripts, which should make it much easier to debug in the future when there are issues<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:49:24)</span> <b>jpeterson:</b></span> new factory jobs idle<br/>
<span style="color: #43761b"><span style="font-size: small">(16:50:56)</span> <b>blin:</b></span> great, let me work on tagging that hash as stable and you should be good to go to redeploy the rest of them<br/>
<span style="color: #385a86"><span style="font-size: small">(16:53:20)</span> <b>jdost321:</b></span> @jpeterson before you disappear today give me a list of any you don't get to and I can spin them up<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:53:55)</span> <b>jpeterson:</b></span> (I should have disappeared an hour and a half ago ^_^)<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:57:04)</span> <b>jpeterson:</b></span> The AMNH-HEL jobs have been idle over 11 minutes now, is good they didn’t get held right away, but don’t want to do the rest if they aren’t actually working right.<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:57:24)</span> <b>jpeterson:</b></span> and there they went held<br/>
<span style="color: #3c8c69"><span style="font-size: small">(16:57:39)</span> <b>jpeterson:</b></span> <pre>4532605.9   gfactory       11/16 14:56 Error connecting to schedd <a href="http://hosted-ce36.opensciencegrid.org">hosted-ce36.opensciencegrid.org</a>: AUTHENTICATE:1003:Failed to authenticate with any method|AUTHENTICATE:1004:Failed to authenticate using GSI|GSI:5002:Failed to authenticate because the remote (server) side was not able to acquire its credentials.|AUTHENTICATE:1004:Failed to authenticate using FS</pre><br/>
<span style="color: #385a86"><span style="font-size: small">(16:59:09)</span> <b>jdost321:</b></span> cert is expired Not After : Nov 12 15:50:55 2020 GMT<br/>
<span style="color: #385a86"><span style="font-size: small">(16:59:33)</span> <b>jdost321:</b></span> i saw that in the cert dump in the CE log<br/>
<span style="color: #43761b"><span style="font-size: small">(17:00:01)</span> <b>blin:</b></span> you should probably just remove the host cert/key secrets from the values file since it's fairly stable<br/>
<span style="color: #385a86"><span style="font-size: small">(17:00:21)</span> <b>jdost321:</b></span> if we do that is the idea every time thye are kicked we just get a new one?<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:00:30)</span> <b>jpeterson:</b></span> doing that now, just comment out?<br/>
<span style="color: #385a86"><span style="font-size: small">(17:00:35)</span> <b>jdost321:</b></span> and there's no fear of DOS triggereing in Let's encrypt?<br/>
<span style="color: #43761b"><span style="font-size: small">(17:00:37)</span> <b>blin:</b></span> you could always try to use LE staging first but if you're getting as far as accepting factory pilots then there's no point because the pilots wiill go held with a similar message<br/>
<span style="color: #43761b"><span style="font-size: small">(17:01:18)</span> <b>blin:</b></span> yup, every time a CE is kicked you request a new cert<br/>
<span style="color: #43761b"><span style="font-size: small">(17:01:51)</span> <b>blin:</b></span> so the safest way to deploy these days is<br/>1. disable host cert/key secrets<br/>2. enable LE staging and verify that the CE comes up ok<br/>3. if 2, disable LE staging and redeploy<br/>
<span style="color: #385a86"><span style="font-size: small">(17:02:23)</span> <b>jdost321:</b></span> 2 is new to me.. but Jeff P showed me the new lines in the hosted ce yaml last week, we weren't sure exactly how it wroked<br/>
<span style="color: #385a86"><span style="font-size: small">(17:02:41)</span> <b>jdost321:</b></span> but i like it<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:02:48)</span> <b>jpeterson:</b></span> That is what I thought I explained last week<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:03:23)</span> <b>jpeterson:</b></span> and other lets encrypt things need to be set to <tt>null</tt>  and not just commented out<br/>
<span style="color: #43761b"><span style="font-size: small">(17:03:34)</span> <b>blin:</b></span> sorry, lost of CE container updates and not quite enough time to update the SLATE docs<br/>
<span style="color: #43761b"><span style="font-size: small">(17:04:16)</span> <b>blin:</b></span> commented out should be fine because the default SLATE values should all be null<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:05:07)</span> <b>jpeterson:</b></span> slate app install fails<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:05:12)</span> <b>jpeterson:</b></span> if just commented out<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:05:29)</span> <b>jpeterson:</b></span> <pre>Installing application...<br/>Failed to install application osg-hosted-ce: Failed to start application instance with helm:<br/>[exit] 1<br/>[err]: Error: template: osg-hosted-ce/templates/deployment.yaml:48:19: executing "osg-hosted-ce/templates/deployment.yaml" at &lt;.Values.HostCredentials.HostCertKeySecret&gt;: nil pointer evaluating interface {}.HostCertKeySecret</pre><br/><br/>
<span style="color: #43761b"><span style="font-size: small">(17:06:00)</span> <b>blin:</b></span> well that's dumb and i blame helm somehow<br/>
<span style="color: #43761b"><span style="font-size: small">(17:07:02)</span> <b>blin:</b></span> what does your <tt>HostCredentials</tt> section look like?<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:07:39)</span> <b>jpeterson:</b></span> for that one it was all <tt>#</tt><br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:08:09)</span> <b>jpeterson:</b></span> went to:<br/><pre>135 HostCredentials:<br/>136   # Use a pre-existing host key to request a new Let's Encrypt<br/>137   # certificate If HostCertSecret is also specified, the Let's Encrypt<br/>138   # request is skipped.  Secret must contain a "host.key" key<br/>139   # containing the encoded host key.<br/>140   HostKeySecret: null<br/>141   # Use a pre-existing host certificate instead of requesting a new<br/>142   # Let'S Encrypt certificate. If HostKeySecret is not specified, a<br/>143   # new Let's Encrypt certificate and key are requested anyway.<br/>144   # Secret must contain a "host.cert" containing the encoded host<br/>145   # certificate.<br/>146   HostCertSecret: null</pre><br/>and it installed<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:09:19)</span> <b>jpeterson:</b></span> <tt>slate instance logs --container osg-hosted-ce --max-lines 0 instance_X45TQN_aOtA</tt><br/>
<span style="color: #43761b"><span style="font-size: small">(17:09:51)</span> <b>blin:</b></span> looks good!<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:10:13)</span> <b>jpeterson:</b></span> waiting on new factory jobs<br/>
<span style="color: #43761b"><span style="font-size: small">(17:13:19)</span> <b>blin:</b></span> we should run chaos-mesh or kube-thanos to catch these sort of oddities in the future :smile:<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:13:50)</span> <b>jpeterson:</b></span> not seeing factory jobs start up on it yet<br/>
<span style="color: #43761b"><span style="font-size: small">(17:21:38)</span> <b>blin:</b></span> i don't see any hits in the schedlog so i'm not sure the factory's trying yet?<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:21:44)</span> <b>jpeterson:</b></span> @jdost321 haven’t seen any jobs start up on the redeployed AMNH-HEL  yet, and my dinner is ready for me to finish making. (sousvide was ready 20 minutes ago). I’ll check back after.<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:22:04)</span> <b>jpeterson:</b></span> none of the others have been re-deployed, was waiting on a good one.<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:51:21)</span> <b>jpeterson:</b></span> <pre>[2020-11-16 15:45:07,880] INFO: Iteration initialized<br/>[2020-11-16 15:45:29,598] INFO: Checking downtime for frontend OSG_Flock security class: frontend (entry COVID19_US_AMNH-HEL).<br/>[2020-11-16 15:45:29,621] INFO: Client osg-flock-grid-iu-edu_OSG_gWMSFrontend.covid19 (secid: OSG_Flock_frontend) requesting 0 glideins, max running 0, idle lifetime 864000, remove excess 'ALL', remove_excess_margin 0<br/>[2020-11-16 15:45:29,621] INFO:   Params: {'CONDOR_VERSION': '8.9.x', 'GLIDEIN_Glexec_Use': 'NEVER', 'GLIDEIN_Job_Max_Time': 136800L, 'GLIDECLIENT_ReqNode': '<a href="http://gfactory-2.opensciencegrid.org">gfactory-2.opensciencegrid.org</a>', 'OSG_DEFAULT_CONTAINER_DISTRIBUTION': '95%__opensciencegrid/osgvo-el7:latest 3%__opensciencegrid/osgvo-el6:latest 2%__opensciencegrid/osgvo-el8:latest', 'GLIDEIN_CLAIM_WORKLIFE': 3600L, 'MIN_DISK_GBS': 1, 'GLIDECLIENT_Rank': '1', 'OSG_DEFAULT_CONTAINER_DISTRIBUTION_GPU': '100%__opensciencegrid/osgvo-el7-cuda10:latest', 'CONDOR_ARCH': 'default', 'CONDOR_OS': 'auto', 'UPDATE_COLLECTOR_WITH_TCP': 'True', 'STARTD_JOB_ATTRS': 'x509userproxysubject,x509UserProxyFQAN,x509UserProxyVOName,x509UserProxyEmail,x509UserProxyExpiration,ProjectName', 'JAVA': '/usr/bin/java', 'USE_MATCH_AUTH': 'True', 'GLIDEIN_Monitoring_Enabled': 'False', 'OSG_DEFAULT_CVMFS_DATA': '/cvmfs/stash.osgstorage.org', 'GLIDEIN_Report_Failed': 'NEVER', 'GLIDEIN_Collector': '<a href="http://flock.opensciencegrid.org:9700-9899">flock.opensciencegrid.org:9700-9899</a>'}<br/>[2020-11-16 15:45:29,622] INFO:   Decrypted Param Names: ['SubmitProxy', 'AMNH.idtoken', 'SecurityName', 'SecurityClass']<br/>[2020-11-16 15:45:29,650] INFO: Client osg-flock-grid-iu-edu_OSG_gWMSFrontend.covid19 (secid: OSG_Flock_frontend) schedd status {1: 0}<br/>[2020-11-16 15:45:29,708] INFO: Using v3+ protocol and credential 357657<br/>[2020-11-16 15:45:29,708] INFO: Have enough glideins: idle=0 req_idle=0, not submitting<br/>[2020-11-16 15:45:29,708] INFO: Sanitizing glideins for entry COVID19_US_AMNH-HEL</pre><br/>looks like it isn’t trying?<br/>
<span style="color: #43761b"><span style="font-size: small">(17:52:24)</span> <b>blin:</b></span> yeah, that's strange. i think we'll need @jdost321 on this one<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:53:02)</span> <b>jpeterson:</b></span> <tt>/var/log/gwms-factory/server/entry_COVID19_US_AMNH-HEL/COVID19_US_<a href="http://AMNH-HEL.info">AMNH-HEL.info</a>.log</tt><br/>
<span style="color: #385a86"><span style="font-size: small">(17:59:56)</span> <b>jdost321:</b></span> actually pulling in @rynge looks like osg flock took a nose dive this morning but its slowly recovering <a href="http://gfactory-2.opensciencegrid.org/factory/monitor/factoryStatus.html">http://gfactory-2.opensciencegrid.org/factory/monitor/factoryStatus.html</a><br/>
<span style="color: #385a86"><span style="font-size: small">(18:00:28)</span> <b>jdost321:</b></span> request idle is almost zero for most sites right now<br/>
<span style="color: #385a86"><span style="font-size: small">(18:00:54)</span> <b>jdost321:</b></span> maybe the u chicago issues affected otehr services in osg connect?<br/>
<span style="color: #3c8c69"><span style="font-size: small">(18:02:10)</span> <b>jpeterson:</b></span> I do see a big drop at about midnight here on all the graphs before they drop to 0 a few hours ago<br/>
<span style="color: #43761b"><span style="font-size: small">(18:03:44)</span> <b>blin:</b></span> oh! that makes sense, there was an osg-connect downtime today<br/>
<span style="color: #3c8c69"><span style="font-size: small">(18:03:56)</span> <b>jpeterson:</b></span> on those notes, I’m logging out for the night and will be back in the morning.<br/>
<span style="color: #385a86"><span style="font-size: small">(18:04:24)</span> <b>jdost321:</b></span> ok, thanks for all your efforts Jeff! i'll watch and kick the other CEs as needed once we get some pilots again here to test end to end<br/>
<span style="color: #3c8c69"><span style="font-size: small">(18:04:28)</span> <b>jpeterson:</b></span> @jdost321 let me know if there is anything I should be doing CE related when I get started in the morning<br/>
<span style="color: #385a86"><span style="font-size: small">(18:11:51)</span> <b>jdost321:</b></span> will do<br/>
<span style="color: #674b1b"><span style="font-size: small">(19:10:07)</span> <b>rynge:</b></span> Yeah, osg downtime<br/>
<span style="color: #674b1b"><span style="font-size: small">(19:10:23)</span> <b>rynge:</b></span> Things are coming back up, but we will not be fully back until tomorrow AM<br/>
</body>
</html>
