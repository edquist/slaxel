<!DOCTYPE html>
<html>
<head>
<title>Fri May 21, 2021 : #operations (osg)</title>
</head>
<body>
<h3>Fri May 21, 2021 : #operations (osg)</h3>
<span style="color: #43761b"><span style="font-size: small">(09:09:50)</span> <b>blin:</b></span> @jpeterson UTC is looking better <a href="http://gfactory-2.opensciencegrid.org/factory/monitor/factoryStatus.html?entry=OSG_US_UTC-Epyc&amp;frontend=total&amp;infoGroup=running&amp;elements=StatusRunningCores,ClientCoresTotal,ClientCoresRunning,ClientCoresIdle,&amp;rra=0&amp;window_min=0&amp;window_max=0&amp;timezone=-5">http://gfactory-2.opensciencegrid.org/factory/monitor/factoryStatus.html?entry=OSG_US_UTC-E[…]oresIdle,&amp;rra=0&amp;window_min=0&amp;window_max=0&amp;timezone=-5</a><br/>
<span style="color: #3c8c69"><span style="font-size: small">(09:10:38)</span> <b>jpeterson:</b></span> yeah it at least didn’t flatline down. still about half/half<br/>
<span style="color: #43761b"><span style="font-size: small">(09:12:20)</span> <b>blin:</b></span> claimed cores is steadily moving up and to the right so at least we're on the right path!<br/>
<span style="color: #43761b"><span style="font-size: small">(09:12:56)</span> <b>blin:</b></span> the non-GPU TCNJ monitoring really really confuses me <a href="http://gfactory-2.opensciencegrid.org/factory/monitor/factoryStatus.html?entry=OSG_US_TCNJ-ELSA&amp;frontend=total&amp;infoGroup=running&amp;elements=StatusRunningCores,ClientCoresTotal,ClientCoresRunning,ClientCoresIdle,&amp;rra=0&amp;window_min=0&amp;window_max=0&amp;timezone=-5">http://gfactory-2.opensciencegrid.org/factory/monitor/factoryStatus.html?entry=OSG_US_TCNJ-[…]oresIdle,&amp;rra=0&amp;window_min=0&amp;window_max=0&amp;timezone=-5</a><br/>
<span style="color: #43761b"><span style="font-size: small">(09:13:37)</span> <b>blin:</b></span> similarly, it looks like the factory is still sending jobs to TCNJ but i thought Jeff turned it off<br/>
<span style="color: #9e3997"><span style="font-size: small">(10:08:11)</span> <b>bbockelm:</b></span> @jdost321 - the gridmanager on schedd1 on gfactory-2 has been asserting once a minute for the last 3 days or so.<br/>
<span style="color: #9e3997"><span style="font-size: small">(10:08:30)</span> <b>bbockelm:</b></span> <pre>05/21/21 08:06:35 [1242051] ERROR "Assertion ERROR on (JobsByRemoteId.insert( remote_id, this ) == 0)" at line 102 in file /builddir/build/BUILD/condor-8.8.13/src/condor_gridmanager/basejob.cpp</pre><br/>
<span style="color: #9e3997"><span style="font-size: small">(10:09:02)</span> <b>bbockelm:</b></span> @blin: due to the factory schedd's gridmanager continuously crashing, status updates aren't propagating.<br/>
<span style="color: #43761b"><span style="font-size: small">(10:09:27)</span> <b>blin:</b></span> argh<br/>
<span style="color: #9e3997"><span style="font-size: small">(10:09:30)</span> <b>bbockelm:</b></span> so... 297 running pilots is where it appears to have left off.<br/>
<span style="color: #43761b"><span style="font-size: small">(10:22:45)</span> <b>blin:</b></span> @jpeterson i'm still stumped by the PSU gridmanager multiplexing issue. Jaime tells me that condor's using <tt>ssh -R</tt> so we shouldn't need to open ports on the login side<br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(11:21:27)</span> <b>blin:</b></span> now i'm seeing<br/><pre>05/21/21 16:19:21 (D_ALWAYS:2) [11147] GAHP[11149] (stderr) -&gt; ECDSA host key for 128.118.25.38 has changed and you have requested strict checking.</pre><br/>
<span style="color: #3c8c69"><span style="font-size: small">(11:25:14)</span> <b>jpeterson:</b></span> That might have been part of the cluster maintenance?   wonder if things got re-installed.  I’ll poke at it some.<br/>
<span style="color: #43761b"><span style="font-size: small">(11:25:32)</span> <b>blin:</b></span> oh, PSU had a cluster maintenance?<br/>
<span style="color: #3c8c69"><span style="font-size: small">(11:27:02)</span> <b>jpeterson:</b></span> yeah, wednesday I think it was<br/>
<span style="color: #3c8c69"><span style="font-size: small">(11:27:17)</span> <b>jpeterson:</b></span> why they delayed getting back on the outgoing restrictions<br/>
<span style="color: #43761b"><span style="font-size: small">(11:27:44)</span> <b>blin:</b></span> ah right<br/>
<span style="color: #3c8c69"><span style="font-size: small">(11:28:33)</span> <b>jpeterson:</b></span> I’ll start with a fresh redeploy just to get the current state of everything<br/>
<span style="color: #3c8c69"><span style="font-size: small">(12:33:39)</span> <b>jpeterson:</b></span> <pre>000 (5219138.000.000) 05/21 10:30:40 Job submitted from host: &lt;169.228.38.43:9618?addrs=169.228.38.43-9618&amp;noUDP&amp;sock=2909650_76d3_8&gt;<br/>...<br/>027 (5219138.000.000) 05/21 10:31:10 Job submitted to grid resource<br/>    GridResource: condor <a href="http://psu-ligo-ce1.svc.opensciencegrid.org">psu-ligo-ce1.svc.opensciencegrid.org</a> <a href="http://psu-ligo-ce1.svc.opensciencegrid.org:9619">psu-ligo-ce1.svc.opensciencegrid.org:9619</a><br/>    GridJobId: condor <a href="http://psu-ligo-ce1.svc.opensciencegrid.org">psu-ligo-ce1.svc.opensciencegrid.org</a> <a href="http://psu-ligo-ce1.svc.opensciencegrid.org:9619">psu-ligo-ce1.svc.opensciencegrid.org:9619</a> 17.0<br/>...<br/>012 (5219138.000.000) 05/21 10:32:05 Job was held.<br/>	Failed to start transfer GAHP: Agent pid 3305\n/home/osg07/bosco_slate/glite/bin/batch_gahp.symlink: /home/osg07/bosco_slate/glite/bin/../lib/condor/libglobus_common.so.0: no version information available (required by /home/osg07/bosco_slate/glite/bin/batch_gahp.symlink)\n<br/>	Code 0 Subcode 0<br/>...</pre><br/><br/>
<span style="color: #43761b"><span style="font-size: small">(12:35:55)</span> <b>blin:</b></span> hrm that's at least familiar looking<br/>
</blockquote>
<span style="color: #385a86"><span style="font-size: small">(10:59:24)</span> <b>jdost321:</b></span> @blin these are all the imaginary 6+ running pilots.. i didn't clear the TCNJ entries only put them down. I'll clear them now, i'd like to see next week when they are out of downtime if fresh pilots still don't transition to completed<br/>
<span style="color: #385a86"><span style="font-size: small">(10:59:35)</span> <b>jdost321:</b></span> 6+ day running<br/>
<span style="color: #9e3997"><span style="font-size: small">(11:00:05)</span> <b>bbockelm:</b></span> @jdost321 - did a quick chat with Jaime, there's no easy way to tell if gridmanager is crashing besides reading logs.<br/>
<span style="color: #385a86"><span style="font-size: small">(11:00:40)</span> <b>jdost321:</b></span> our gms share many entries there's no guarantee its even TCNJ that's causing it to crash.. i'll check that independently<br/>
<span style="color: #9e3997"><span style="font-size: small">(11:14:20)</span> <b>bbockelm:</b></span> oh - I don't think it's TCNJ causing the failure, but it just got unlucky.  Everything on that schedd for condor-ces is screwed.<br/>
<span style="color: #385a86"><span style="font-size: small">(11:16:43)</span> <b>jdost321:</b></span> i should have check that last job id before clearing tcnj..<br/><pre>05/21/21 09:03:19 [1308588] Found job 4313007.0 --- inserting<br/>05/21/21 09:03:19 [1308588] ERROR "Assertion ERROR on (JobsByRemoteId.insert( remote_id, this ) == 0)" at line 102 in file /builddir/build/BUILD/condor-8.8.13/src/condor_gridmanager/basejob.cpp</pre><br/>
<span style="color: #385a86"><span style="font-size: small">(11:17:09)</span> <b>jdost321:</b></span> its gone now after my remove so i'm guessing maybe it could be related, going to check the condor logs<br/>
<span style="color: #385a86"><span style="font-size: small">(11:17:33)</span> <b>jdost321:</b></span> or we get lucky / unlucky and it continues to assert<br/>
<span style="color: #385a86"><span style="font-size: small">(11:25:42)</span> <b>jdost321:</b></span> i'm geussing it fails to print the job it's asserting on and its the one after 4313007.0<br/>
<span style="color: #385a86"><span style="font-size: small">(11:25:44)</span> <b>jdost321:</b></span> <pre>condor_history -file history.20210521T091019 | grep 4313007.0<br/>4313007.0   gfactory        5/14 06:30   0+08:56:15 X   5/14 14:10 /var/lib/gwms-factory/work-dir/glidein_startup.sh -v std -name gfactory_instance -entry OSG_US_ASU-DELL_M420 -clientname osg-flock-grid-iu-edu_OSG_gWMSFrontend.main -schedd <a href="mailto:schedd_glideins1@gfactory-2.opensciencegrid.org">schedd_glideins1@gfactory-2.opensciencegrid.org</a> -proxy OSG -factory OSG -web <a href="http://gfactory-2.opensciencegrid.org/factory/stage">http://gfactory-2.opensciencegrid.org/factory/stage</a> -sign a3aa4c18d9a763c3c117fc229c732e303d76a50d -signentry 52debf5fb7fd238be429eb11c69cbc460eeea651 -signtype sha1 -descript description.l5d7qT.cfg -descriptentry description.l5d7qT.cfg -dir OSG -param_GLIDEIN_Client osg-flock-grid-iu-edu_OSG_gWMSFrontend.main -submitcredid 357657 -slotslayout fixed -clientweb <a href="http://flock.opensciencegrid.org/vofrontend/stage">http://flock.opensciencegrid.org/vofrontend/stage</a> -clientsign 859f7050b3542d957e99803ec9350918d322758f -clientsigntype sha1 -clientdescript description.l5dhEI.cfg -clientgroup main -clientwebgroup <a href="http://flock.opensciencegrid.org/vofrontend/stage/group_main">http://flock.opensciencegrid.org/vofrontend/stage/group_main</a> -clientsigngroup de5a93d20915d0e65b3d89f37aca836b1d2be19d -clientdescriptgroup descrip</pre><br/>
<span style="color: #3c8c69"><span style="font-size: small">(11:26:04)</span> <b>jpeterson:</b></span> also, I put the TCNJ_gpu queue into downtime this morning as well.<br/>
<span style="color: #385a86"><span style="font-size: small">(11:26:26)</span> <b>jdost321:</b></span> thanks Jeff I missed that one<br/>
<span style="color: #9e3997"><span style="font-size: small">(11:56:43)</span> <b>bbockelm:</b></span> @jdost321 - maybe just remove all condor-ce jobs from that schedd?<br/>
<span style="color: #9e3997"><span style="font-size: small">(11:56:52)</span> <b>bbockelm:</b></span> it's been 3 days, none of them are likely working anyway.<br/>
<span style="color: #385a86"><span style="font-size: small">(12:03:14)</span> <b>jdost321:</b></span> there's at least some evidence since clearing out TCNJ jobs that its recovering on its own <a href="http://gfactory-2.opensciencegrid.org/factory/monitor/factoryStatus.html?entry=OSG_US_ASU-DELL_M420&amp;frontend=total&amp;infoGroup=running&amp;elements=StatusRunningCores,ClientCoresTotal,ClientCoresRunning,ClientCoresIdle,&amp;rra=0&amp;window_min=0&amp;window_max=0&amp;timezone=-7">http://gfactory-2.opensciencegrid.org/factory/monitor/factoryStatus.html?entry=OSG_US_ASU-D[…]oresIdle,&amp;rra=0&amp;window_min=0&amp;window_max=0&amp;timezone=-7</a><br/>
<span style="color: #43761b"><span style="font-size: small">(13:07:27)</span> <b>blin:</b></span> @jdost321 @bbockelm @rynge so RE: scitoken mapping failures not falling back to GSI, i think we've got two paths:<br/>• maintain config complexity in the factory or VO side<br/>• start a CE upgrade campaign for updating htcondor/htcondor-ce<br/>
<span style="color: #43761b"><span style="font-size: small">(13:08:10)</span> <b>blin:</b></span> we should probably be starting the latter anyway, pushing folks to htcondor-ce 5/htcondor 9 so that they can support GSI/SciTokens concurrently<br/>
<span style="color: #43761b"><span style="font-size: small">(13:08:49)</span> <b>blin:</b></span> but only choosing that path would mean either a) holding back the prod factory upgrade to 9.0.0 or b) losing hours from sites that don't update on our timeline<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:09:14)</span> <b>rynge:</b></span> Maybe not great, but can't we have GSI before SciToken on the factory side? And then new CEs would only have SciToken enabled?<br/>
<span style="color: #43761b"><span style="font-size: small">(13:09:48)</span> <b>blin:</b></span> yeah, that's one of the options of config complexity<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:09:56)</span> <b>rynge:</b></span> Ok<br/>
<span style="color: #43761b"><span style="font-size: small">(13:10:32)</span> <b>blin:</b></span> but it'd have to be GSI without SciTokens by default: since the factory is the client in this case and the CEs prefer SciTokens, SciTokens would "win" in the authN handshake if it's anywhere in the client authN list<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:10:59)</span> <b>rynge:</b></span> Well, as a fe operator and vo admin, I would not mind a big push for scitokens. However, we know there will always be a few sites straggling behind<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:11:09)</span> <b>rynge:</b></span> Ah,<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:12:15)</span> <b>rynge:</b></span> Yeah, then I don't know. At a higher level, we need to have tokens on by default, and a carrot for sites switching over<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:12:37)</span> <b>rynge:</b></span> Leaving tokens at a secondary member will probably delay the overall move<br/>
<span style="color: #43761b"><span style="font-size: small">(13:13:21)</span> <b>blin:</b></span> yeah. it feels like we have to tread both paths concurrently<br/>
<span style="color: #43761b"><span style="font-size: small">(13:14:26)</span> <b>blin:</b></span> and annoying as it is, i think the config complexity is more reasonable to have at the VO/FE level since the underlying issue is that failure is the result of a VO token not being mapped on the CE side<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:14:48)</span> <b>rynge:</b></span> Ok, so what would that entail?<br/>
<span style="color: #43761b"><span style="font-size: small">(13:15:37)</span> <b>blin:</b></span> separate SciTokens/GSI groups, I think<br/>
<span style="color: #385a86"><span style="font-size: small">(13:15:54)</span> <b>jdost321:</b></span> we can campaign on the OSG side for sites to change, but I only thoguht about it today when Brian L brought it up on the ops call, what about the O(100) condor ce entries we have in europe? are they under any obligation to update to accept sci tokens when OSG is ready to start transitioning?<br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(13:16:30)</span> <b>blin:</b></span> this is only really a problem once the VO starts supporting SciToken pilot submission<br/>
<span style="color: #43761b"><span style="font-size: small">(13:22:37)</span> <b>blin:</b></span> though I guess that's going to be a problem for GLOW since IceCube has european sites<br/>
<span style="color: #43761b"><span style="font-size: small">(13:23:18)</span> <b>blin:</b></span> the real kicker for Europe is going to be when CMS wants to start submitting token-based pilots<br/>
</blockquote>
<span style="color: #43761b"><span style="font-size: small">(13:15:55)</span> <b>blin:</b></span> where the former whitelists on CEs that we know support SciTokens from that VO<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:16:34)</span> <b>rynge:</b></span> I can do separate groups. Would they use auth method to find factory entries?<br/>
<span style="color: #43761b"><span style="font-size: small">(13:17:17)</span> <b>blin:</b></span> unfortunately i think it's worse, the list has to be somewhat hand maintained<br/>
<span style="color: #43761b"><span style="font-size: small">(13:17:36)</span> <b>blin:</b></span> because the failure is not in the authN layer, it's in the mapping layer, which isn't advertised by the CE<br/>
<span style="color: #43761b"><span style="font-size: small">(13:18:11)</span> <b>blin:</b></span> and so the only way to determine if you're mapped is to see if you have WRITE permission with your token credential<br/>
<span style="color: #385a86"><span style="font-size: small">(13:18:36)</span> <b>jdost321:</b></span> yeah our failures at AMNH werre really cryptic, pilots went hold for something like "failed to update classad"<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:19:19)</span> <b>rynge:</b></span> In general, the frontend does not really track sites by list, but by attributes on the factory entries<br/>
<span style="color: #674b1b"><span style="font-size: small">(13:19:57)</span> <b>rynge:</b></span> So it sounds a little bit like we would have to tag entries accordingly and have the fe groups match on those<br/>
<span style="color: #43761b"><span style="font-size: small">(13:20:45)</span> <b>blin:</b></span> i hope we can avoid tagging CEs as that'll be a bear to maintain<br/>
<span style="color: #43761b"><span style="font-size: small">(13:21:13)</span> <b>blin:</b></span> i'd much rather have some other process automatically generate a whitelist for us and have the FE consume that if it's possible<br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(13:26:07)</span> <b>blin:</b></span> I was thinking some script that runs on the FE that queries the factory for each CE/entry that supports the VO, then turns around and runs a token-based <tt>condor_ping...WRITE</tt> against each CE, and dumps a list of entries corresponding to CEs with successful token-based pings<br/>
</blockquote>
<span style="color: #385a86"><span style="font-size: small">(13:21:17)</span> <b>jdost321:</b></span> once we discover it we can add some tag in the factory entries to say this site supportst okens<br/>
<span style="color: #385a86"><span style="font-size: small">(13:21:26)</span> <b>jdost321:</b></span> the hard part is finding out who as they transition<br/>
<span style="color: #43761b"><span style="font-size: small">(13:21:42)</span> <b>blin:</b></span> exactly, that puts load on factory ops<br/>
<span style="color: #385a86"><span style="font-size: small">(13:24:00)</span> <b>jdost321:</b></span> can it be like teh covid19 support? we advertised if you want to support covid 19 do these things, and i think one of those was open a ticket w/ these key wors<br/>
<span style="color: #385a86"><span style="font-size: small">(13:24:02)</span> <b>jdost321:</b></span> words<br/>
<span style="color: #385a86"><span style="font-size: small">(13:24:15)</span> <b>jdost321:</b></span> and we made a FD filter so factory ops would see<br/>
<span style="color: #385a86"><span style="font-size: small">(13:24:38)</span> <b>jdost321:</b></span> basically sites need to annoucne "we're ready to support sci tokens" ?<br/>
<span style="color: #43761b"><span style="font-size: small">(13:27:05)</span> <b>blin:</b></span> yeah, we could do that along with any automatic detection that we can do<br/>
<span style="color: #385a86"><span style="font-size: small">(13:28:13)</span> <b>jdost321:</b></span> I definitely prefer automated detection though if its doable<br/>
<span style="color: #9e3997"><span style="font-size: small">(14:14:51)</span> <b>bbockelm:</b></span> @blin - thinking out of the box: how about we write a script to detect CEs accepting SciTokens but not mapping OSG or CHTC, then we all sit at the Terrace one Friday afternoon until we've opened tickets for all the corresponding sites?<br/>
<span style="color: #9e3997"><span style="font-size: small">(14:15:57)</span> <b>bbockelm:</b></span> E.g., I'll gladly fund brats (or vegan equivalents) and beer until 92 tickets are open.<br/>
<span style="color: #43761b"><span style="font-size: small">(14:16:01)</span> <b>blin:</b></span> yeah, i was thinking something like that but something more automated here <a href="https://opensciencegrid.slack.com/archives/C5GAYBGA0/p1621621567098000?thread_ts=1621621273.094900&amp;cid=C5GAYBGA0">https://opensciencegrid.slack.com/archives/C5GAYBGA0/p1621621567098000?thread_ts=1621621273.094900&amp;cid=C5GAYBGA0</a><br/>
<span style="color: #9e3997"><span style="font-size: small">(14:47:12)</span> <b>bbockelm:</b></span> Yes, that's the easy part.  The hard part is the corresponding 92 tickets.<br/>
<span style="color: #43761b"><span style="font-size: small">(14:50:06)</span> <b>blin:</b></span> ya. i think for the 92 CEs we gotta start with a general announcement encouraging everyone to update to HTCondor 9.0 and HTCondor-CE 5<br/>
<span style="color: #9e3997"><span style="font-size: small">(14:50:52)</span> <b>bbockelm:</b></span> (I thought 90-something was the actual count of CEs accepting SciTokens?)<br/>
<span style="color: #43761b"><span style="font-size: small">(14:51:30)</span> <b>blin:</b></span> yeah, though we should expect that number to grow<br/>
<span style="color: #A82F2F"><span style="font-size: small">(16:41:11)</span> <b>B01GA370NNT:</b></span> <br/>
<span style="color: #A82F2F"><span style="font-size: small">(19:43:35)</span> <b>B01GA370NNT:</b></span> Your incident *Intermittent outage due to data center issues* has been open for over *3 hours*. (<a href="http://manage.statuspage.io/pages/ws62tz4wcmxv">http://manage.statuspage.io/pages/ws62tz4wcmxv</a>)<br/>
<span style="color: #A82F2F"><span style="font-size: small">(22:43:31)</span> <b>B01GA370NNT:</b></span> Your component *StashCache Redirector* has been set to *Partial Outage* for over *6 hours*. (<a href="http://manage.statuspage.io/pages/ws62tz4wcmxv">http://manage.statuspage.io/pages/ws62tz4wcmxv</a>)<br/>
<span style="color: #A82F2F"><span style="font-size: small">(22:43:47)</span> <b>B01GA370NNT:</b></span> Your incident *Intermittent outage due to data center issues* has been open for over *6 hours*. (<a href="http://manage.statuspage.io/pages/ws62tz4wcmxv">http://manage.statuspage.io/pages/ws62tz4wcmxv</a>)<br/>
</body>
</html>
