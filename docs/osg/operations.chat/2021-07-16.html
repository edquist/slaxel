<!DOCTYPE html>
<html>
<head>
<title>Fri Jul 16, 2021 : #operations (osg)</title>
</head>
<body>
<h3>Fri Jul 16, 2021 : #operations (osg)</h3>
<span style="color: #50a0cf"><span style="font-size: small">(10:13:41)</span> <b>timm:</b></span> Has anyone yet successfully submitted batch slurm jobs (to bosco)  from an htcondor-ce running 9.0.1 or greater (host?  If so was there anything you had to do to get the LD_LIBRARY_PATH straight?  with htcondor 9.0.1 /glideinwms3.9.2 I am getting an error consistent with the LD_LIBRARY_PATH not being set correctly..  With htcondor 8.9.8 / glideinwms 3.6.5 this does not happen.  Have filed htcondor ticket but would be interested in anyone who has experience in doing this successfully.. in particular is a newer bosco (than 1.3) needed with htcondor 9.0.x?<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(11:23:16)</span> <b>didavila:</b></span> I think I’m experiencing something similar @timm, I just deployed a hosted-ce via slate and I got <tt>condor-9.0.1</tt> with <tt>htcondor-ce-5.1.1</tt>  and my jobs are getting hold at the CE queue with HoldReason:<br/><pre>submission command failed (exit code = 1) (stdout:) (stderr:/export/nfs0home/osg09/bosco/glite/libexec/slurm_submit.sh: line 103: /usr/bin/sbatch: No such file or directory-Error from sbatch: -)</pre><br/>
<span style="color: #a2a5dc"><span style="font-size: small">(11:23:56)</span> <b>didavila:</b></span> I can see that <tt>sbatch</tt> is available in the login node, but it is not in <tt>/usr/bin</tt><br/>
<span style="color: #50a0cf"><span style="font-size: small">(11:24:57)</span> <b>timm:</b></span> What’s the version_info.txt say in the login mode<br/>
<span style="color: #50a0cf"><span style="font-size: small">(11:25:41)</span> <b>timm:</b></span> Should be able to tweak the deployed config to find the right slurm dir<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(11:25:58)</span> <b>didavila:</b></span> where can I find <tt>version_info.txt</tt> ?<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(11:33:33)</span> <b>didavila:</b></span> so I went into the login node and changed the failing line (103) at the <tt>slurm_submit.sh</tt> script, from:<br/><pre>jobID=<tt>${slurm_binpath}/sbatch $bls_tmp_file</tt> # actual submission</pre><br/>
<span style="color: #a2a5dc"><span style="font-size: small">(11:33:35)</span> <b>didavila:</b></span> to<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(11:34:09)</span> <b>didavila:</b></span> <pre>jobID=<tt>sbatch $bls_tmp_file</tt> # actual submission</pre><br/>
<span style="color: #a2a5dc"><span style="font-size: small">(11:34:43)</span> <b>didavila:</b></span> and now I got a different error:<br/><pre>submission command failed (exit code = 1) (stdout:) (stderr:sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified-Error from sbatch: -)</pre><br/>
<span style="color: #50a0cf"><span style="font-size: small">(11:38:04)</span> <b>timm:</b></span> version_info.txt appears to not be in the newer bosco as installed in a hosted-ce install.<br/>
<span style="color: #50a0cf"><span style="font-size: small">(11:38:11)</span> <b>timm:</b></span> used to be at the top level of the bosco directory<br/>
<span style="color: #50a0cf"><span style="font-size: small">(11:38:41)</span> <b>timm:</b></span> as far as the slurm_submit error you have above, there should be a slurm_submit file in the home directory of the login node that<br/>
<span style="color: #50a0cf"><span style="font-size: small">(11:38:53)</span> <b>timm:</b></span> you can look at to see what it was trying to submit.<br/>
<span style="color: #50a0cf"><span style="font-size: small">(11:39:12)</span> <b>timm:</b></span> something wrong in one of the #SBATCH options no doubt<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(11:56:08)</span> <b>didavila:</b></span> this is the submit file:<br/><pre>#!/bin/bash<br/># SLURM job wrapper generated by slurm_submit.sh<br/># on Fri Jul 16 09:54:44 PDT 2021<br/>#<br/># stgcmd = no<br/># proxy_string = /export/nfs0home/osg09/bosco/sandbox/329e/329e513b/hosted-ce40.opensciencegrid.org_9619_hosted-ce40.opensciencegrid.org_2.0_1626393002/x509up_u0<br/># proxy_local_file = /export/nfs0home/osg09/bosco/sandbox/329e/329e513b/hosted-ce40.opensciencegrid.org_9619_hosted-ce40.opensciencegrid.org_2.0_1626393002/x509up_u0<br/>#<br/># SLURM directives:<br/>#SBATCH -o /dev/null<br/>#SBATCH -e /dev/null<br/>#SBATCH -t 4320<br/>#SBATCH --mem=2000<br/><br/># Setting the environment:<br/>export "OSG_HOSTNAME=<a href="http://hosted-ce40.opensciencegrid.org">hosted-ce40.opensciencegrid.org</a>"<br/>export "OSG_APP=UNAVAILABLE"<br/>export "OSG_SITE_READ="<br/>export "OSG_DATA=UNAVAILABLE"<br/>export "OSG_WN_TMP=/scratch"<br/>export "OSG_SITE_WRITE="<br/>export "OSG_SITE_NAME=UCI-GPATLAS"<br/>export "OSG_GRID=/export/home/osg09/bosco-osg-wn-client"<br/>export "CONDORCE_COLLECTOR_HOST=<a href="http://hosted-ce40.opensciencegrid.org:9619">hosted-ce40.opensciencegrid.org:9619</a>"<br/>export "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"<br/>export "OSG_STORAGE_ELEMENT=False"<br/>export "OSG_SQUID_LOCATION=10.201.32.13:3128"<br/>export "OSG_DEFAULT_SE="<br/>old_home=<tt>pwd</tt><br/>new_home=${old_home}/home_bl_hosted-ce40.opensciencegrid.org_9619_hosted-ce40.opensciencegrid.org_2.0_1626393002<br/>mkdir "$new_home"<br/>job_wait_cleanup () { wait "$job_pid"; cd "$old_home"; rm -rf "$new_home"; }<br/>on_signal () { kill -$1 "$job_pid"; job_wait_cleanup; exit 255; }<br/>trap_sigs () { for sig; do trap "on_signal $sig" $sig; done; }<br/>trap_sigs HUP INT QUIT TERM XCPU<br/>trap job_wait_cleanup EXIT<br/># Copy into new home any shared input sandbox file<br/># Move into new home any relative input sandbox file<br/>export HOME=$new_home<br/>cd $new_home<br/>export X509_USER_PROXY=/export/nfs0home/osg09/bosco/sandbox/329e/329e513b/hosted-ce40.opensciencegrid.org_9619_hosted-ce40.opensciencegrid.org_2.0_1626393002/x509up_u0<br/><br/># Command to execute:<br/>export NODE_COUNT=1<br/> /usr/bin/env  &lt; "/dev/null" &gt; "/export/nfs0home/osg09/bosco/sandbox/329e/329e513b/hosted-ce40.opensciencegrid.org_9619_hosted-ce40.opensciencegrid.org_2.0_1626393002/_condor_stdout" 2&gt; "/export/nfs0home/osg09/bosco/sandbox/329e/329e513b/hosted-ce40.opensciencegrid.org_9619_hosted-ce40.opensciencegrid.org_2.0_1626393002/_condor_stderr" &amp;<br/>job_pid=$!<br/><br/># Wait for the user job to finish<br/>wait $job_pid<br/>user_retcode=$?<br/><br/># Move all relative outputsand paths out of temp home<br/>cd $new_home<br/># Move any remapped outputsand file to shared directories<br/><br/># Remove the staged files, if any<br/>cd $old_home<br/>rm -f /export/nfs0home/osg09/bosco/sandbox/329e/329e513b/hosted-ce40.opensciencegrid.org_9619_hosted-ce40.opensciencegrid.org_2.0_1626393002/x509up_u0<br/><br/>exit $user_retcode</pre><br/>
<span style="color: #50a0cf"><span style="font-size: small">(12:12:07)</span> <b>timm:</b></span> what SLURM resource is that<br/>
<span style="color: #50a0cf"><span style="font-size: small">(12:12:28)</span> <b>timm:</b></span> The default #SBATCH -t 4320<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(12:12:37)</span> <b>didavila:</b></span> <a href="http://gpatlas1.ps.uci.edu">gpatlas1.ps.uci.edu</a><br/>
<span style="color: #50a0cf"><span style="font-size: small">(12:12:43)</span> <b>timm:</b></span> has bit me on a couple resources and I had to have the guys take it out.<br/>
<span style="color: #50a0cf"><span style="font-size: small">(12:12:58)</span> <b>timm:</b></span> that's a 3 day job.. most slurm resources don't allow that, not sure why it is the default<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(12:13:32)</span> <b>didavila:</b></span> i tried with a simpler submit file and got the same error:<br/><pre>#!/bin/bash<br/>#SBATCH --job-name=serial_job_test    # Job name<br/>#SBATCH --ntasks=1                    # Run on a single CPU<br/>#SBATCH --mem=1gb                     # Job memory request<br/>#SBATCH --time=00:05:00               # Time limit hrs:min:sec<br/>#SBATCH --output=serial_test_%j.log   # Standard output and error log<br/>pwd; hostname; date<br/><br/>#module load python<br/><br/>echo "Running plot script on a single CPU core"<br/><br/>#python /data/training/SLURM/plot_template.py<br/><br/>date</pre><br/>
<span style="color: #50a0cf"><span style="font-size: small">(12:13:44)</span> <b>timm:</b></span> you can just log onto the node, change a couple things in the slurm_submit and submit it again interactively<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(12:13:46)</span> <b>didavila:</b></span> I think we need to specify a partition<br/>
<span style="color: #50a0cf"><span style="font-size: small">(12:13:47)</span> <b>timm:</b></span> until you get it<br/>
<span style="color: #50a0cf"><span style="font-size: small">(12:14:36)</span> <b>timm:</b></span> yes, missing the partition..<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(12:25:01)</span> <b>didavila:</b></span> so I found this in the Entry configuration at the factory:<br/><pre>&lt;submit_attr name="+queue" value="&amp;quot;atlas&amp;quot;"/&gt;</pre><br/>
<span style="color: #a2a5dc"><span style="font-size: small">(12:25:23)</span> <b>didavila:</b></span> which I guess it translates to:<br/><pre>#SBATCH -p "atlas"</pre><br/>
<span style="color: #a2a5dc"><span style="font-size: small">(12:25:28)</span> <b>didavila:</b></span> that way it worked<br/>
<span style="color: #a2a5dc"><span style="font-size: small">(12:26:15)</span> <b>didavila:</b></span> so I guess my problem is that I was submitting a test job with <tt>condor_ce_trace</tt> and that knos nothing about the specifics of the entry<br/>
<span style="color: #aba727"><span style="font-size: small">(13:30:14)</span> <b>moate:</b></span> From freshdesk <a href="https://support.opensciencegrid.org/a/tickets/67620">ticket #67620 "Adjusting max OSG jobs running at Penn State"</a> :<br/><pre>Hello,<br/><br/>We would like to adjust the max jobs allowed to run at the Penn State LIGO cluster. We set up an OSG-hosted CE earlier (see <a href="https://support.opensciencegrid.org/support/tickets/66625">https://support.opensciencegrid.org/support/tickets/66625</a>) and had the max jobs set to 100 for testing. Now that that's been validated, we would like to increase the max number of jobs to match our virtual core count (8832) to allow the jobs to backfill the cluster when it is idle.<br/><br/>Could you adjust the max jobs to 8832? Let me know if there's anything else I should configure.<br/><br/>Thanks,<br/>Bryce</pre><br/>@jpeterson helped him in ticket #8832;  should this go to Jeff P?  Or Factory Ops (Marian this week)?<br/>
<span style="color: #aba727"><span style="font-size: small">(13:30:54)</span> <b>moate:</b></span> I presume it's a CE configuration change<br/>
<span style="color: #3c8c69"><span style="font-size: small">(13:31:17)</span> <b>jpeterson:</b></span> I’ll take it<br/>
<span style="color: #aba727"><span style="font-size: small">(13:32:53)</span> <b>moate:</b></span> Thanks Jeff<br/>
</body>
</html>
