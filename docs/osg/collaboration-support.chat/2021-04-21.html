<!DOCTYPE html>
<html>
<head>
<title>Wed Apr 21, 2021 : #collaboration-support (osg)</title>
</head>
<body>
<h3>Wed Apr 21, 2021 : #collaboration-support (osg)</h3>
<span style="color: #a63024"><span style="font-size: small">(11:44:25)</span> <b>paschos:</b></span> @briedel are these GPU jobs? ^ cause we don’t see any matching  of gpu pilots for gatech from the factory side<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:00:37)</span> <b>bbockelm:</b></span> (particularly, <tt>condor_status</tt> against the CHTC central manager says there are no GPUs at that site)<br/>
<span style="color: #a63024"><span style="font-size: small">(12:02:46)</span> <b>paschos:</b></span> pinging @blin as well … At georgia tech, local jobs match if they set: <tt>+WantGPU = true</tt> attribute in the submit script.<br/>The local worker config on the gpu looks like this:<br/><pre>use feature : gpus<br/>HasGPU = True<br/>START = (TARGET.WantGPU == True) &amp;&amp; ( $(START) )<br/>STARTD_ATTRS = $(STARTD_ATTRS),HasGPU<br/>GLIDEIN_ResourceName = "Georgia_Tech_PACE_CE_2"<br/>STARTD_ATTRS = $(STARTD_ATTRS),GLIDEIN_ResourceName</pre><br/><br/>
<span style="color: #43761b"><span style="font-size: small">(12:03:37)</span> <b>blin:</b></span> how many GPUs are they requesting in their submit script?<br/>
<span style="color: #a63024"><span style="font-size: small">(12:03:45)</span> <b>paschos:</b></span> for icecube: 1<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:04:34)</span> <b>bbockelm:</b></span> silly question, does the GPU show up in the site batch system?<br/>
<span style="color: #a63024"><span style="font-size: small">(12:04:52)</span> <b>paschos:</b></span> at gatech? yes<br/>
<span style="color: #43761b"><span style="font-size: small">(12:05:01)</span> <b>blin:</b></span> it's condor locally, right?<br/>
<span style="color: #a63024"><span style="font-size: small">(12:05:04)</span> <b>paschos:</b></span> yes<br/>
<span style="color: #a63024"><span style="font-size: small">(12:05:41)</span> <b>paschos:</b></span> so to loop in brianL, facttory is sending them gpu jobs they just don’t match<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:05:53)</span> <b>bbockelm:</b></span> The pilot logs indicate the pilots are configured for GPUs but condor doesn't detect any.<br/>
<span style="color: #a63024"><span style="font-size: small">(12:06:16)</span> <b>paschos:</b></span> hmm…<br/>
<span style="color: #43761b"><span style="font-size: small">(12:06:27)</span> <b>blin:</b></span> do you have access to the CE or any other local condor pool node?<br/>
<span style="color: #a63024"><span style="font-size: small">(12:07:15)</span> <b>paschos:</b></span> i have access on the submit node which also is running the condor pool --- it will take a few minutes to connect --- vpn stuff<br/>
<span style="color: #43761b"><span style="font-size: small">(12:07:38)</span> <b>blin:</b></span> if you do, i'd be interested in what the local condor pool says<br/><pre>condor_status -af gpus | sort | uniq -c</pre><br/>
<span style="color: #9e3997"><span style="font-size: small">(12:09:51)</span> <b>bbockelm:</b></span> oh - another thought, are we certain these are running on the right hosts?  If I give you a hostname where a glidein ran, can you tell me whether that's a GGPU host?<br/>
<span style="color: #a63024"><span style="font-size: small">(12:09:59)</span> <b>paschos:</b></span> just connected --- hold on<br/>
<span style="color: #a63024"><span style="font-size: small">(12:10:18)</span> <b>paschos:</b></span> [ppaschos3@osg-login2 ~]$ condor_status -af gpus | sort | uniq -c<br/>   4 0<br/>   11 4<br/>  482 undefined<br/>
<span style="color: #a63024"><span style="font-size: small">(12:10:53)</span> <b>paschos:</b></span> yeah give me a hostname<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:10:57)</span> <b>bbockelm:</b></span> <pre>Running on <a href="http://atl1-1-02-014-6-r.pace.gatech.edu">atl1-1-02-014-6-r.pace.gatech.edu</a><br/>System: Linux <a href="http://atl1-1-02-014-6-r.pace.gatech.edu">atl1-1-02-014-6-r.pace.gatech.edu</a> 3.10.0-1160.15.2.el7.x86_64 #1 SMP Thu Jan 21 16:15:07 EST 2021 x86_64 x86_64 x86_64 GNU/Linux<br/>Release: Red Hat Enterprise Linux Server release 7.9 (Maipo)<br/>As: uid=1112(icecube) gid=2112(icecube) groups=2112(icecube),1080(ligo-6),1836(icecube-osg)</pre><br/>
<span style="color: #a63024"><span style="font-size: small">(12:13:05)</span> <b>paschos:</b></span> those are not gpus<br/>
<span style="color: #a63024"><span style="font-size: small">(12:13:19)</span> <b>paschos:</b></span> these are:<br/>condor_status -long <a href="http://atl1-1-01-002-27.pace.gatech.edu">atl1-1-01-002-27.pace.gatech.edu</a> | grep GPU<br/>
<span style="color: #a63024"><span style="font-size: small">(12:13:25)</span> <b>paschos:</b></span> <tt>Assigned*GPU*s = "CUDA0,CUDA1,CUDA2,CUDA3"</tt><br/><tt>Child*GPU*s = { }</tt><br/><tt>Detected*GPU*s = 4</tt><br/><tt>*GPU*s = 4</tt><br/><tt>*GPU*sMemoryUsage = 3.0</tt><br/><tt>Has*GPU* = true</tt><br/><tt>MachineResources = "Cpus Memory Disk Swap *GPU*s"</tt><br/><tt>Rank = (TARGET.Want*GPU* * 1000)</tt><br/><tt>Total*GPU*s = 4</tt><br/><tt>TotalSlot*GPU*s = 4</tt><br/><tt>WithinResourceLimits = (ifThenElse(TARGET._condor_RequestCpus =!= undefined,MY.Cpus &gt; 0 &amp;&amp; TARGET._condor_RequestCpus &lt;= MY.Cpus,ifThenElse(TARGET.RequestCpus =!= undefined,MY.Cpus &gt; 0 &amp;&amp; TARGET.RequestCpus &lt;= MY.Cpus,1 &lt;= MY.Cpus)) &amp;&amp; ifThenElse(TARGET._condor_RequestMemory =!= undefined,MY.Memory &gt; 0 &amp;&amp; TARGET._condor_RequestMemory &lt;= MY.Memory,ifThenElse(TARGET.RequestMemory =!= undefined,MY.Memory &gt; 0 &amp;&amp; TARGET.RequestMemory &lt;= MY.Memory,false)) &amp;&amp; ifThenElse(TARGET._condor_RequestDisk =!= undefined,MY.Disk &gt; 0 &amp;&amp; TARGET._condor_RequestDisk &lt;= MY.Disk,ifThenElse(TARGET.RequestDisk =!= undefined,MY.Disk &gt; 0 &amp;&amp; TARGET.RequestDisk &lt;= MY.Disk,false)) &amp;&amp; (TARGET.Request*GPU*s =?= undefined || MY.*GPU*s &gt;= ifThenElse(TARGET._condor_Request*GPU*s =?= undefined,TARGET.Request*GPU*s,TARGET._condor_Request*GPU*s)))</tt><br/>
<span style="color: #9e3997"><span style="font-size: small">(12:14:41)</span> <b>bbockelm:</b></span> ok, so this is probably a job router problem on the CE.<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:14:47)</span> <b>bbockelm:</b></span> That pilot was in the GPU-only entry point.<br/>
<span style="color: #43761b"><span style="font-size: small">(12:15:13)</span> <b>blin:</b></span> there aren't separate GPU/non-GPU factory entries<br/>
<span style="color: #a63024"><span style="font-size: small">(12:15:14)</span> <b>paschos:</b></span> we made no changes in the CE besides adding the VOs<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:15:29)</span> <b>bbockelm:</b></span> @blin - the entry point for that pilot was <tt>OSG_US_GATech_osg-sched2_gpu</tt><br/>
<span style="color: #43761b"><span style="font-size: small">(12:15:42)</span> <b>blin:</b></span> oh wait nvm, i had a stale factory repo<br/>
<span style="color: #43761b"><span style="font-size: small">(12:16:41)</span> <b>blin:</b></span> i'm not sure why this would be a job router problem? the factory is setting<br/><pre>                  &lt;submit_attr name="Request_GPUs" value="1"/&gt;</pre><br/>for that entry and that should propagate down to the local condor<br/>
<span style="color: #9e3997"><span style="font-size: small">(12:17:52)</span> <b>bbockelm:</b></span> ok, Pascal, if you have access to the local schedd (not the factory one), can you confirm a GPU is being requested in the pilot?<br/>
<span style="color: #a63024"><span style="font-size: small">(12:19:01)</span> <b>paschos:</b></span> you want me to login to a worker node?<br/>
<span style="color: #43761b"><span style="font-size: small">(12:19:10)</span> <b>blin:</b></span> nah, from the CE would be the best actually<br/>
<span style="color: #43761b"><span style="font-size: small">(12:19:42)</span> <b>blin:</b></span> <tt>condor_q &lt;icecube username&gt; -af requestgpus | sort | uniq -c</tt><br/>
<span style="color: #a63024"><span style="font-size: small">(12:20:32)</span> <b>paschos:</b></span> condor_q icecube -af requestgpus | sort | uniq -c<br/>  178 undefined<br/>
<span style="color: #a63024"><span style="font-size: small">(12:21:04)</span> <b>paschos:</b></span> i don’t have access to the CE<br/>
<span style="color: #a63024"><span style="font-size: small">(12:21:17)</span> <b>paschos:</b></span> @ruben.lara<br/>
<span style="color: #a63024"><span style="font-size: small">(12:22:11)</span> <b>paschos:</b></span> i pinged the local folks ----<br/>
<span style="color: #a63024"><span style="font-size: small">(12:23:36)</span> <b>paschos:</b></span> just for my own edification, can you list for me the exact VO names for the GPU jobs the factory is sending to gatech? Is it for example IcecubeGPU or just Icecube?<br/>
<span style="color: #43761b"><span style="font-size: small">(12:24:14)</span> <b>blin:</b></span> i see IceCubeGPU<br/>
<span style="color: #a63024"><span style="font-size: small">(12:27:29)</span> <b>paschos:</b></span> ok --- that VO name is not in the CE configuration --- tthere is just icecube<br/>
<span style="color: #a63024"><span style="font-size: small">(12:27:44)</span> <b>paschos:</b></span> as one of the supported VOs<br/>
<span style="color: #43761b"><span style="font-size: small">(12:28:49)</span> <b>blin:</b></span> i don't think that should matter<br/>
<span style="color: #a63024"><span style="font-size: small">(12:29:19)</span> <b>paschos:</b></span> ok --- just for reference this is what is there:<br/><pre>VoRemoteUserMapping:<br/>  - !&lt;!&gt; /osg/Role=NULL/Capability=NULL: osg<br/>  - !&lt;!&gt; /osg/ligo/Role=NULL/Capability=NULL: ligo<br/>  - !&lt;!&gt; /virgo/ligo/Role=NULL/Capability=NULL: ligo<br/>  - !&lt;!&gt; /icecube/Role=pilot/Capability=NULL: icecube</pre><br/><br/>
<span style="color: #a63024"><span style="font-size: small">(12:29:46)</span> <b>paschos:</b></span> in any case, i. am limited to what I can run on their. system --- we can wait until one of the admins join here<br/>
<span style="color: #43761b"><span style="font-size: small">(12:32:17)</span> <b>blin:</b></span> yeah, the GPU vs non-GPU pilots will be using the same crednetials coming in<br/>
<span style="color: #a63024"><span style="font-size: small">(12:41:48)</span> <b>paschos:</b></span> @blin how can i get a list of nodes where the HostedCE is submitting jobs?<br/>
<span style="color: #43761b"><span style="font-size: small">(12:48:01)</span> <b>blin:</b></span> you'd need access to the CE to tell for sure but from there, you can run <tt>condor_status -af machine | sort | uniq</tt><br/>
<span style="color: #a63024"><span style="font-size: small">(12:52:03)</span> <b>paschos:</b></span> well the entire cluster is a target for glideins --- so I am going to assume that every node is running one — but neither have access to the CE or the individual worker nodes --- so we’ll need someone from there to run those… there is a ticket for this--- discussed with BB to include software in it<br/>
<span style="color: #9e3997"><span style="font-size: small">(13:10:26)</span> <b>bbockelm:</b></span> Pascal, I think the important thing is to verify the glideins landing in the local condor schedd are requesting GPUs.<br/>
<span style="color: #a63024"><span style="font-size: small">(13:23:03)</span> <b>paschos:</b></span> the cluster is a mix of cpu-only and gpu-nodes<br/>
<span style="color: #a63024"><span style="font-size: small">(13:25:37)</span> <b>paschos:</b></span> all i can see from the headnode is this:<br/><tt>[ppaschos3@osg-login2 ~]$ for a in condor_status -af machine | sort | uniq; do b=</tt>condor_status -long $a | grep DetectedGPU<tt>; echo $a " " $b; done</tt><br/><tt><a href="http://atl1-1-01-002-11.pace.gatech.edu">atl1-1-01-002-11.pace.gatech.edu</a>  DetectedGPUs = 4 DetectedGPUs = 4 DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-01-002-13.pace.gatech.edu">atl1-1-01-002-13.pace.gatech.edu</a>  DetectedGPUs = 4 DetectedGPUs = 4 DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-01-002-15.pace.gatech.edu">atl1-1-01-002-15.pace.gatech.edu</a>  DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-01-002-17.pace.gatech.edu">atl1-1-01-002-17.pace.gatech.edu</a>  DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-01-002-19.pace.gatech.edu">atl1-1-01-002-19.pace.gatech.edu</a>  DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-01-002-21.pace.gatech.edu">atl1-1-01-002-21.pace.gatech.edu</a>  DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-01-002-23.pace.gatech.edu">atl1-1-01-002-23.pace.gatech.edu</a>  DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-01-002-25.pace.gatech.edu">atl1-1-01-002-25.pace.gatech.edu</a>  DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-01-002-27.pace.gatech.edu">atl1-1-01-002-27.pace.gatech.edu</a>  DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-01-002-29.pace.gatech.edu">atl1-1-01-002-29.pace.gatech.edu</a>  DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-01-002-33-l.pace.gatech.edu">atl1-1-01-002-33-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-33-r.pace.gatech.edu">atl1-1-01-002-33-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-34-l.pace.gatech.edu">atl1-1-01-002-34-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-34-r.pace.gatech.edu">atl1-1-01-002-34-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-35-l.pace.gatech.edu">atl1-1-01-002-35-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-35-r.pace.gatech.edu">atl1-1-01-002-35-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-36-l.pace.gatech.edu">atl1-1-01-002-36-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-36-r.pace.gatech.edu">atl1-1-01-002-36-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-37-l.pace.gatech.edu">atl1-1-01-002-37-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-37-r.pace.gatech.edu">atl1-1-01-002-37-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-38-l.pace.gatech.edu">atl1-1-01-002-38-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-38-r.pace.gatech.edu">atl1-1-01-002-38-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-01-002-9.pace.gatech.edu">atl1-1-01-002-9.pace.gatech.edu</a>  DetectedGPUs = 4</tt><br/><tt><a href="http://atl1-1-02-014-10-l.pace.gatech.edu">atl1-1-02-014-10-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-10-r.pace.gatech.edu">atl1-1-02-014-10-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-11-l.pace.gatech.edu">atl1-1-02-014-11-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-11-r.pace.gatech.edu">atl1-1-02-014-11-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-12-l.pace.gatech.edu">atl1-1-02-014-12-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-12-r.pace.gatech.edu">atl1-1-02-014-12-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-13-l.pace.gatech.edu">atl1-1-02-014-13-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-1-l.pace.gatech.edu">atl1-1-02-014-1-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-1-r.pace.gatech.edu">atl1-1-02-014-1-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-2-l.pace.gatech.edu">atl1-1-02-014-2-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-2-r.pace.gatech.edu">atl1-1-02-014-2-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-3-l.pace.gatech.edu">atl1-1-02-014-3-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-3-r.pace.gatech.edu">atl1-1-02-014-3-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-4-l.pace.gatech.edu">atl1-1-02-014-4-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-4-r.pace.gatech.edu">atl1-1-02-014-4-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-5-l.pace.gatech.edu">atl1-1-02-014-5-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-5-r.pace.gatech.edu">atl1-1-02-014-5-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-6-l.pace.gatech.edu">atl1-1-02-014-6-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-6-r.pace.gatech.edu">atl1-1-02-014-6-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-7-l.pace.gatech.edu">atl1-1-02-014-7-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-7-r.pace.gatech.edu">atl1-1-02-014-7-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-8-l.pace.gatech.edu">atl1-1-02-014-8-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-8-r.pace.gatech.edu">atl1-1-02-014-8-r.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-9-l.pace.gatech.edu">atl1-1-02-014-9-l.pace.gatech.edu</a>  </tt><br/><tt><a href="http://atl1-1-02-014-9-r.pace.gatech.edu">atl1-1-02-014-9-r.pace.gatech.edu</a></tt><br/>
<span style="color: #43761b"><span style="font-size: small">(13:26:14)</span> <b>blin:</b></span> it's too bad that GATech firewalls remote queries. we could do a fair amount of digging locally!<br/>
<span style="color: #43761b"><span style="font-size: small">(13:26:27)</span> <b>blin:</b></span> OH WAIT!<br/>
<span style="color: #43761b"><span style="font-size: small">(13:26:37)</span> <b>blin:</b></span> i think this is a Bosco issue<br/>
<span style="color: #43761b"><span style="font-size: small">(13:26:51)</span> <b>blin:</b></span> this is a hosted CE, right?<br/>
<span style="color: #a63024"><span style="font-size: small">(13:26:54)</span> <b>paschos:</b></span> yes<br/>
<span style="color: #a63024"><span style="font-size: small">(13:28:43)</span> <b>paschos:</b></span> <pre><a href="http://osg-sched2.pace.gatech.edu">osg-sched2.pace.gatech.edu</a></pre><br/><br/>
<span style="color: #43761b"><span style="font-size: small">(13:28:44)</span> <b>blin:</b></span> older versions of bosco submission don't support GPU job submission natively<br/>
<span style="color: #43761b"><span style="font-size: small">(13:29:03)</span> <b>blin:</b></span> bad news: new versions of bosco are untested<br/>
<span style="color: #43761b"><span style="font-size: small">(13:29:14)</span> <b>blin:</b></span> medium (?) news: we can work around this with Hosted CE config<br/>
<span style="color: #43761b"><span style="font-size: small">(13:29:51)</span> <b>blin:</b></span> what does the <tt>HTCondorCeConfig</tt> section look like?<br/>
<span style="color: #43761b"><span style="font-size: small">(13:30:03)</span> <b>blin:</b></span> also <tt>BoscoOverrides</tt><br/>
<span style="color: #a63024"><span style="font-size: small">(13:31:36)</span> <b>paschos:</b></span> i can’t be on the CE itself but here is the config<br/><pre>$ slate instance info instance_56OFJwTb1XQ --conf<br/><br/>HTCondorCeConfig: !&lt;!&gt; "IsCCStar = True\nSCHEDD_ATTRS = $(SCHEDD_ATTRS) IsCCStar\n"<br/>Developer:<br/>  Enabled: false<br/>RemoteCluster:<br/>  WorkerNodeTemp: /scratch<br/>  BoscoDir: bosco<br/>  GridDir: /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.5/current/el7-x86_64<br/>  MaxWallTime: 86400<br/>  Batch: condor<br/>  Squid: 128.61.166.231:31200<br/>  MemoryPerNode: 196608<br/>  CoresPerNode: 24<br/>  LoginHost: <a href="http://osg-login2.pace.gatech.edu">osg-login2.pace.gatech.edu</a><br/>  PrivateKeySecret: gatech-lp-hostedce-privkey<br/>HTTPLogger:<br/>  Enabled: true<br/>DnRemoteUserMapping:<br/>  - /DC=org/DC=cilogon/C=US/O=University of Chicago/CN=lincoln bryant A34716: osg<br/>  - /DC=org/DC=cilogon/C=US/O=Georgia Institute of Technology/CN=Trever Nightingale A37200796: osg<br/>BoscoOverrides:<br/>  Enabled: false<br/>  GitEndpoint: <a href="https://github.com/slateci/bosco-override-template">https://github.com/slateci/bosco-override-template</a><br/>  GitKeySecret: ~<br/>Topology:<br/>  City: Atlanta<br/>  Resource: Georgia_Tech_PACE_CE_2<br/>  ResourceGroup: Georgia Tech PACE OSG 2<br/>  Latitude: 33.7756<br/>  Country: US<br/>  Longitude: -84.3963<br/>  Sponsor: ligo:100<br/>  ContactEmail: <a href="mailto:tnightingale6@gatech.edu">tnightingale6@gatech.edu</a><br/>  Contact: Trever Nightingale<br/>ContainerTags:<br/>  HostedCE: stable<br/>HostCredentials:<br/>  HostKeySecret: gatech-hostedce-osg-sched-2-gridcert-key<br/>  HostCertSecret: gatech-hostedce-osg-sched-2-gridcert<br/>VoRemoteUserMapping:<br/>  - /osg/Role=NULL/Capability=NULL: osg<br/>  - /osg/ligo/Role=NULL/Capability=NULL: ligo<br/>  - /virgo/ligo/Role=NULL/Capability=NULL: ligo<br/>Instance: osg-gatech-dev<br/>Networking:<br/>  Hostname: <a href="http://osg-sched2.pace.gatech.edu">osg-sched2.pace.gatech.edu</a><br/>  ServiceType: LoadBalancer<br/>  RequestIP: 128.61.166.235</pre><br/><br/>
<span style="color: #a63024"><span style="font-size: small">(13:32:17)</span> <b>paschos:</b></span> enabled false<br/>
<span style="color: #43761b"><span style="font-size: small">(13:33:03)</span> <b>blin:</b></span> ok to get this working they'll need to set up a <tt>BoscoOverrides</tt> adding GPU requests to <tt>condor_local_submit_attributes.sh</tt> and set up job router entries such that the GPU vs non-GPU pilots are split into separate routes<br/>
<span style="color: #a63024"><span style="font-size: small">(13:34:59)</span> <b>paschos:</b></span> do they need to rebuilt the hostedCE?<br/>
<span style="color: #43761b"><span style="font-size: small">(13:36:04)</span> <b>blin:</b></span> they'll need to redeploy it after making these changes<br/>
<span style="color: #a63024"><span style="font-size: small">(13:36:21)</span> <b>paschos:</b></span> hmm--- ok<br/>
<span style="color: #43761b"><span style="font-size: small">(13:37:17)</span> <b>blin:</b></span> the alternative is to wait for us to test the latest bosco (i'm shooting to have that done this week) but that still requires a redeploy<br/>
<span style="color: #a63024"><span style="font-size: small">(13:37:44)</span> <b>paschos:</b></span> can non-GPU pilots still rrun on available cores of GPU nodes?<br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(13:43:23)</span> <b>blin:</b></span> depends on how their condor pool is set up. if the GPU nodes aren't restricted to GPU-only jobs then yes, they'll run non-GPU pilots<br/>
</blockquote>
<span style="color: #a63024"><span style="font-size: small">(13:41:14)</span> <b>paschos:</b></span> also where is the *condor_local_submit_attributes*.*sh located?*<br/>
<blockquote>
<span style="color: #43761b"><span style="font-size: small">(13:43:52)</span> <b>blin:</b></span> you'll have to set this up in a bosco override. I believe SLATE has documentation for this<br/>
</blockquote>
<span style="color: #e96699"><span style="font-size: small">(13:46:30)</span> <b>lincoln:</b></span> <a href="https://github.com/slateci/bosco-override-template/blob/master/RESOURCE_NAME/bosco_override/glite/etc/blahp/condor_local_submit_attributes.sh">https://github.com/slateci/bosco-override-template/blob/master/RESOURCE_NAME/bosco_override/glite/etc/blahp/condor_local_submit_attributes.sh</a> I think you basically end up cloning this repo and editing this file<br/>
<span style="color: #43761b"><span style="font-size: small">(13:48:39)</span> <b>blin:</b></span> making sure the RESOURCE_NAME root dir reflect the resource name of the CE that you have configured<br/>
<span style="color: #a63024"><span style="font-size: small">(13:52:20)</span> <b>paschos:</b></span> well — it’s up to them --- but i’d prefer we wait for the latest bosco --- no reason for effort investing if there is an upcoming solution<br/>
<span style="color: #43761b"><span style="font-size: small">(13:54:37)</span> <b>blin:</b></span> i'll let you know if the diagnosis for the bosco tarball doesn't look good. that'd stretch the timeline<br/>
<span style="color: #c386df"><span style="font-size: small">(13:56:26)</span> <b>ruben.lara:</b></span> So, for now, there’s nothing for us to change locally, correct?<br/>
<span style="color: #43761b"><span style="font-size: small">(13:57:40)</span> <b>blin:</b></span> correct<br/>
<span style="color: #c386df"><span style="font-size: small">(14:00:01)</span> <b>ruben.lara:</b></span> Very good. To answer one of @paschos questions, yes, the GPU nodes accept non-GPU jobs without issues. And locally the GPUs can be requested and used.<br/>
<span style="color: #a63024"><span style="font-size: small">(14:05:13)</span> <b>paschos:</b></span> so @ruben.lara from your end, ok to wait for the new bosco to be deployed rather than working through the process outlined above?<br/>
<span style="color: #c386df"><span style="font-size: small">(14:06:21)</span> <b>ruben.lara:</b></span> I am fine. The less changes and workarounds we need to do, the better. I think @mehmet.belgin will also be able to wait.<br/>
</body>
</html>
