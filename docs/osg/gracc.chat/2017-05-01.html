<!DOCTYPE html>
<html>
<head>
<title>Mon May 1, 2017 : #gracc (osg)</title>
</head>
<body>
<h3>Mon May 1, 2017 : #gracc (osg)</h3>
<span style="color: #674b1b"><span style="font-size: small">(10:35:20)</span> <b>rynge:</b></span> 249 Payload records dated between 2016-05-01 13:00:01 and 2017-05-01 13:00:01 with:<br/>         CommonName: /CN=tswetnam<br/>         VOName: osg<br/>         ProbeName: condor:<a href="http://xd-login.opensciencegrid.org">xd-login.opensciencegrid.org</a><br/>         Wall Hours: 52094.9133333<br/> were reported with no ProjectName ("N/A") to GRACC.  Please investigate.<br/>
<span style="color: #674b1b"><span style="font-size: small">(10:35:30)</span> <b>rynge:</b></span> That is is probably not worth reporting for the whole year<br/>
<span style="color: #674b1b"><span style="font-size: small">(10:40:13)</span> <b>rynge:</b></span> That report also seems to be run multiple times<br/>
<span style="color: #674b1b"><span style="font-size: small">(10:41:08)</span> <b>rynge:</b></span> I bet those records are dagmans running in the scheduler universe<br/>
<span style="color: #235e5b"><span style="font-size: small">(10:41:29)</span> <b>dweitzel:</b></span> Let me look them up real quick.<br/>
<span style="color: #aba727"><span style="font-size: small">(10:42:52)</span> <b>sbhat:</b></span> I'll look into the multiple times. I kept the same schedule as the Gratia reports, so it should be the same amount. But I'll check.<br/>
<span style="color: #235e5b"><span style="font-size: small">(10:43:23)</span> <b>dweitzel:</b></span> @rynge They look like legit jobs, not DagMan<br/>
<span style="color: #235e5b"><span style="font-size: small">(10:43:36)</span> <b>dweitzel:</b></span> On xd-login, 1 job is 176955.64<br/>
<span style="color: #235e5b"><span style="font-size: small">(10:43:43)</span> <b>dweitzel:</b></span> From March 25th.<br/>
<span style="color: #235e5b"><span style="font-size: small">(10:44:05)</span> <b>dweitzel:</b></span> Ran at Caltech.<br/>
<span style="color: #674b1b"><span style="font-size: small">(10:45:20)</span> <b>rynge:</b></span> Hmm<br/>
<span style="color: #8d4b84"><span style="font-size: small">(10:50:44)</span> <b>kherner:</b></span> @rynge Yes, I saw these in the reports too. We're talking about a few hundred hours over the course of the year (out of nearly 1.4 B). If it hasn't happened recently I'm not sure how much time we should spend on it. It looks like 5 weeks ago was the last time?<br/>
<span style="color: #674b1b"><span style="font-size: small">(10:50:51)</span> <b>rynge:</b></span> Do you have a newer one? History is rolling over too quickly<br/>
<span style="color: #674b1b"><span style="font-size: small">(10:51:27)</span> <b>rynge:</b></span> Yeah, the only time I can think of it happening is when we upgrade condor. The submit wrapper then have to be moved into place, and we could miss a few jobs<br/>
<span style="color: #235e5b"><span style="font-size: small">(10:51:36)</span> <b>dweitzel:</b></span> Looks like the newest is March 25th.<br/>
<span style="color: #674b1b"><span style="font-size: small">(10:51:40)</span> <b>rynge:</b></span> The 25 is weird as it is a saturday<br/>
<span style="color: #674b1b"><span style="font-size: small">(10:51:53)</span> <b>rynge:</b></span> But maybe we did sneak an upgrade in on the weekend<br/>
<span style="color: #674b1b"><span style="font-size: small">(10:52:42)</span> <b>rynge:</b></span> Ok, so let's not worry unless it happens again then<br/>
<span style="color: #aba727"><span style="font-size: small">(11:08:36)</span> <b>sbhat:</b></span> @rynge The old gratia project reports (OSG-Direct, OSG-Connect, XD) ran every Monday (for the past week of data), and on the first of every month (past month, past year)<br/>
<span style="color: #aba727"><span style="font-size: small">(11:09:04)</span> <b>sbhat:</b></span> this is Monday _and_ the 1st of the month, so we got hit with all of the reports<br/>
<span style="color: #aba727"><span style="font-size: small">(11:09:14)</span> <b>sbhat:</b></span> but they should all be unique<br/>
<span style="color: #aba727"><span style="font-size: small">(11:10:20)</span> <b>sbhat:</b></span> would it be better if I staggered them so they don't all get sent at the same time?<br/>
<span style="color: #674b1b"><span style="font-size: small">(11:10:44)</span> <b>rynge:</b></span> I think that report should only report data from last week<br/>
<span style="color: #674b1b"><span style="font-size: small">(11:11:01)</span> <b>rynge:</b></span> A full year of "investigate this" will just train us to never look at them<br/>
<span style="color: #aba727"><span style="font-size: small">(11:11:04)</span> <b>sbhat:</b></span> haha<br/>
<span style="color: #aba727"><span style="font-size: small">(11:11:36)</span> <b>sbhat:</b></span> that's an easy enough change - let me check with Tanya to see if anyone else had asked for a full month/year before I turn that off<br/>
<span style="color: #902d59"><span style="font-size: small">(11:12:24)</span> <b>tanya:</b></span> Hi, no nobody asked for  a year or month. Weekly should be enough<br/>
<span style="color: #aba727"><span style="font-size: small">(11:15:03)</span> <b>sbhat:</b></span> great<br/>
<span style="color: #9e3997"><span style="font-size: small">(13:53:37)</span> <b>bbockelm:</b></span> <b>@edquist</b> - for <a href="https://ticket.grid.iu.edu/33618">https://ticket.grid.iu.edu/33618</a> - can you post a status report for Ajit?  It's been 4 days since the last update.<br/>
<span style="color: #9e3997"><span style="font-size: small">(13:54:43)</span> <b>bbockelm:</b></span> Given that these align with the end of the month, it needs to resolve in the next day or two.<br/>
<span style="color: #9e3997"><span style="font-size: small">(13:55:21)</span> <b>bbockelm:</b></span> I'll also start getting emails from James Letts on the subject soon. Might be a good idea to preemptively reach out to him as he'll be at condor week<br/>
<span style="color: #16569E"><span style="font-size: small">(14:01:47)</span> <b>edquist:</b></span> Yeah I'll post an update in the ticket today; and yeah hopefully we should have it sorted out today or tomorrow.<br/>
<span style="color: #235e5b"><span style="font-size: small">(16:59:31)</span> <b>dweitzel:</b></span> Why do we have "By Project" in the pilot jobs view?  Pilot jobs don't have projects.<br/>
<span style="color: #235e5b"><span style="font-size: small">(16:59:50)</span> <b>dweitzel:</b></span> though, it confuses me why some are <tt>grid</tt> or <tt>osg</tt><br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:06:59)</span> <b>kretzke:</b></span> so delete it. those dashboards need a lot of cleanup<br/>
<span style="color: #16569E"><span style="font-size: small">(17:36:35)</span> <b>edquist:</b></span> @sbhat; how are the <tt>OIM_WLCGAPELNormFactor</tt> field values computed?  Or, what are the key fields from the record used to match what is in OIM?  Eg, for GLOW cms Batch records, I see 68% at 9.87 and 32% at 0<br/><br/><a href="https://gracc.opensciencegrid.org/kibana/app/kibana#/discover?_g=(refreshInterval:(display:Off,pause:!f,value:0),time:(from:%272017-03-02T01:00:00.000Z%27,mode:absolute,to:%272017-03-31T23:59:59.999Z%27))&amp;_a=(columns:!(_source),filters:!((%27$$hashKey%27:%27object:1233%27,%27$state%27:(store:appState),meta:(alias:!n,disabled:!f,index:gracc.osg.summary,key:VOName,negate:!f,value:cms),query:(match:(VOName:(query:cms,type:phrase)))),(%27$$hashKey%27:%27object:2151%27,%27$state%27:(store:appState),meta:(alias:!n,disabled:!f,index:gracc.osg.summary,key:OIM_ResourceGroup,negate:!f,value:GLOW),query:(match:(OIM_ResourceGroup:(query:GLOW,type:phrase)))),(%27$$hashKey%27:%27object:2628%27,%27$state%27:(store:appState),meta:(alias:!n,disabled:!f,index:gracc.osg.summary,key:ResourceType,negate:!f,value:Batch),query:(match:(ResourceType:(query:Batch,type:phrase))))),index:gracc.osg.summary,interval:auto,query:(query_string:(analyze_wildcard:!f,query:%27*%27)),sort:!(EndTime,desc),uiState:(vis:(legendOpen:!t)))">https://gracc.opensciencegrid.org/kibana/app/kibana#/discover?_g=(refreshInterval:(display:Off,pause:!f,value:0),time:(from:%272017-03-02T01:00:00.000Z%27,mode:absolute,to:%272017-03-31T23:59:59.999Z%27))&amp;_a=(columns:!(_source),filters:!((%27$$hashKey%27:%27object:1233%27,%27$state%27:(store:appState),meta:(alias:!n,disabled:!f,index:gracc.osg.summary,key:VOName,negate:!f,value:cms),query:(match:(VOName:(query:cms,type:phrase)))),(%27$$hashKey%27:%27object:2151%27,%27$state%27:(store:appState),meta:(alias:!n,disabled:!f,index:gracc.osg.summary,key:OIM_ResourceGroup,negate:!f,value:GLOW),query:(match:(OIM_ResourceGroup:(query:GLOW,type:phrase)))),(%27$$hashKey%27:%27object:2628%27,%27$state%27:(store:appState),meta:(alias:!n,disabled:!f,index:gracc.osg.summary,key:ResourceType,negate:!f,value:Batch),query:(match:(ResourceType:(query:Batch,type:phrase))))),index:gracc.osg.summary,interval:auto,query:(query_string:(analyze_wildcard:!f,query:%27*%27)),sort:!(EndTime,desc),uiState:(vis:(legendOpen:!t)))</a><br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:40:49)</span> <b>kretzke:</b></span> <b>@edquist</b> here’s your problem <a href="https://oim.opensciencegrid.org/oim/resource?id=644">https://oim.opensciencegrid.org/oim/resource?id=644</a><br/>
<span style="color: #16569E"><span style="font-size: small">(17:41:43)</span> <b>edquist:</b></span> ah so it's per resource not per resource group?<br/>
<span style="color: #3c8c69"><span style="font-size: small">(17:42:45)</span> <b>kretzke:</b></span> Shreyas will confirm, but afaik yes, and it explains what you’re seeing with GLOW<br/>
<span style="color: #16569E"><span style="font-size: small">(17:43:13)</span> <b>edquist:</b></span> makes sense<br/>
<span style="color: #16569E"><span style="font-size: small">(17:43:17)</span> <b>edquist:</b></span> thank you!<br/>
<span style="color: #aba727"><span style="font-size: small">(19:06:51)</span> <b>sbhat:</b></span> Confirmed <br/>
<span style="color: #235e5b"><span style="font-size: small">(20:59:33)</span> <b>dweitzel:</b></span> Great. So does that mean we just need to resummarize?<br/>
</body>
</html>
